{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikit-learn\n!pip install playwright\n!playwright install\n!playwright install-deps\nprint(\"done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:33:39.548918Z","iopub.execute_input":"2026-01-15T18:33:39.549299Z","iopub.status.idle":"2026-01-15T18:35:20.186940Z","shell.execute_reply.started":"2026-01-15T18:33:39.549273Z","shell.execute_reply":"2026-01-15T18:35:20.185779Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nCollecting playwright\n  Downloading playwright-1.57.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\nCollecting pyee<14,>=13 (from playwright)\n  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright) (3.1.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<14,>=13->playwright) (4.12.2)\nDownloading playwright-1.57.0-py3-none-manylinux1_x86_64.whl (46.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyee-13.0.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyee, playwright\nSuccessfully installed playwright-1.57.0 pyee-13.0.0\nDownloading Chromium 143.0.7499.4 (playwright build v1200)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1200/chromium-linux.zip\u001b[22m\n(node:3156) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\u001b[1G164.7 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G164.7 MiB [                    ] 0% 20.5s\u001b[0K\u001b[1G164.7 MiB [                    ] 0% 11.9s\u001b[0K\u001b[1G164.7 MiB [                    ] 0% 8.9s\u001b[0K\u001b[1G164.7 MiB [                    ] 1% 3.8s\u001b[0K\u001b[1G164.7 MiB [=                   ] 2% 2.9s\u001b[0K\u001b[1G164.7 MiB [=                   ] 3% 2.4s\u001b[0K\u001b[1G164.7 MiB [=                   ] 4% 2.4s\u001b[0K\u001b[1G164.7 MiB [=                   ] 5% 2.2s\u001b[0K\u001b[1G164.7 MiB [=                   ] 6% 2.0s\u001b[0K\u001b[1G164.7 MiB [==                  ] 8% 1.8s\u001b[0K\u001b[1G164.7 MiB [==                  ] 9% 1.8s\u001b[0K\u001b[1G164.7 MiB [==                  ] 10% 1.7s\u001b[0K\u001b[1G164.7 MiB [==                  ] 11% 1.6s\u001b[0K\u001b[1G164.7 MiB [===                 ] 12% 1.5s\u001b[0K\u001b[1G164.7 MiB [===                 ] 14% 1.4s\u001b[0K\u001b[1G164.7 MiB [===                 ] 15% 1.4s\u001b[0K\u001b[1G164.7 MiB [===                 ] 16% 1.4s\u001b[0K\u001b[1G164.7 MiB [====                ] 17% 1.3s\u001b[0K\u001b[1G164.7 MiB [====                ] 19% 1.3s\u001b[0K\u001b[1G164.7 MiB [====                ] 20% 1.2s\u001b[0K\u001b[1G164.7 MiB [====                ] 21% 1.2s\u001b[0K\u001b[1G164.7 MiB [=====               ] 23% 1.2s\u001b[0K\u001b[1G164.7 MiB [=====               ] 24% 1.1s\u001b[0K\u001b[1G164.7 MiB [=====               ] 26% 1.1s\u001b[0K\u001b[1G164.7 MiB [======              ] 27% 1.0s\u001b[0K\u001b[1G164.7 MiB [======              ] 29% 1.0s\u001b[0K\u001b[1G164.7 MiB [======              ] 30% 1.0s\u001b[0K\u001b[1G164.7 MiB [======              ] 32% 0.9s\u001b[0K\u001b[1G164.7 MiB [=======             ] 33% 0.9s\u001b[0K\u001b[1G164.7 MiB [=======             ] 35% 0.9s\u001b[0K\u001b[1G164.7 MiB [=======             ] 36% 0.9s\u001b[0K\u001b[1G164.7 MiB [========            ] 38% 0.8s\u001b[0K\u001b[1G164.7 MiB [========            ] 40% 0.8s\u001b[0K\u001b[1G164.7 MiB [========            ] 41% 0.8s\u001b[0K\u001b[1G164.7 MiB [=========           ] 43% 0.7s\u001b[0K\u001b[1G164.7 MiB [=========           ] 44% 0.7s\u001b[0K\u001b[1G164.7 MiB [=========           ] 45% 0.7s\u001b[0K\u001b[1G164.7 MiB [=========           ] 47% 0.7s\u001b[0K\u001b[1G164.7 MiB [==========          ] 48% 0.7s\u001b[0K\u001b[1G164.7 MiB [==========          ] 49% 0.6s\u001b[0K\u001b[1G164.7 MiB [==========          ] 51% 0.6s\u001b[0K\u001b[1G164.7 MiB [===========         ] 53% 0.6s\u001b[0K\u001b[1G164.7 MiB [===========         ] 55% 0.6s\u001b[0K\u001b[1G164.7 MiB [===========         ] 56% 0.5s\u001b[0K\u001b[1G164.7 MiB [============        ] 58% 0.5s\u001b[0K\u001b[1G164.7 MiB [============        ] 59% 0.5s\u001b[0K\u001b[1G164.7 MiB [============        ] 61% 0.5s\u001b[0K\u001b[1G164.7 MiB [=============       ] 63% 0.4s\u001b[0K\u001b[1G164.7 MiB [=============       ] 65% 0.4s\u001b[0K\u001b[1G164.7 MiB [=============       ] 66% 0.4s\u001b[0K\u001b[1G164.7 MiB [==============      ] 68% 0.4s\u001b[0K\u001b[1G164.7 MiB [==============      ] 69% 0.4s\u001b[0K\u001b[1G164.7 MiB [==============      ] 71% 0.3s\u001b[0K\u001b[1G164.7 MiB [===============     ] 73% 0.3s\u001b[0K\u001b[1G164.7 MiB [===============     ] 74% 0.3s\u001b[0K\u001b[1G164.7 MiB [===============     ] 76% 0.3s\u001b[0K\u001b[1G164.7 MiB [================    ] 77% 0.3s\u001b[0K\u001b[1G164.7 MiB [================    ] 79% 0.2s\u001b[0K\u001b[1G164.7 MiB [================    ] 81% 0.2s\u001b[0K\u001b[1G164.7 MiB [=================   ] 82% 0.2s\u001b[0K\u001b[1G164.7 MiB [=================   ] 84% 0.2s\u001b[0K\u001b[1G164.7 MiB [=================   ] 86% 0.2s\u001b[0K\u001b[1G164.7 MiB [==================  ] 87% 0.1s\u001b[0K\u001b[1G164.7 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G164.7 MiB [==================  ] 91% 0.1s\u001b[0K\u001b[1G164.7 MiB [=================== ] 92% 0.1s\u001b[0K\u001b[1G164.7 MiB [=================== ] 94% 0.1s\u001b[0K\u001b[1G164.7 MiB [=================== ] 96% 0.0s\u001b[0K\u001b[1G164.7 MiB [====================] 98% 0.0s\u001b[0K\u001b[1G164.7 MiB [====================] 99% 0.0s\u001b[0K\u001b[1G164.7 MiB [====================] 100% 0.0s\u001b[0K\nChromium 143.0.7499.4 (playwright build v1200) downloaded to /root/.cache/ms-playwright/chromium-1200\nDownloading Chromium Headless Shell 143.0.7499.4 (playwright build v1200)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1200/chromium-headless-shell-linux.zip\u001b[22m\n(node:3168) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\u001b[1G109.7 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G109.7 MiB [                    ] 0% 9.8s\u001b[0K\u001b[1G109.7 MiB [                    ] 0% 5.4s\u001b[0K\u001b[1G109.7 MiB [                    ] 2% 2.4s\u001b[0K\u001b[1G109.7 MiB [=                   ] 3% 1.7s\u001b[0K\u001b[1G109.7 MiB [=                   ] 5% 1.4s\u001b[0K\u001b[1G109.7 MiB [=                   ] 6% 1.5s\u001b[0K\u001b[1G109.7 MiB [==                  ] 8% 1.3s\u001b[0K\u001b[1G109.7 MiB [==                  ] 10% 1.2s\u001b[0K\u001b[1G109.7 MiB [==                  ] 11% 1.1s\u001b[0K\u001b[1G109.7 MiB [===                 ] 13% 1.0s\u001b[0K\u001b[1G109.7 MiB [===                 ] 14% 1.0s\u001b[0K\u001b[1G109.7 MiB [===                 ] 16% 1.0s\u001b[0K\u001b[1G109.7 MiB [====                ] 18% 0.9s\u001b[0K\u001b[1G109.7 MiB [====                ] 20% 0.9s\u001b[0K\u001b[1G109.7 MiB [====                ] 22% 0.8s\u001b[0K\u001b[1G109.7 MiB [=====               ] 23% 0.8s\u001b[0K\u001b[1G109.7 MiB [=====               ] 25% 0.8s\u001b[0K\u001b[1G109.7 MiB [======              ] 28% 0.7s\u001b[0K\u001b[1G109.7 MiB [======              ] 29% 0.7s\u001b[0K\u001b[1G109.7 MiB [======              ] 31% 0.7s\u001b[0K\u001b[1G109.7 MiB [=======             ] 33% 0.7s\u001b[0K\u001b[1G109.7 MiB [=======             ] 35% 0.6s\u001b[0K\u001b[1G109.7 MiB [========            ] 38% 0.6s\u001b[0K\u001b[1G109.7 MiB [========            ] 40% 0.6s\u001b[0K\u001b[1G109.7 MiB [=========           ] 43% 0.5s\u001b[0K\u001b[1G109.7 MiB [=========           ] 45% 0.5s\u001b[0K\u001b[1G109.7 MiB [==========          ] 48% 0.5s\u001b[0K\u001b[1G109.7 MiB [==========          ] 51% 0.4s\u001b[0K\u001b[1G109.7 MiB [===========         ] 53% 0.4s\u001b[0K\u001b[1G109.7 MiB [===========         ] 56% 0.4s\u001b[0K\u001b[1G109.7 MiB [============        ] 58% 0.4s\u001b[0K\u001b[1G109.7 MiB [============        ] 60% 0.3s\u001b[0K\u001b[1G109.7 MiB [=============       ] 63% 0.3s\u001b[0K\u001b[1G109.7 MiB [=============       ] 65% 0.3s\u001b[0K\u001b[1G109.7 MiB [==============      ] 67% 0.3s\u001b[0K\u001b[1G109.7 MiB [==============      ] 69% 0.2s\u001b[0K\u001b[1G109.7 MiB [==============      ] 71% 0.2s\u001b[0K\u001b[1G109.7 MiB [===============     ] 74% 0.2s\u001b[0K\u001b[1G109.7 MiB [===============     ] 76% 0.2s\u001b[0K\u001b[1G109.7 MiB [================    ] 79% 0.2s\u001b[0K\u001b[1G109.7 MiB [================    ] 82% 0.1s\u001b[0K\u001b[1G109.7 MiB [=================   ] 84% 0.1s\u001b[0K\u001b[1G109.7 MiB [=================   ] 87% 0.1s\u001b[0K\u001b[1G109.7 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G109.7 MiB [==================  ] 91% 0.1s\u001b[0K\u001b[1G109.7 MiB [=================== ] 94% 0.0s\u001b[0K\u001b[1G109.7 MiB [=================== ] 96% 0.0s\u001b[0K\u001b[1G109.7 MiB [====================] 98% 0.0s\u001b[0K\u001b[1G109.7 MiB [====================] 100% 0.0s\u001b[0K\nChromium Headless Shell 143.0.7499.4 (playwright build v1200) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1200\nDownloading Firefox 144.0.2 (playwright build v1497)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1497/firefox-ubuntu-22.04.zip\u001b[22m\n(node:3179) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\u001b[1G98.4 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G98.4 MiB [                    ] 0% 5.6s\u001b[0K\u001b[1G98.4 MiB [                    ] 1% 3.0s\u001b[0K\u001b[1G98.4 MiB [=                   ] 2% 2.2s\u001b[0K\u001b[1G98.4 MiB [=                   ] 4% 1.6s\u001b[0K\u001b[1G98.4 MiB [=                   ] 5% 1.5s\u001b[0K\u001b[1G98.4 MiB [=                   ] 6% 1.6s\u001b[0K\u001b[1G98.4 MiB [==                  ] 8% 1.3s\u001b[0K\u001b[1G98.4 MiB [==                  ] 10% 1.2s\u001b[0K\u001b[1G98.4 MiB [==                  ] 12% 1.1s\u001b[0K\u001b[1G98.4 MiB [===                 ] 13% 1.1s\u001b[0K\u001b[1G98.4 MiB [===                 ] 14% 1.1s\u001b[0K\u001b[1G98.4 MiB [===                 ] 16% 1.1s\u001b[0K\u001b[1G98.4 MiB [====                ] 17% 1.0s\u001b[0K\u001b[1G98.4 MiB [====                ] 19% 1.0s\u001b[0K\u001b[1G98.4 MiB [====                ] 20% 1.0s\u001b[0K\u001b[1G98.4 MiB [====                ] 22% 0.9s\u001b[0K\u001b[1G98.4 MiB [=====               ] 24% 0.9s\u001b[0K\u001b[1G98.4 MiB [=====               ] 25% 0.9s\u001b[0K\u001b[1G98.4 MiB [======              ] 27% 0.9s\u001b[0K\u001b[1G98.4 MiB [======              ] 29% 0.8s\u001b[0K\u001b[1G98.4 MiB [======              ] 30% 0.8s\u001b[0K\u001b[1G98.4 MiB [=======             ] 32% 0.8s\u001b[0K\u001b[1G98.4 MiB [=======             ] 33% 0.8s\u001b[0K\u001b[1G98.4 MiB [=======             ] 35% 0.7s\u001b[0K\u001b[1G98.4 MiB [========            ] 37% 0.7s\u001b[0K\u001b[1G98.4 MiB [========            ] 38% 0.7s\u001b[0K\u001b[1G98.4 MiB [========            ] 40% 0.7s\u001b[0K\u001b[1G98.4 MiB [========            ] 42% 0.6s\u001b[0K\u001b[1G98.4 MiB [=========           ] 44% 0.6s\u001b[0K\u001b[1G98.4 MiB [=========           ] 46% 0.6s\u001b[0K\u001b[1G98.4 MiB [==========          ] 48% 0.6s\u001b[0K\u001b[1G98.4 MiB [==========          ] 51% 0.5s\u001b[0K\u001b[1G98.4 MiB [===========         ] 52% 0.5s\u001b[0K\u001b[1G98.4 MiB [===========         ] 54% 0.5s\u001b[0K\u001b[1G98.4 MiB [===========         ] 55% 0.5s\u001b[0K\u001b[1G98.4 MiB [===========         ] 57% 0.5s\u001b[0K\u001b[1G98.4 MiB [============        ] 60% 0.4s\u001b[0K\u001b[1G98.4 MiB [============        ] 62% 0.4s\u001b[0K\u001b[1G98.4 MiB [=============       ] 64% 0.4s\u001b[0K\u001b[1G98.4 MiB [=============       ] 67% 0.3s\u001b[0K\u001b[1G98.4 MiB [==============      ] 69% 0.3s\u001b[0K\u001b[1G98.4 MiB [==============      ] 71% 0.3s\u001b[0K\u001b[1G98.4 MiB [===============     ] 72% 0.3s\u001b[0K\u001b[1G98.4 MiB [===============     ] 73% 0.3s\u001b[0K\u001b[1G98.4 MiB [===============     ] 75% 0.3s\u001b[0K\u001b[1G98.4 MiB [===============     ] 77% 0.2s\u001b[0K\u001b[1G98.4 MiB [================    ] 78% 0.2s\u001b[0K\u001b[1G98.4 MiB [================    ] 79% 0.2s\u001b[0K\u001b[1G98.4 MiB [================    ] 81% 0.2s\u001b[0K\u001b[1G98.4 MiB [=================   ] 83% 0.2s\u001b[0K\u001b[1G98.4 MiB [=================   ] 84% 0.2s\u001b[0K\u001b[1G98.4 MiB [=================   ] 87% 0.1s\u001b[0K\u001b[1G98.4 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G98.4 MiB [==================  ] 91% 0.1s\u001b[0K\u001b[1G98.4 MiB [=================== ] 93% 0.1s\u001b[0K\u001b[1G98.4 MiB [=================== ] 95% 0.0s\u001b[0K\u001b[1G98.4 MiB [====================] 97% 0.0s\u001b[0K\u001b[1G98.4 MiB [====================] 98% 0.0s\u001b[0K\u001b[1G98.4 MiB [====================] 100% 0.0s\u001b[0K\nFirefox 144.0.2 (playwright build v1497) downloaded to /root/.cache/ms-playwright/firefox-1497\nDownloading Webkit 26.0 (playwright build v2227)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2227/webkit-ubuntu-22.04.zip\u001b[22m\n(node:3190) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\u001b[1G96.1 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G96.1 MiB [                    ] 0% 8.3s\u001b[0K\u001b[1G96.1 MiB [                    ] 0% 4.1s\u001b[0K\u001b[1G96.1 MiB [                    ] 2% 2.3s\u001b[0K\u001b[1G96.1 MiB [=                   ] 3% 1.7s\u001b[0K\u001b[1G96.1 MiB [=                   ] 5% 1.5s\u001b[0K\u001b[1G96.1 MiB [=                   ] 6% 1.3s\u001b[0K\u001b[1G96.1 MiB [=                   ] 7% 1.5s\u001b[0K\u001b[1G96.1 MiB [==                  ] 8% 1.4s\u001b[0K\u001b[1G96.1 MiB [==                  ] 9% 1.4s\u001b[0K\u001b[1G96.1 MiB [==                  ] 11% 1.3s\u001b[0K\u001b[1G96.1 MiB [===                 ] 13% 1.2s\u001b[0K\u001b[1G96.1 MiB [===                 ] 14% 1.1s\u001b[0K\u001b[1G96.1 MiB [===                 ] 16% 1.1s\u001b[0K\u001b[1G96.1 MiB [====                ] 18% 1.0s\u001b[0K\u001b[1G96.1 MiB [====                ] 20% 0.9s\u001b[0K\u001b[1G96.1 MiB [====                ] 22% 0.9s\u001b[0K\u001b[1G96.1 MiB [=====               ] 24% 0.9s\u001b[0K\u001b[1G96.1 MiB [=====               ] 26% 0.8s\u001b[0K\u001b[1G96.1 MiB [======              ] 28% 0.8s\u001b[0K\u001b[1G96.1 MiB [======              ] 31% 0.7s\u001b[0K\u001b[1G96.1 MiB [=======             ] 33% 0.7s\u001b[0K\u001b[1G96.1 MiB [=======             ] 36% 0.6s\u001b[0K\u001b[1G96.1 MiB [========            ] 39% 0.6s\u001b[0K\u001b[1G96.1 MiB [=========           ] 42% 0.5s\u001b[0K\u001b[1G96.1 MiB [=========           ] 45% 0.5s\u001b[0K\u001b[1G96.1 MiB [==========          ] 48% 0.5s\u001b[0K\u001b[1G96.1 MiB [==========          ] 49% 0.4s\u001b[0K\u001b[1G96.1 MiB [===========         ] 54% 0.4s\u001b[0K\u001b[1G96.1 MiB [============        ] 57% 0.3s\u001b[0K\u001b[1G96.1 MiB [============        ] 61% 0.3s\u001b[0K\u001b[1G96.1 MiB [=============       ] 64% 0.3s\u001b[0K\u001b[1G96.1 MiB [=============       ] 67% 0.3s\u001b[0K\u001b[1G96.1 MiB [==============      ] 70% 0.2s\u001b[0K\u001b[1G96.1 MiB [===============     ] 74% 0.2s\u001b[0K\u001b[1G96.1 MiB [================    ] 78% 0.2s\u001b[0K\u001b[1G96.1 MiB [================    ] 82% 0.1s\u001b[0K\u001b[1G96.1 MiB [=================   ] 85% 0.1s\u001b[0K\u001b[1G96.1 MiB [==================  ] 88% 0.1s\u001b[0K\u001b[1G96.1 MiB [==================  ] 92% 0.1s\u001b[0K\u001b[1G96.1 MiB [=================== ] 96% 0.0s\u001b[0K\u001b[1G96.1 MiB [====================] 99% 0.0s\u001b[0K\u001b[1G96.1 MiB [====================] 100% 0.0s\u001b[0K\nWebkit 26.0 (playwright build v2227) downloaded to /root/.cache/ms-playwright/webkit-2227\nDownloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n(node:3201) [DEP0169] DeprecationWarning: `url.parse()` behavior is not standardized and prone to errors that have security implications. Use the WHATWG URL API instead. CVEs are not issued for `url.parse()` vulnerabilities.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\u001b[1G2.3 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [==                  ] 9% 0.1s\u001b[0K\u001b[1G2.3 MiB [========            ] 38% 0.1s\u001b[0K\u001b[1G2.3 MiB [=================== ] 96% 0.0s\u001b[0K\u001b[1G2.3 MiB [====================] 100% 0.0s\u001b[0K\nFFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\nPlaywright Host validation warning: \n╔══════════════════════════════════════════════════════╗\n║ Host system is missing dependencies to run browsers. ║\n║ Missing libraries:                                   ║\n║     libgtk-4.so.1                                    ║\n║     libgraphene-1.0.so.0                             ║\n║     libwoff2dec.so.1.0.2                             ║\n║     libgstgl-1.0.so.0                                ║\n║     libgstcodecparsers-1.0.so.0                      ║\n║     libavif.so.13                                    ║\n║     libharfbuzz-icu.so.0                             ║\n║     libenchant-2.so.2                                ║\n║     libsecret-1.so.0                                 ║\n║     libhyphen.so.0                                   ║\n║     libmanette-0.2.so.0                              ║\n╚══════════════════════════════════════════════════════╝\n    at validateDependenciesLinux (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:269:9)\n\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:103:5)\u001b[39m\n    at async Registry._validateHostRequirements (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:990:14)\n    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:1112:7)\n    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:1101:7)\n    at async r.<anonymous> (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/cli/program.js:176:7)\nInstalling dependencies...\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]                 \nGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,297 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]    \nGet:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,868 kB]           \nGet:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB] \nGet:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]       \nGet:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                          \nGet:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]              \nGet:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,607 kB]                      \nGet:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [60.9 kB]         \nGet:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]        \nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]          \nGet:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]   \nGet:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,637 kB]              \nGet:21 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [44.9 kB]\nGet:22 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.1 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,600 kB]         \nGet:24 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,968 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\nGet:27 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\nFetched 38.8 MB in 3s (11.9 MB/s)                            \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nfonts-liberation is already the newest version (1:1.07.4-11).\nlibasound2 is already the newest version (1.2.6.1-1ubuntu1).\nlibasound2 set to manually installed.\nlibatk-bridge2.0-0 is already the newest version (2.38.0-3).\nlibatk-bridge2.0-0 set to manually installed.\nlibatk1.0-0 is already the newest version (2.36.0-3build1).\nlibatk1.0-0 set to manually installed.\nlibatspi2.0-0 is already the newest version (2.44.0-3).\nlibatspi2.0-0 set to manually installed.\nlibcairo-gobject2 is already the newest version (1.16.0-5ubuntu2).\nlibcairo-gobject2 set to manually installed.\nlibcairo2 is already the newest version (1.16.0-5ubuntu2).\nlibcairo2 set to manually installed.\nlibegl1 is already the newest version (1.4.0-1).\nlibepoxy0 is already the newest version (1.5.10-1).\nlibepoxy0 set to manually installed.\nlibevent-2.1-7 is already the newest version (2.1.12-stable-1build3).\nlibevent-2.1-7 set to manually installed.\nlibfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\nlibgles2 is already the newest version (1.4.0-1).\nlibglx0 is already the newest version (1.4.0-1).\nlibglx0 set to manually installed.\nlibicu70 is already the newest version (70.1-2).\nlibicu70 set to manually installed.\nlibjpeg-turbo8 is already the newest version (2.1.2-0ubuntu1).\nlibjpeg-turbo8 set to manually installed.\nliblcms2-2 is already the newest version (2.12~rc1-2build2).\nliblcms2-2 set to manually installed.\nlibopengl0 is already the newest version (1.4.0-1).\nlibopus0 is already the newest version (1.3.1-0.1build2).\nlibopus0 set to manually installed.\nlibxcb-shm0 is already the newest version (1.14-3ubuntu3).\nlibxcb-shm0 set to manually installed.\nlibxcb1 is already the newest version (1.14-3ubuntu3).\nlibxcb1 set to manually installed.\nlibxcomposite1 is already the newest version (1:0.4.5-1build2).\nlibxcomposite1 set to manually installed.\nlibxcursor1 is already the newest version (1:1.2.0-2build4).\nlibxcursor1 set to manually installed.\nlibxdamage1 is already the newest version (1:1.1.5-2build2).\nlibxdamage1 set to manually installed.\nlibxext6 is already the newest version (2:1.3.4-1build1).\nlibxfixes3 is already the newest version (1:6.0.0-1).\nlibxfixes3 set to manually installed.\nlibxi6 is already the newest version (2:1.8-1build1).\nlibxi6 set to manually installed.\nlibxkbcommon0 is already the newest version (1.4.0-1).\nlibxkbcommon0 set to manually installed.\nlibxrandr2 is already the newest version (2:1.5.2-1build1).\nlibxrandr2 set to manually installed.\nlibxrender1 is already the newest version (1:0.9.10-1build4).\nlibx264-163 is already the newest version (2:0.163.3060+git5db6aa6-2build1).\nlibx264-163 set to manually installed.\nlibdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\nlibdbus-1-3 set to manually installed.\nlibdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\nlibdrm2 set to manually installed.\nlibgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\nlibgbm1 set to manually installed.\nlibgtk-3-0 is already the newest version (3.24.33-1ubuntu2.2).\nlibgtk-3-0 set to manually installed.\nlibnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\nlibnspr4 set to manually installed.\nlibnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\nlibnss3 set to manually installed.\nlibpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\nlibpango-1.0-0 set to manually installed.\nlibpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\nlibpangocairo-1.0-0 set to manually installed.\nlibwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\nlibwayland-client0 set to manually installed.\nlibwayland-egl1 is already the newest version (1.20.0-1ubuntu0.1).\nlibwayland-egl1 set to manually installed.\nlibwayland-server0 is already the newest version (1.20.0-1ubuntu0.1).\nlibwayland-server0 set to manually installed.\nlibwebpdemux2 is already the newest version (1.2.2-2ubuntu0.22.04.2).\nlibx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\nlibx11-6 set to manually installed.\nlibx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\nlibx11-xcb1 set to manually installed.\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\nThe following additional packages will be installed:\n  dictionaries-common gcc-12-base gir1.2-gdkpixbuf-2.0 glib-networking glib-networking-common\n  glib-networking-services gsettings-desktop-schemas hunspell-en-us lib32gcc-s1 lib32stdc++6 libaa1\n  libabsl20210324 libaspell15 libcc1-0 libcdparanoia0 libdca0 libdv4 libdvdnav4 libdvdread8\n  libfaad2 libfluidsynth3 libfreeaptx0 libfreetype-dev libfreetype6-dev libgav1-0 libgcc-s1\n  libgdk-pixbuf-2.0-dev libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common libgfortran5 libglib2.0-bin\n  libglib2.0-dev libglib2.0-dev-bin libgomp1 libgraphene-1.0-0 libgssdp-1.2-0\n  libgstreamer-plugins-bad1.0-0 libgstreamer-plugins-good1.0-0 libgtk-4-common libgupnp-1.2-1\n  libgupnp-igd-1.0-4 libhunspell-1.7-0 libinstpatch-1.0-2 libitm1 libjson-glib-1.0-0\n  libjson-glib-1.0-common libkate1 libldacbt-enc2 liblsan0 libltc11 libmjpegutils-2.1-0 libmodplug1\n  libmpcdec6 libmpeg2encpp-2.1-0 libmplex2-2.1-0 libnice10 libobjc4 libopenh264-6 libopenjp2-7-dev\n  libopenni2-0 libpng-dev libqrencode4 libquadmath0 libsbc1 libsecret-common libshout3\n  libsoundtouch1 libsoup-3.0-common libsoup2.4-1 libsoup2.4-common libspandsp2 libsrtp2-1\n  libstdc++6 libtag1v5 libtag1v5-vanilla libtext-iconv-perl libubsan1 libv4l-0 libv4lconvert0\n  libvisual-0.4-0 libvo-aacenc0 libvo-amrwbenc0 libwavpack1 libwebrtc-audio-processing1\n  libwildmidi2 libxml2-dev libyuv0 libzbar0 libzxingcore1 session-migration timgm6mb-soundfont\n  xserver-common\nSuggested packages:\n  ispell | aspell | hunspell wordlist frei0r-plugins gvfs hunspell openoffice.org-hunspell\n  | openoffice.org-core aspell cups-common libdv-bin oss-compat libdvdcss2 libenchant-2-voikko\n  freetype2-doc libgirepository1.0-dev libglib2.0-doc libxml2-utils libvisual-0.4-plugins\n  gstreamer1.0-tools libgtk-4-media-gstreamer | libgtk-4-media-ffmpeg gnome-shell\n  | notification-daemon libwildmidi-config fluid-soundfont-gm\nRecommended packages:\n  fonts-ipafont-mincho fonts-tlwg-loma gstreamer1.0-x aspell-en | aspell-dictionary\n  | aspell6a-dictionary enchant-2 xdg-user-dirs gstreamer1.0-gl libgtk-4-bin libpng-tools\nThe following NEW packages will be installed:\n  dictionaries-common fonts-freefont-ttf fonts-ipafont-gothic fonts-noto-color-emoji\n  fonts-tlwg-loma-otf fonts-unifont fonts-wqy-zenhei glib-networking glib-networking-common\n  glib-networking-services gsettings-desktop-schemas gstreamer1.0-libav gstreamer1.0-plugins-bad\n  gstreamer1.0-plugins-base gstreamer1.0-plugins-good hunspell-en-us libaa1 libabsl20210324\n  libaspell15 libavif13 libcdparanoia0 libdbus-glib-1-2 libdca0 libdv4 libdvdnav4 libdvdread8\n  libenchant-2-2 libevdev2 libfaad2 libffi7 libfluidsynth3 libfreeaptx0 libgav1-0 libgraphene-1.0-0\n  libgssdp-1.2-0 libgstreamer-gl1.0-0 libgstreamer-plugins-bad1.0-0 libgstreamer-plugins-good1.0-0\n  libgtk-4-1 libgtk-4-common libgudev-1.0-0 libgupnp-1.2-1 libgupnp-igd-1.0-4 libharfbuzz-icu0\n  libhunspell-1.7-0 libhyphen0 libinstpatch-1.0-2 libjson-glib-1.0-0 libjson-glib-1.0-common\n  libkate1 libldacbt-enc2 libltc11 libmanette-0.2-0 libmjpegutils-2.1-0 libmodplug1 libmpcdec6\n  libmpeg2encpp-2.1-0 libmplex2-2.1-0 libnice10 libnotify4 libopenh264-6 libopenni2-0 libproxy1v5\n  libqrencode4 libsbc1 libsecret-1-0 libsecret-common libshout3 libsoundtouch1 libsoup-3.0-0\n  libsoup-3.0-common libsoup2.4-1 libsoup2.4-common libspandsp2 libsrtp2-1 libtag1v5\n  libtag1v5-vanilla libtext-iconv-perl libv4l-0 libv4lconvert0 libvisual-0.4-0 libvo-aacenc0\n  libvo-amrwbenc0 libwavpack1 libwebrtc-audio-processing1 libwildmidi2 libwoff1 libxtst6 libyuv0\n  libzbar0 libzxingcore1 session-migration timgm6mb-soundfont xfonts-cyrillic xfonts-scalable\nThe following packages will be upgraded:\n  gcc-12-base gir1.2-gdkpixbuf-2.0 lib32gcc-s1 lib32stdc++6 libatomic1 libcc1-0 libcups2\n  libfreetype-dev libfreetype6 libfreetype6-dev libgcc-s1 libgdk-pixbuf-2.0-0 libgdk-pixbuf-2.0-dev\n  libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common libgfortran5 libglib2.0-0 libglib2.0-bin\n  libglib2.0-dev libglib2.0-dev-bin libgomp1 libgstreamer-plugins-base1.0-0 libgstreamer1.0-0\n  libharfbuzz0b libitm1 liblsan0 libobjc4 libopenjp2-7 libopenjp2-7-dev libpng-dev libpng16-16\n  libquadmath0 libstdc++6 libubsan1 libxml2 libxml2-dev libxslt1.1 xserver-common xvfb\n39 upgraded, 95 newly installed, 0 to remove and 333 not upgraded.\nNeed to get 66.4 MB of archives.\nAfter this operation, 133 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ipafont-gothic all 00303-21ubuntu1 [3,513 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 lib32gcc-s1 amd64 12.3.0-1ubuntu1~22.04.2 [63.9 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libubsan1 amd64 12.3.0-1ubuntu1~22.04.2 [976 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12-base amd64 12.3.0-1ubuntu1~22.04.2 [20.6 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libstdc++6 amd64 12.3.0-1ubuntu1~22.04.2 [699 kB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libquadmath0 amd64 12.3.0-1ubuntu1~22.04.2 [154 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libobjc4 amd64 12.3.0-1ubuntu1~22.04.2 [48.7 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 liblsan0 amd64 12.3.0-1ubuntu1~22.04.2 [1,069 kB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libitm1 amd64 12.3.0-1ubuntu1~22.04.2 [30.2 kB]\nGet:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgomp1 amd64 12.3.0-1ubuntu1~22.04.2 [127 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgfortran5 amd64 12.3.0-1ubuntu1~22.04.2 [879 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcc1-0 amd64 12.3.0-1ubuntu1~22.04.2 [48.3 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libatomic1 amd64 12.3.0-1ubuntu1~22.04.2 [10.4 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 lib32stdc++6 amd64 12.3.0-1ubuntu1~22.04.2 [739 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-s1 amd64 12.3.0-1ubuntu1~22.04.2 [53.9 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev amd64 2.72.4-0ubuntu2.7 [1,742 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev-bin amd64 2.72.4-0ubuntu2.7 [117 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-bin amd64 2.72.4-0ubuntu2.7 [80.9 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.7 [1,467 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtext-iconv-perl amd64 1.7-7build3 [14.3 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxml2-dev amd64 2.9.13+dfsg-1ubuntu0.10 [804 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxml2 amd64 2.9.13+dfsg-1ubuntu0.10 [764 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpng-dev amd64 1.6.37-3ubuntu0.3 [193 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpng16-16 amd64 1.6.37-3ubuntu0.3 [192 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 dictionaries-common all 1.28.14 [185 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\nGet:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.047-0ubuntu0.22.04.1 [10.0 MB]\nGet:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-tlwg-loma-otf all 1:0.7.3-1 [107 kB]\nGet:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-unifont all 1:14.0.01-1 [3,551 kB]\nGet:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-wqy-zenhei all 0.9.45-8 [7,472 kB]\nGet:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgdk-pixbuf2.0-common all 2.42.8+dfsg-1ubuntu0.4 [5,546 B]\nGet:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgdk-pixbuf-2.0-dev amd64 2.42.8+dfsg-1ubuntu0.4 [47.8 kB]\nGet:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgdk-pixbuf-2.0-0 amd64 2.42.8+dfsg-1ubuntu0.4 [148 kB]\nGet:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgdk-pixbuf2.0-bin amd64 2.42.8+dfsg-1ubuntu0.4 [14.1 kB]\nGet:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gir1.2-gdkpixbuf-2.0 amd64 2.42.8+dfsg-1ubuntu0.4 [9,494 B]\nGet:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\nGet:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\nGet:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\nGet:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\nGet:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\nGet:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\nGet:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgstreamer1.0-0 amd64 1.20.3-0ubuntu1.1 [984 kB]\nGet:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgstreamer-plugins-base1.0-0 amd64 1.20.1-1ubuntu0.5 [848 kB]\nGet:44 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 gstreamer1.0-libav amd64 1.20.3-0ubuntu1 [103 kB]\nGet:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcdparanoia0 amd64 3.10.2+debian-14build2 [49.3 kB]\nGet:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvisual-0.4-0 amd64 0.4.0-17build2 [108 kB]\nGet:47 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gstreamer1.0-plugins-base amd64 1.20.1-1ubuntu0.5 [712 kB]\nGet:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 libaa1 amd64 1.4p5-50build1 [51.9 kB]\nGet:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdv4 amd64 1.0.0-14build1 [61.9 kB]\nGet:50 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgstreamer-plugins-good1.0-0 amd64 1.20.3-0ubuntu1.4 [30.2 kB]\nGet:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\nGet:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 libshout3 amd64 2.4.5-1build3 [54.5 kB]\nGet:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtag1v5-vanilla amd64 1.11.1+dfsg.1-3ubuntu3 [304 kB]\nGet:54 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtag1v5 amd64 1.11.1+dfsg.1-3ubuntu3 [11.5 kB]\nGet:55 http://archive.ubuntu.com/ubuntu jammy/main amd64 libv4lconvert0 amd64 1.22.1-2build1 [82.4 kB]\nGet:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libv4l-0 amd64 1.22.1-2build1 [44.9 kB]\nGet:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\nGet:58 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.6 [4,778 B]\nGet:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.6 [288 kB]\nGet:60 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gstreamer1.0-plugins-good amd64 1.20.3-0ubuntu1.4 [2,009 kB]\nGet:61 http://archive.ubuntu.com/ubuntu jammy/main amd64 hunspell-en-us all 1:2020.12.07-2 [280 kB]\nGet:62 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libabsl20210324 amd64 0~20210324.2-2ubuntu0.2 [386 kB]\nGet:63 http://archive.ubuntu.com/ubuntu jammy/main amd64 libaspell15 amd64 0.60.8-4build1 [325 kB]\nGet:64 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgav1-0 amd64 0.17.0-1build1 [336 kB]\nGet:65 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libyuv0 amd64 0.0~git20220104.b91df1a-2 [154 kB]\nGet:66 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libavif13 amd64 0.9.3-3 [69.5 kB]\nGet:67 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcups2 amd64 2.4.1op1-1ubuntu4.16 [264 kB]\nGet:68 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdbus-glib-1-2 amd64 0.112-2build1 [65.4 kB]\nGet:69 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdvdread8 amd64 6.1.2-1 [55.7 kB]\nGet:70 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdvdnav4 amd64 6.1.1-1 [39.3 kB]\nGet:71 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhunspell-1.7-0 amd64 1.7.0-4build1 [175 kB]\nGet:72 http://archive.ubuntu.com/ubuntu jammy/main amd64 libenchant-2-2 amd64 2.3.2-1ubuntu2 [50.9 kB]\nGet:73 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfaad2 amd64 2.10.0-2 [197 kB]\nGet:74 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libffi7 amd64 3.3-5ubuntu1 [19.9 kB]\nGet:75 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libinstpatch-1.0-2 amd64 1.1.6-1 [240 kB]\nGet:76 http://archive.ubuntu.com/ubuntu jammy/universe amd64 timgm6mb-soundfont all 1.3-5 [5,427 kB]\nGet:77 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfluidsynth3 amd64 2.2.5-1 [246 kB]\nGet:78 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfreeaptx0 amd64 0.1.1-1 [12.9 kB]\nGet:79 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libfreetype-dev amd64 2.11.1+dfsg-1ubuntu0.3 [555 kB]\nGet:80 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libfreetype6-dev amd64 2.11.1+dfsg-1ubuntu0.3 [8,298 B]\nGet:81 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libfreetype6 amd64 2.11.1+dfsg-1ubuntu0.3 [388 kB]\nGet:82 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgraphene-1.0-0 amd64 1.10.8-1 [48.2 kB]\nGet:83 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgssdp-1.2-0 amd64 1.4.0.1-2build1 [48.9 kB]\nGet:84 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgstreamer-gl1.0-0 amd64 1.20.1-1ubuntu0.5 [204 kB]\nGet:85 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libharfbuzz0b amd64 2.7.4-1ubuntu3.2 [353 kB]\nGet:86 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-4-common all 4.6.9+ds-0ubuntu0.22.04.2 [662 kB]\nGet:87 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-4-1 amd64 4.6.9+ds-0ubuntu0.22.04.2 [2,866 kB]\nGet:88 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgupnp-1.2-1 amd64 1.4.3-1 [93.3 kB]\nGet:89 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgupnp-igd-1.0-4 amd64 1.2.0-1build1 [16.8 kB]\nGet:90 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libharfbuzz-icu0 amd64 2.7.4-1ubuntu3.2 [5,890 B]\nGet:91 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\nGet:92 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\nGet:93 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\nGet:94 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libkate1 amd64 0.4.1-11build1 [39.4 kB]\nGet:95 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libldacbt-enc2 amd64 2.0.2.3+git20200429+ed310a0-4 [24.6 kB]\nGet:96 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libltc11 amd64 1.3.1-1 [12.3 kB]\nGet:97 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\nGet:98 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmanette-0.2-0 amd64 0.2.6-3build1 [30.4 kB]\nGet:99 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmjpegutils-2.1-0 amd64 1:2.1.0+debian-6build1 [24.1 kB]\nGet:100 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmodplug1 amd64 1:0.8.9.0-3 [153 kB]\nGet:101 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpcdec6 amd64 2:0.1~r495-2 [32.4 kB]\nGet:102 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpeg2encpp-2.1-0 amd64 1:2.1.0+debian-6build1 [69.4 kB]\nGet:103 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmplex2-2.1-0 amd64 1:2.1.0+debian-6build1 [44.4 kB]\nGet:104 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnice10 amd64 0.1.18-2 [156 kB]\nGet:105 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\nGet:106 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenh264-6 amd64 2.2.0+dfsg-2 [407 kB]\nGet:107 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenni2-0 amd64 2.2.0.33+dfsg-15 [389 kB]\nGet:108 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqrencode4 amd64 4.1.1-1 [24.0 kB]\nGet:109 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsecret-common all 0.20.5-2 [4,278 B]\nGet:110 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsecret-1-0 amd64 0.20.5-2 [124 kB]\nGet:111 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsoundtouch1 amd64 2.3.1+ds1-1 [38.3 kB]\nGet:112 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsoup-3.0-common all 3.0.7-0ubuntu1 [62.1 kB]\nGet:113 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsoup-3.0-0 amd64 3.0.7-0ubuntu1 [278 kB]\nGet:114 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libspandsp2 amd64 0.0.6+dfsg-2 [272 kB]\nGet:115 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsrtp2-1 amd64 2.4.2-2 [40.7 kB]    \nGet:116 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwebrtc-audio-processing1 amd64 0.3.1-0ubuntu5 [291 kB]\nGet:117 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libwildmidi2 amd64 0.4.3-1 [59.9 kB]  \nGet:118 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]    \nGet:119 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxslt1.1 amd64 1.1.34-4ubuntu0.22.04.5 [165 kB]\nGet:120 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]  \nGet:121 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzbar0 amd64 0.23.92-4build2 [121 kB]\nGet:122 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzxingcore1 amd64 1.2.0-1 [619 kB]  \nGet:123 http://archive.ubuntu.com/ubuntu jammy/universe amd64 xfonts-cyrillic all 1:1.0.5 [386 kB]  \nGet:124 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-scalable all 1:1.0.3-1.2ubuntu1 [306 kB]\nGet:125 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.16 [29.5 kB]\nGet:126 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.16 [866 kB]\nGet:127 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdca0 amd64 0.0.7-2 [88.2 kB]       \nGet:128 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgstreamer-plugins-bad1.0-0 amd64 1.20.3-0ubuntu1.1 [489 kB]\nGet:129 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libopenjp2-7-dev amd64 2.4.0-6ubuntu0.4 [245 kB]\nGet:130 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libopenjp2-7 amd64 2.4.0-6ubuntu0.4 [158 kB]\nGet:131 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsbc1 amd64 1.5-3build2 [34.4 kB]       \nGet:132 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libvo-aacenc0 amd64 0.1.3-2 [69.4 kB] \nGet:133 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libvo-amrwbenc0 amd64 0.1.3-2 [68.2 kB]\nGet:134 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 gstreamer1.0-plugins-bad amd64 1.20.3-0ubuntu1.1 [2,602 kB]\nFetched 66.4 MB in 7s (10.0 MB/s)                                                                   \nExtracting templates from packages: 100%\nPreconfiguring packages ...\nSelecting previously unselected package fonts-ipafont-gothic.\n(Reading database ... 127400 files and directories currently installed.)\nPreparing to unpack .../fonts-ipafont-gothic_00303-21ubuntu1_all.deb ...\nUnpacking fonts-ipafont-gothic (00303-21ubuntu1) ...\nPreparing to unpack .../lib32gcc-s1_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking lib32gcc-s1 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../libubsan1_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libubsan1:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../gcc-12-base_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking gcc-12-base:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nSetting up gcc-12-base:amd64 (12.3.0-1ubuntu1~22.04.2) ...\n(Reading database ... 127409 files and directories currently installed.)\nPreparing to unpack .../libstdc++6_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libstdc++6:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nSetting up libstdc++6:amd64 (12.3.0-1ubuntu1~22.04.2) ...\n(Reading database ... 127409 files and directories currently installed.)\nPreparing to unpack .../0-libquadmath0_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libquadmath0:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../1-libobjc4_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libobjc4:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../2-liblsan0_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking liblsan0:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../3-libitm1_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libitm1:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../4-libgomp1_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libgomp1:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../5-libgfortran5_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libgfortran5:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../6-libcc1-0_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libcc1-0:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../7-libatomic1_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libatomic1:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../8-lib32stdc++6_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking lib32stdc++6 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nPreparing to unpack .../9-libgcc-s1_12.3.0-1ubuntu1~22.04.2_amd64.deb ...\nUnpacking libgcc-s1:amd64 (12.3.0-1ubuntu1~22.04.2) over (12.3.0-1ubuntu1~22.04) ...\nSetting up libgcc-s1:amd64 (12.3.0-1ubuntu1~22.04.2) ...\n(Reading database ... 127409 files and directories currently installed.)\nPreparing to unpack .../000-libglib2.0-dev_2.72.4-0ubuntu2.7_amd64.deb ...\nUnpacking libglib2.0-dev:amd64 (2.72.4-0ubuntu2.7) over (2.72.4-0ubuntu2.4) ...\nPreparing to unpack .../001-libglib2.0-dev-bin_2.72.4-0ubuntu2.7_amd64.deb ...\nUnpacking libglib2.0-dev-bin (2.72.4-0ubuntu2.7) over (2.72.4-0ubuntu2.4) ...\nPreparing to unpack .../002-libglib2.0-bin_2.72.4-0ubuntu2.7_amd64.deb ...\nUnpacking libglib2.0-bin (2.72.4-0ubuntu2.7) over (2.72.4-0ubuntu2.4) ...\nPreparing to unpack .../003-libglib2.0-0_2.72.4-0ubuntu2.7_amd64.deb ...\nUnpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.7) over (2.72.4-0ubuntu2.4) ...\nSelecting previously unselected package libtext-iconv-perl.\nPreparing to unpack .../004-libtext-iconv-perl_1.7-7build3_amd64.deb ...\nUnpacking libtext-iconv-perl (1.7-7build3) ...\nPreparing to unpack .../005-libxml2-dev_2.9.13+dfsg-1ubuntu0.10_amd64.deb ...\nUnpacking libxml2-dev:amd64 (2.9.13+dfsg-1ubuntu0.10) over (2.9.13+dfsg-1ubuntu0.4) ...\nPreparing to unpack .../006-libxml2_2.9.13+dfsg-1ubuntu0.10_amd64.deb ...\nUnpacking libxml2:amd64 (2.9.13+dfsg-1ubuntu0.10) over (2.9.13+dfsg-1ubuntu0.4) ...\nPreparing to unpack .../007-libpng-dev_1.6.37-3ubuntu0.3_amd64.deb ...\nUnpacking libpng-dev:amd64 (1.6.37-3ubuntu0.3) over (1.6.37-3build5) ...\nPreparing to unpack .../008-libpng16-16_1.6.37-3ubuntu0.3_amd64.deb ...\nUnpacking libpng16-16:amd64 (1.6.37-3ubuntu0.3) over (1.6.37-3build5) ...\nSelecting previously unselected package dictionaries-common.\nPreparing to unpack .../009-dictionaries-common_1.28.14_all.deb ...\nAdding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\nUnpacking dictionaries-common (1.28.14) ...\nSelecting previously unselected package fonts-freefont-ttf.\nPreparing to unpack .../010-fonts-freefont-ttf_20120503-10build1_all.deb ...\nUnpacking fonts-freefont-ttf (20120503-10build1) ...\nSelecting previously unselected package fonts-noto-color-emoji.\nPreparing to unpack .../011-fonts-noto-color-emoji_2.047-0ubuntu0.22.04.1_all.deb ...\nUnpacking fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\nSelecting previously unselected package fonts-tlwg-loma-otf.\nPreparing to unpack .../012-fonts-tlwg-loma-otf_1%3a0.7.3-1_all.deb ...\nUnpacking fonts-tlwg-loma-otf (1:0.7.3-1) ...\nSelecting previously unselected package fonts-unifont.\nPreparing to unpack .../013-fonts-unifont_1%3a14.0.01-1_all.deb ...\nUnpacking fonts-unifont (1:14.0.01-1) ...\nSelecting previously unselected package fonts-wqy-zenhei.\nPreparing to unpack .../014-fonts-wqy-zenhei_0.9.45-8_all.deb ...\nUnpacking fonts-wqy-zenhei (0.9.45-8) ...\nPreparing to unpack .../015-libgdk-pixbuf2.0-common_2.42.8+dfsg-1ubuntu0.4_all.deb ...\nUnpacking libgdk-pixbuf2.0-common (2.42.8+dfsg-1ubuntu0.4) over (2.42.8+dfsg-1ubuntu0.3) ...\nPreparing to unpack .../016-libgdk-pixbuf-2.0-dev_2.42.8+dfsg-1ubuntu0.4_amd64.deb ...\nUnpacking libgdk-pixbuf-2.0-dev:amd64 (2.42.8+dfsg-1ubuntu0.4) over (2.42.8+dfsg-1ubuntu0.3) ...\nPreparing to unpack .../017-libgdk-pixbuf-2.0-0_2.42.8+dfsg-1ubuntu0.4_amd64.deb ...\nUnpacking libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) over (2.42.8+dfsg-1ubuntu0.3) ...\nPreparing to unpack .../018-libgdk-pixbuf2.0-bin_2.42.8+dfsg-1ubuntu0.4_amd64.deb ...\nUnpacking libgdk-pixbuf2.0-bin (2.42.8+dfsg-1ubuntu0.4) over (2.42.8+dfsg-1ubuntu0.3) ...\nPreparing to unpack .../019-gir1.2-gdkpixbuf-2.0_2.42.8+dfsg-1ubuntu0.4_amd64.deb ...\nUnpacking gir1.2-gdkpixbuf-2.0:amd64 (2.42.8+dfsg-1ubuntu0.4) over (2.42.8+dfsg-1ubuntu0.3) ...\nSelecting previously unselected package libproxy1v5:amd64.\nPreparing to unpack .../020-libproxy1v5_0.4.17-2_amd64.deb ...\nUnpacking libproxy1v5:amd64 (0.4.17-2) ...\nSelecting previously unselected package glib-networking-common.\nPreparing to unpack .../021-glib-networking-common_2.72.0-1_all.deb ...\nUnpacking glib-networking-common (2.72.0-1) ...\nSelecting previously unselected package glib-networking-services.\nPreparing to unpack .../022-glib-networking-services_2.72.0-1_amd64.deb ...\nUnpacking glib-networking-services (2.72.0-1) ...\nSelecting previously unselected package session-migration.\nPreparing to unpack .../023-session-migration_0.3.6_amd64.deb ...\nUnpacking session-migration (0.3.6) ...\nSelecting previously unselected package gsettings-desktop-schemas.\nPreparing to unpack .../024-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\nUnpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\nSelecting previously unselected package glib-networking:amd64.\nPreparing to unpack .../025-glib-networking_2.72.0-1_amd64.deb ...\nUnpacking glib-networking:amd64 (2.72.0-1) ...\nPreparing to unpack .../026-libgstreamer1.0-0_1.20.3-0ubuntu1.1_amd64.deb ...\nUnpacking libgstreamer1.0-0:amd64 (1.20.3-0ubuntu1.1) over (1.20.3-0ubuntu1) ...\nPreparing to unpack .../027-libgstreamer-plugins-base1.0-0_1.20.1-1ubuntu0.5_amd64.deb ...\nUnpacking libgstreamer-plugins-base1.0-0:amd64 (1.20.1-1ubuntu0.5) over (1.20.1-1ubuntu0.2) ...\nSelecting previously unselected package gstreamer1.0-libav:amd64.\nPreparing to unpack .../028-gstreamer1.0-libav_1.20.3-0ubuntu1_amd64.deb ...\nUnpacking gstreamer1.0-libav:amd64 (1.20.3-0ubuntu1) ...\nSelecting previously unselected package libcdparanoia0:amd64.\nPreparing to unpack .../029-libcdparanoia0_3.10.2+debian-14build2_amd64.deb ...\nUnpacking libcdparanoia0:amd64 (3.10.2+debian-14build2) ...\nSelecting previously unselected package libvisual-0.4-0:amd64.\nPreparing to unpack .../030-libvisual-0.4-0_0.4.0-17build2_amd64.deb ...\nUnpacking libvisual-0.4-0:amd64 (0.4.0-17build2) ...\nSelecting previously unselected package gstreamer1.0-plugins-base:amd64.\nPreparing to unpack .../031-gstreamer1.0-plugins-base_1.20.1-1ubuntu0.5_amd64.deb ...\nUnpacking gstreamer1.0-plugins-base:amd64 (1.20.1-1ubuntu0.5) ...\nSelecting previously unselected package libaa1:amd64.\nPreparing to unpack .../032-libaa1_1.4p5-50build1_amd64.deb ...\nUnpacking libaa1:amd64 (1.4p5-50build1) ...\nSelecting previously unselected package libdv4:amd64.\nPreparing to unpack .../033-libdv4_1.0.0-14build1_amd64.deb ...\nUnpacking libdv4:amd64 (1.0.0-14build1) ...\nSelecting previously unselected package libgstreamer-plugins-good1.0-0:amd64.\nPreparing to unpack .../034-libgstreamer-plugins-good1.0-0_1.20.3-0ubuntu1.4_amd64.deb ...\nUnpacking libgstreamer-plugins-good1.0-0:amd64 (1.20.3-0ubuntu1.4) ...\nSelecting previously unselected package libgudev-1.0-0:amd64.\nPreparing to unpack .../035-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\nUnpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\nSelecting previously unselected package libshout3:amd64.\nPreparing to unpack .../036-libshout3_2.4.5-1build3_amd64.deb ...\nUnpacking libshout3:amd64 (2.4.5-1build3) ...\nSelecting previously unselected package libtag1v5-vanilla:amd64.\nPreparing to unpack .../037-libtag1v5-vanilla_1.11.1+dfsg.1-3ubuntu3_amd64.deb ...\nUnpacking libtag1v5-vanilla:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\nSelecting previously unselected package libtag1v5:amd64.\nPreparing to unpack .../038-libtag1v5_1.11.1+dfsg.1-3ubuntu3_amd64.deb ...\nUnpacking libtag1v5:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\nSelecting previously unselected package libv4lconvert0:amd64.\nPreparing to unpack .../039-libv4lconvert0_1.22.1-2build1_amd64.deb ...\nUnpacking libv4lconvert0:amd64 (1.22.1-2build1) ...\nSelecting previously unselected package libv4l-0:amd64.\nPreparing to unpack .../040-libv4l-0_1.22.1-2build1_amd64.deb ...\nUnpacking libv4l-0:amd64 (1.22.1-2build1) ...\nSelecting previously unselected package libwavpack1:amd64.\nPreparing to unpack .../041-libwavpack1_5.4.0-1build2_amd64.deb ...\nUnpacking libwavpack1:amd64 (5.4.0-1build2) ...\nSelecting previously unselected package libsoup2.4-common.\nPreparing to unpack .../042-libsoup2.4-common_2.74.2-3ubuntu0.6_all.deb ...\nUnpacking libsoup2.4-common (2.74.2-3ubuntu0.6) ...\nSelecting previously unselected package libsoup2.4-1:amd64.\nPreparing to unpack .../043-libsoup2.4-1_2.74.2-3ubuntu0.6_amd64.deb ...\nUnpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\nSelecting previously unselected package gstreamer1.0-plugins-good:amd64.\nPreparing to unpack .../044-gstreamer1.0-plugins-good_1.20.3-0ubuntu1.4_amd64.deb ...\nUnpacking gstreamer1.0-plugins-good:amd64 (1.20.3-0ubuntu1.4) ...\nSelecting previously unselected package hunspell-en-us.\nPreparing to unpack .../045-hunspell-en-us_1%3a2020.12.07-2_all.deb ...\nUnpacking hunspell-en-us (1:2020.12.07-2) ...\nSelecting previously unselected package libabsl20210324:amd64.\nPreparing to unpack .../046-libabsl20210324_0~20210324.2-2ubuntu0.2_amd64.deb ...\nUnpacking libabsl20210324:amd64 (0~20210324.2-2ubuntu0.2) ...\nSelecting previously unselected package libaspell15:amd64.\nPreparing to unpack .../047-libaspell15_0.60.8-4build1_amd64.deb ...\nUnpacking libaspell15:amd64 (0.60.8-4build1) ...\nSelecting previously unselected package libgav1-0:amd64.\nPreparing to unpack .../048-libgav1-0_0.17.0-1build1_amd64.deb ...\nUnpacking libgav1-0:amd64 (0.17.0-1build1) ...\nSelecting previously unselected package libyuv0:amd64.\nPreparing to unpack .../049-libyuv0_0.0~git20220104.b91df1a-2_amd64.deb ...\nUnpacking libyuv0:amd64 (0.0~git20220104.b91df1a-2) ...\nSelecting previously unselected package libavif13:amd64.\nPreparing to unpack .../050-libavif13_0.9.3-3_amd64.deb ...\nUnpacking libavif13:amd64 (0.9.3-3) ...\nPreparing to unpack .../051-libcups2_2.4.1op1-1ubuntu4.16_amd64.deb ...\nUnpacking libcups2:amd64 (2.4.1op1-1ubuntu4.16) over (2.4.1op1-1ubuntu4.11) ...\nSelecting previously unselected package libdbus-glib-1-2:amd64.\nPreparing to unpack .../052-libdbus-glib-1-2_0.112-2build1_amd64.deb ...\nUnpacking libdbus-glib-1-2:amd64 (0.112-2build1) ...\nSelecting previously unselected package libdvdread8:amd64.\nPreparing to unpack .../053-libdvdread8_6.1.2-1_amd64.deb ...\nUnpacking libdvdread8:amd64 (6.1.2-1) ...\nSelecting previously unselected package libdvdnav4:amd64.\nPreparing to unpack .../054-libdvdnav4_6.1.1-1_amd64.deb ...\nUnpacking libdvdnav4:amd64 (6.1.1-1) ...\nSelecting previously unselected package libhunspell-1.7-0:amd64.\nPreparing to unpack .../055-libhunspell-1.7-0_1.7.0-4build1_amd64.deb ...\nUnpacking libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\nSelecting previously unselected package libenchant-2-2:amd64.\nPreparing to unpack .../056-libenchant-2-2_2.3.2-1ubuntu2_amd64.deb ...\nUnpacking libenchant-2-2:amd64 (2.3.2-1ubuntu2) ...\nSelecting previously unselected package libfaad2:amd64.\nPreparing to unpack .../057-libfaad2_2.10.0-2_amd64.deb ...\nUnpacking libfaad2:amd64 (2.10.0-2) ...\nSelecting previously unselected package libffi7:amd64.\nPreparing to unpack .../058-libffi7_3.3-5ubuntu1_amd64.deb ...\nUnpacking libffi7:amd64 (3.3-5ubuntu1) ...\nSelecting previously unselected package libinstpatch-1.0-2:amd64.\nPreparing to unpack .../059-libinstpatch-1.0-2_1.1.6-1_amd64.deb ...\nUnpacking libinstpatch-1.0-2:amd64 (1.1.6-1) ...\nSelecting previously unselected package timgm6mb-soundfont.\nPreparing to unpack .../060-timgm6mb-soundfont_1.3-5_all.deb ...\nUnpacking timgm6mb-soundfont (1.3-5) ...\nSelecting previously unselected package libfluidsynth3:amd64.\nPreparing to unpack .../061-libfluidsynth3_2.2.5-1_amd64.deb ...\nUnpacking libfluidsynth3:amd64 (2.2.5-1) ...\nSelecting previously unselected package libfreeaptx0:amd64.\nPreparing to unpack .../062-libfreeaptx0_0.1.1-1_amd64.deb ...\nUnpacking libfreeaptx0:amd64 (0.1.1-1) ...\nPreparing to unpack .../063-libfreetype-dev_2.11.1+dfsg-1ubuntu0.3_amd64.deb ...\nUnpacking libfreetype-dev:amd64 (2.11.1+dfsg-1ubuntu0.3) over (2.11.1+dfsg-1ubuntu0.2) ...\nPreparing to unpack .../064-libfreetype6-dev_2.11.1+dfsg-1ubuntu0.3_amd64.deb ...\nUnpacking libfreetype6-dev:amd64 (2.11.1+dfsg-1ubuntu0.3) over (2.11.1+dfsg-1ubuntu0.2) ...\nPreparing to unpack .../065-libfreetype6_2.11.1+dfsg-1ubuntu0.3_amd64.deb ...\nUnpacking libfreetype6:amd64 (2.11.1+dfsg-1ubuntu0.3) over (2.11.1+dfsg-1ubuntu0.2) ...\nSelecting previously unselected package libgraphene-1.0-0:amd64.\nPreparing to unpack .../066-libgraphene-1.0-0_1.10.8-1_amd64.deb ...\nUnpacking libgraphene-1.0-0:amd64 (1.10.8-1) ...\nSelecting previously unselected package libgssdp-1.2-0:amd64.\nPreparing to unpack .../067-libgssdp-1.2-0_1.4.0.1-2build1_amd64.deb ...\nUnpacking libgssdp-1.2-0:amd64 (1.4.0.1-2build1) ...\nSelecting previously unselected package libgstreamer-gl1.0-0:amd64.\nPreparing to unpack .../068-libgstreamer-gl1.0-0_1.20.1-1ubuntu0.5_amd64.deb ...\nUnpacking libgstreamer-gl1.0-0:amd64 (1.20.1-1ubuntu0.5) ...\nPreparing to unpack .../069-libharfbuzz0b_2.7.4-1ubuntu3.2_amd64.deb ...\nUnpacking libharfbuzz0b:amd64 (2.7.4-1ubuntu3.2) over (2.7.4-1ubuntu3.1) ...\nSelecting previously unselected package libgtk-4-common.\nPreparing to unpack .../070-libgtk-4-common_4.6.9+ds-0ubuntu0.22.04.2_all.deb ...\nUnpacking libgtk-4-common (4.6.9+ds-0ubuntu0.22.04.2) ...\nSelecting previously unselected package libgtk-4-1:amd64.\nPreparing to unpack .../071-libgtk-4-1_4.6.9+ds-0ubuntu0.22.04.2_amd64.deb ...\nUnpacking libgtk-4-1:amd64 (4.6.9+ds-0ubuntu0.22.04.2) ...\nSelecting previously unselected package libgupnp-1.2-1:amd64.\nPreparing to unpack .../072-libgupnp-1.2-1_1.4.3-1_amd64.deb ...\nUnpacking libgupnp-1.2-1:amd64 (1.4.3-1) ...\nSelecting previously unselected package libgupnp-igd-1.0-4:amd64.\nPreparing to unpack .../073-libgupnp-igd-1.0-4_1.2.0-1build1_amd64.deb ...\nUnpacking libgupnp-igd-1.0-4:amd64 (1.2.0-1build1) ...\nSelecting previously unselected package libharfbuzz-icu0:amd64.\nPreparing to unpack .../074-libharfbuzz-icu0_2.7.4-1ubuntu3.2_amd64.deb ...\nUnpacking libharfbuzz-icu0:amd64 (2.7.4-1ubuntu3.2) ...\nSelecting previously unselected package libhyphen0:amd64.\nPreparing to unpack .../075-libhyphen0_2.8.8-7build2_amd64.deb ...\nUnpacking libhyphen0:amd64 (2.8.8-7build2) ...\nSelecting previously unselected package libjson-glib-1.0-common.\nPreparing to unpack .../076-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\nUnpacking libjson-glib-1.0-common (1.6.6-1build1) ...\nSelecting previously unselected package libjson-glib-1.0-0:amd64.\nPreparing to unpack .../077-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\nUnpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\nSelecting previously unselected package libkate1:amd64.\nPreparing to unpack .../078-libkate1_0.4.1-11build1_amd64.deb ...\nUnpacking libkate1:amd64 (0.4.1-11build1) ...\nSelecting previously unselected package libldacbt-enc2:amd64.\nPreparing to unpack .../079-libldacbt-enc2_2.0.2.3+git20200429+ed310a0-4_amd64.deb ...\nUnpacking libldacbt-enc2:amd64 (2.0.2.3+git20200429+ed310a0-4) ...\nSelecting previously unselected package libltc11:amd64.\nPreparing to unpack .../080-libltc11_1.3.1-1_amd64.deb ...\nUnpacking libltc11:amd64 (1.3.1-1) ...\nSelecting previously unselected package libevdev2:amd64.\nPreparing to unpack .../081-libevdev2_1.12.1+dfsg-1_amd64.deb ...\nUnpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\nSelecting previously unselected package libmanette-0.2-0:amd64.\nPreparing to unpack .../082-libmanette-0.2-0_0.2.6-3build1_amd64.deb ...\nUnpacking libmanette-0.2-0:amd64 (0.2.6-3build1) ...\nSelecting previously unselected package libmjpegutils-2.1-0:amd64.\nPreparing to unpack .../083-libmjpegutils-2.1-0_1%3a2.1.0+debian-6build1_amd64.deb ...\nUnpacking libmjpegutils-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\nSelecting previously unselected package libmodplug1:amd64.\nPreparing to unpack .../084-libmodplug1_1%3a0.8.9.0-3_amd64.deb ...\nUnpacking libmodplug1:amd64 (1:0.8.9.0-3) ...\nSelecting previously unselected package libmpcdec6:amd64.\nPreparing to unpack .../085-libmpcdec6_2%3a0.1~r495-2_amd64.deb ...\nUnpacking libmpcdec6:amd64 (2:0.1~r495-2) ...\nSelecting previously unselected package libmpeg2encpp-2.1-0:amd64.\nPreparing to unpack .../086-libmpeg2encpp-2.1-0_1%3a2.1.0+debian-6build1_amd64.deb ...\nUnpacking libmpeg2encpp-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\nSelecting previously unselected package libmplex2-2.1-0:amd64.\nPreparing to unpack .../087-libmplex2-2.1-0_1%3a2.1.0+debian-6build1_amd64.deb ...\nUnpacking libmplex2-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\nSelecting previously unselected package libnice10:amd64.\nPreparing to unpack .../088-libnice10_0.1.18-2_amd64.deb ...\nUnpacking libnice10:amd64 (0.1.18-2) ...\nSelecting previously unselected package libnotify4:amd64.\nPreparing to unpack .../089-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\nUnpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\nSelecting previously unselected package libopenh264-6:amd64.\nPreparing to unpack .../090-libopenh264-6_2.2.0+dfsg-2_amd64.deb ...\nUnpacking libopenh264-6:amd64 (2.2.0+dfsg-2) ...\nSelecting previously unselected package libopenni2-0:amd64.\nPreparing to unpack .../091-libopenni2-0_2.2.0.33+dfsg-15_amd64.deb ...\nUnpacking libopenni2-0:amd64 (2.2.0.33+dfsg-15) ...\nSelecting previously unselected package libqrencode4:amd64.\nPreparing to unpack .../092-libqrencode4_4.1.1-1_amd64.deb ...\nUnpacking libqrencode4:amd64 (4.1.1-1) ...\nSelecting previously unselected package libsecret-common.\nPreparing to unpack .../093-libsecret-common_0.20.5-2_all.deb ...\nUnpacking libsecret-common (0.20.5-2) ...\nSelecting previously unselected package libsecret-1-0:amd64.\nPreparing to unpack .../094-libsecret-1-0_0.20.5-2_amd64.deb ...\nUnpacking libsecret-1-0:amd64 (0.20.5-2) ...\nSelecting previously unselected package libsoundtouch1:amd64.\nPreparing to unpack .../095-libsoundtouch1_2.3.1+ds1-1_amd64.deb ...\nUnpacking libsoundtouch1:amd64 (2.3.1+ds1-1) ...\nSelecting previously unselected package libsoup-3.0-common.\nPreparing to unpack .../096-libsoup-3.0-common_3.0.7-0ubuntu1_all.deb ...\nUnpacking libsoup-3.0-common (3.0.7-0ubuntu1) ...\nSelecting previously unselected package libsoup-3.0-0:amd64.\nPreparing to unpack .../097-libsoup-3.0-0_3.0.7-0ubuntu1_amd64.deb ...\nUnpacking libsoup-3.0-0:amd64 (3.0.7-0ubuntu1) ...\nSelecting previously unselected package libspandsp2:amd64.\nPreparing to unpack .../098-libspandsp2_0.0.6+dfsg-2_amd64.deb ...\nUnpacking libspandsp2:amd64 (0.0.6+dfsg-2) ...\nSelecting previously unselected package libsrtp2-1:amd64.\nPreparing to unpack .../099-libsrtp2-1_2.4.2-2_amd64.deb ...\nUnpacking libsrtp2-1:amd64 (2.4.2-2) ...\nSelecting previously unselected package libwebrtc-audio-processing1:amd64.\nPreparing to unpack .../100-libwebrtc-audio-processing1_0.3.1-0ubuntu5_amd64.deb ...\nUnpacking libwebrtc-audio-processing1:amd64 (0.3.1-0ubuntu5) ...\nSelecting previously unselected package libwildmidi2:amd64.\nPreparing to unpack .../101-libwildmidi2_0.4.3-1_amd64.deb ...\nUnpacking libwildmidi2:amd64 (0.4.3-1) ...\nSelecting previously unselected package libwoff1:amd64.\nPreparing to unpack .../102-libwoff1_1.0.2-1build4_amd64.deb ...\nUnpacking libwoff1:amd64 (1.0.2-1build4) ...\nPreparing to unpack .../103-libxslt1.1_1.1.34-4ubuntu0.22.04.5_amd64.deb ...\nUnpacking libxslt1.1:amd64 (1.1.34-4ubuntu0.22.04.5) over (1.1.34-4ubuntu0.22.04.1) ...\nSelecting previously unselected package libxtst6:amd64.\nPreparing to unpack .../104-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\nUnpacking libxtst6:amd64 (2:1.2.3-1build4) ...\nSelecting previously unselected package libzbar0:amd64.\nPreparing to unpack .../105-libzbar0_0.23.92-4build2_amd64.deb ...\nUnpacking libzbar0:amd64 (0.23.92-4build2) ...\nSelecting previously unselected package libzxingcore1:amd64.\nPreparing to unpack .../106-libzxingcore1_1.2.0-1_amd64.deb ...\nUnpacking libzxingcore1:amd64 (1.2.0-1) ...\nSelecting previously unselected package xfonts-cyrillic.\nPreparing to unpack .../107-xfonts-cyrillic_1%3a1.0.5_all.deb ...\nUnpacking xfonts-cyrillic (1:1.0.5) ...\nSelecting previously unselected package xfonts-scalable.\nPreparing to unpack .../108-xfonts-scalable_1%3a1.0.3-1.2ubuntu1_all.deb ...\nUnpacking xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\nPreparing to unpack .../109-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.16_all.deb ...\nUnpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.16) over (2:21.1.4-2ubuntu1.7~22.04.12) ...\nPreparing to unpack .../110-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.16_amd64.deb ...\nUnpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.16) over (2:21.1.4-2ubuntu1.7~22.04.12) ...\nSelecting previously unselected package libdca0:amd64.\nPreparing to unpack .../111-libdca0_0.0.7-2_amd64.deb ...\nUnpacking libdca0:amd64 (0.0.7-2) ...\nSelecting previously unselected package libgstreamer-plugins-bad1.0-0:amd64.\nPreparing to unpack .../112-libgstreamer-plugins-bad1.0-0_1.20.3-0ubuntu1.1_amd64.deb ...\nUnpacking libgstreamer-plugins-bad1.0-0:amd64 (1.20.3-0ubuntu1.1) ...\nPreparing to unpack .../113-libopenjp2-7-dev_2.4.0-6ubuntu0.4_amd64.deb ...\nUnpacking libopenjp2-7-dev:amd64 (2.4.0-6ubuntu0.4) over (2.4.0-6ubuntu0.2) ...\nPreparing to unpack .../114-libopenjp2-7_2.4.0-6ubuntu0.4_amd64.deb ...\nUnpacking libopenjp2-7:amd64 (2.4.0-6ubuntu0.4) over (2.4.0-6ubuntu0.2) ...\nSelecting previously unselected package libsbc1:amd64.\nPreparing to unpack .../115-libsbc1_1.5-3build2_amd64.deb ...\nUnpacking libsbc1:amd64 (1.5-3build2) ...\nSelecting previously unselected package libvo-aacenc0:amd64.\nPreparing to unpack .../116-libvo-aacenc0_0.1.3-2_amd64.deb ...\nUnpacking libvo-aacenc0:amd64 (0.1.3-2) ...\nSelecting previously unselected package libvo-amrwbenc0:amd64.\nPreparing to unpack .../117-libvo-amrwbenc0_0.1.3-2_amd64.deb ...\nUnpacking libvo-amrwbenc0:amd64 (0.1.3-2) ...\nSelecting previously unselected package gstreamer1.0-plugins-bad:amd64.\nPreparing to unpack .../118-gstreamer1.0-plugins-bad_1.20.3-0ubuntu1.1_amd64.deb ...\nUnpacking gstreamer1.0-plugins-bad:amd64 (1.20.3-0ubuntu1.1) ...\nSetting up libtext-iconv-perl (1.7-7build3) ...\nSetting up libfreeaptx0:amd64 (0.1.1-1) ...\nSetting up libmodplug1:amd64 (1:0.8.9.0-3) ...\nSetting up libcdparanoia0:amd64 (3.10.2+debian-14build2) ...\nSetting up libvo-amrwbenc0:amd64 (0.1.3-2) ...\nSetting up libsbc1:amd64 (1.5-3build2) ...\nSetting up libproxy1v5:amd64 (0.4.17-2) ...\nSetting up libtag1v5-vanilla:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\nSetting up libkate1:amd64 (0.4.1-11build1) ...\nSetting up libopenni2-0:amd64 (2.2.0.33+dfsg-15) ...\nSetting up libwoff1:amd64 (1.0.2-1build4) ...\nSetting up libqrencode4:amd64 (4.1.1-1) ...\nSetting up libhyphen0:amd64 (2.8.8-7build2) ...\nSetting up dictionaries-common (1.28.14) ...\nSetting up fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\nSetting up libvisual-0.4-0:amd64 (0.4.0-17build2) ...\nSetting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.7) ...\nSetting up libaspell15:amd64 (0.60.8-4build1) ...\nSetting up libxtst6:amd64 (2:1.2.3-1build4) ...\nSetting up libsrtp2-1:amd64 (2.4.2-2) ...\nSetting up libgdk-pixbuf2.0-common (2.42.8+dfsg-1ubuntu0.4) ...\nSetting up libffi7:amd64 (3.3-5ubuntu1) ...\nSetting up libldacbt-enc2:amd64 (2.0.2.3+git20200429+ed310a0-4) ...\nSetting up fonts-wqy-zenhei (0.9.45-8) ...\nSetting up libwebrtc-audio-processing1:amd64 (0.3.1-0ubuntu5) ...\nSetting up fonts-freefont-ttf (20120503-10build1) ...\nSetting up libglib2.0-bin (2.72.4-0ubuntu2.7) ...\nSetting up libobjc4:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libsoup-3.0-common (3.0.7-0ubuntu1) ...\nSetting up libgomp1:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libmpcdec6:amd64 (2:0.1~r495-2) ...\nSetting up libspandsp2:amd64 (0.0.6+dfsg-2) ...\nSetting up libvo-aacenc0:amd64 (0.1.3-2) ...\nSetting up libsoundtouch1:amd64 (2.3.1+ds1-1) ...\nSetting up fonts-tlwg-loma-otf (1:0.7.3-1) ...\nSetting up libdvdread8:amd64 (6.1.2-1) ...\nSetting up lib32gcc-s1 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up lib32stdc++6 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libdbus-glib-1-2:amd64 (0.112-2build1) ...\nSetting up libquadmath0:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libfaad2:amd64 (2.10.0-2) ...\nSetting up libshout3:amd64 (2.4.5-1build3) ...\nSetting up libpng16-16:amd64 (1.6.37-3ubuntu0.3) ...\nSetting up libatomic1:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libabsl20210324:amd64 (0~20210324.2-2ubuntu0.2) ...\nSetting up libgfortran5:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libltc11:amd64 (1.3.1-1) ...\nSetting up libsoup2.4-common (2.74.2-3ubuntu0.6) ...\nSetting up libcups2:amd64 (2.4.1op1-1ubuntu4.16) ...\nSetting up libubsan1:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libtag1v5:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\nSetting up libdv4:amd64 (1.0.0-14build1) ...\nSetting up fonts-ipafont-gothic (00303-21ubuntu1) ...\nupdate-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\nSetting up libwildmidi2:amd64 (0.4.3-1) ...\nSetting up libopenh264-6:amd64 (2.2.0+dfsg-2) ...\nSetting up libwavpack1:amd64 (5.4.0-1build2) ...\nSetting up xfonts-cyrillic (1:1.0.5) ...\nSetting up libzxingcore1:amd64 (1.2.0-1) ...\nSetting up libv4lconvert0:amd64 (1.22.1-2build1) ...\nSetting up hunspell-en-us (1:2020.12.07-2) ...\nSetting up libdca0:amd64 (0.0.7-2) ...\nSetting up libopenjp2-7:amd64 (2.4.0-6ubuntu0.4) ...\nSetting up libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\nSetting up libjson-glib-1.0-common (1.6.6-1build1) ...\nSetting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.16) ...\nSetting up libgtk-4-common (4.6.9+ds-0ubuntu0.22.04.2) ...\nSetting up libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\nSetting up glib-networking-common (2.72.0-1) ...\nSetting up timgm6mb-soundfont (1.3-5) ...\nupdate-alternatives: using /usr/share/sounds/sf2/TimGM6mb.sf2 to provide /usr/share/sounds/sf2/default-GM.sf2 (default-GM.sf2) in auto mode\nupdate-alternatives: using /usr/share/sounds/sf2/TimGM6mb.sf2 to provide /usr/share/sounds/sf3/default-GM.sf3 (default-GM.sf3) in auto mode\nSetting up libyuv0:amd64 (0.0~git20220104.b91df1a-2) ...\nSetting up libevdev2:amd64 (1.12.1+dfsg-1) ...\nSetting up libxml2:amd64 (2.9.13+dfsg-1ubuntu0.10) ...\nSetting up libinstpatch-1.0-2:amd64 (1.1.6-1) ...\nSetting up libcc1-0:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libmjpegutils-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\nSetting up libgudev-1.0-0:amd64 (1:237-2build1) ...\nSetting up libsecret-common (0.20.5-2) ...\nSetting up liblsan0:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\nSetting up libgstreamer1.0-0:amd64 (1.20.3-0ubuntu1.1) ...\nSetcap worked! gst-ptp-helper is not suid!\nSetting up libgraphene-1.0-0:amd64 (1.10.8-1) ...\nSetting up libitm1:amd64 (12.3.0-1ubuntu1~22.04.2) ...\nSetting up libfluidsynth3:amd64 (2.2.5-1) ...\nSetting up libdvdnav4:amd64 (6.1.1-1) ...\nSetting up fonts-unifont (1:14.0.01-1) ...\nSetting up libaa1:amd64 (1.4p5-50build1) ...\nSetting up libglib2.0-dev-bin (2.72.4-0ubuntu2.7) ...\nSetting up glib-networking-services (2.72.0-1) ...\nSetting up session-migration (0.3.6) ...\nCreated symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\nSetting up gir1.2-gdkpixbuf-2.0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\nSetting up libenchant-2-2:amd64 (2.3.2-1ubuntu2) ...\nSetting up xvfb (2:21.1.4-2ubuntu1.7~22.04.16) ...\nSetting up libmanette-0.2-0:amd64 (0.2.6-3build1) ...\nSetting up libpng-dev:amd64 (1.6.37-3ubuntu0.3) ...\nSetting up libgstreamer-plugins-base1.0-0:amd64 (1.20.1-1ubuntu0.5) ...\nSetting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\nSetting up libv4l-0:amd64 (1.22.1-2build1) ...\nSetting up libgstreamer-plugins-bad1.0-0:amd64 (1.20.3-0ubuntu1.1) ...\nSetting up libxml2-dev:amd64 (2.9.13+dfsg-1ubuntu0.10) ...\nSetting up libsecret-1-0:amd64 (0.20.5-2) ...\nSetting up libgstreamer-plugins-good1.0-0:amd64 (1.20.3-0ubuntu1.4) ...\nSetting up libgstreamer-gl1.0-0:amd64 (1.20.1-1ubuntu0.5) ...\nSetting up gstreamer1.0-plugins-base:amd64 (1.20.1-1ubuntu0.5) ...\nSetting up libglib2.0-dev:amd64 (2.72.4-0ubuntu2.7) ...\nSetting up libfreetype6:amd64 (2.11.1+dfsg-1ubuntu0.3) ...\nSetting up libopenjp2-7-dev:amd64 (2.4.0-6ubuntu0.4) ...\nSetting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\nSetting up libgav1-0:amd64 (0.17.0-1build1) ...\nSetting up libmpeg2encpp-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\nSetting up libavif13:amd64 (0.9.3-3) ...\nSetting up libgdk-pixbuf2.0-bin (2.42.8+dfsg-1ubuntu0.4) ...\nSetting up libxslt1.1:amd64 (1.1.34-4ubuntu0.22.04.5) ...\nSetting up libharfbuzz0b:amd64 (2.7.4-1ubuntu3.2) ...\nSetting up libmplex2-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\nSetting up gstreamer1.0-libav:amd64 (1.20.3-0ubuntu1) ...\nSetting up libgdk-pixbuf-2.0-dev:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\nSetting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\nSetting up libharfbuzz-icu0:amd64 (2.7.4-1ubuntu3.2) ...\nSetting up libzbar0:amd64 (0.23.92-4build2) ...\nSetting up libfreetype-dev:amd64 (2.11.1+dfsg-1ubuntu0.3) ...\nSetting up libgtk-4-1:amd64 (4.6.9+ds-0ubuntu0.22.04.2) ...\nSetting up glib-networking:amd64 (2.72.0-1) ...\nSetting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\nSetting up gstreamer1.0-plugins-good:amd64 (1.20.3-0ubuntu1.4) ...\nSetting up libsoup-3.0-0:amd64 (3.0.7-0ubuntu1) ...\nSetting up libfreetype6-dev:amd64 (2.11.1+dfsg-1ubuntu0.3) ...\nSetting up libgssdp-1.2-0:amd64 (1.4.0.1-2build1) ...\nSetting up libgupnp-1.2-1:amd64 (1.4.3-1) ...\nSetting up libgupnp-igd-1.0-4:amd64 (1.2.0-1build1) ...\nSetting up libnice10:amd64 (0.1.18-2) ...\nSetting up gstreamer1.0-plugins-bad:amd64 (1.20.3-0ubuntu1.1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.4) ...\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\nProcessing triggers for dictionaries-common (1.28.14) ...\ndone!\n","output_type":"stream"}],"execution_count":142},{"cell_type":"code","source":"import pandas as pd\nfrom playwright.async_api import async_playwright\nimport asyncio\nasync def fetch(link):\n    async with async_playwright() as p:\n        browser=await p.chromium.launch(headless=True)\n        page=await browser.new_page()\n        await page.goto(link,wait_until=\"load\")\n        last=None\n        for _ in range(10):\n            await page.wait_for_load_state(\"networkidle\")\n            new=page.url\n            if new==last:\n                break\n            last=new\n        try:\n            await page.wait_for_selector(\"table\")\n        except Exception as e:\n            print(e)\n        html=await page.content()\n        await browser.close()\n        soup=BeautifulSoup(html)\n        return soup\nfrom playwright.async_api import async_playwright\nfrom bs4 import BeautifulSoup\nimport asyncio\n\n\n\nasync def fetchz(link, context):\n    page = await context.new_page()\n    await page.route(\"**/*\", lambda route: route.abort() if route.request.resource_type in [\"image\", \"stylesheet\", \"font\"] else route.continue_())\n    await page.goto(link, wait_until=\"domcontentloaded\",timeout=0)\n    last = None\n    for _ in range(10):\n        await page.wait_for_load_state(\"networkidle\")\n        new = page.url\n        if new == last:\n            break\n        last = new\n    try:\n        await page.wait_for_selector(\"table\",state=\"attached\")\n    except Exception as e:\n        print(e)\n    element = await page.query_selector(\"table\")\n    html = await element.inner_html()\n    soup = BeautifulSoup(html, \"html.parser\")\n    await page.close()\n    return soup\n\nasync def main(link):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True,args=[\"--disable-gpu\", \"--no-sandbox\"])\n        context = await browser.new_context()\n        result = await fetchz(link,context)\n        await browser.close()\n        return result\ndates={}\nimport nest_asyncio\nnest_asyncio.apply()\ndates=[]\narrw=[]\nfor i in range(2019,2027):\n    if i!=2020:\n        dates.append(i)\nfor s in dates:\n    print(s)\n    uk=int(s)-1\n    s=str(s)\n    nj=s.replace(\".0\",\"\")\n    s=s.replace(\".0\",\"\")\n    url='https://barttorvik.com/teamsheets.php?year='+str(s)\n    print(url)\n    loop = asyncio.get_event_loop()\n    table = loop.run_until_complete(main(url))\n    for tr in table.find_all(\"tr\"):\n        if \"AdjOE\" not in str(tr) and 'absolute error' not in str(tr) and 'RESUME' not in str(tr) and 'KPI' not in str(tr):\n            rowz=[]\n            n=0\n            for td in tr.find_all(\"td\"):\n                if 1==1:\n                    if int(s)<2024 and n==8:\n                        m=1\n                    elif int(s)==2025 and n==5:\n                        m=1\n                    elif int(s)==2025 and n==9:\n                        m=1\n                    elif int(s)==2026 and n==5:\n                        m=1\n                    elif int(s)==2026 and n==9:\n                        m=1\n                    elif n==1:\n                        fd=td.find_all(\"a\")[0].text\n                        fd=str(fd)\n                        if fd=='':\n                            print(tr.find_all(\"td\"))\n                        rowz.append(fd)\n                    else:\n                        rowz.append(td.text)\n                n+=1\n            rowz.append(uk)\n            arrw.append(rowz)\ndfe=pd.DataFrame(arrw)\ndfe.columns=['rk','team','net','kpi','sor','avg','bpi','kp','avgz','q1a','q1','q2','q12','q3','q4','season']\nfor i in range(2018,2027):\n    dfe=dfe[dfe.rk!=i]\ndfe=dfe.replace('\\xa0', ' ', regex=True)\nfor row in dfe.itertuples():\n    if \"   \" in str(row.team):\n        teamh=str(row.team).split(\"   \")[0]\n        dfe.at[row.Index,'team']=teamh\ndfe['team']=dfe['team'].str.replace(\" St.\",\" State\")\ndfe=dfe.replace(\"Albany\",\"Albany (NY)\")\ndfe=dfe.replace(\"BYU\",\"Brigham Young\")\ndfe=dfe.replace(\"Grambling State\",\"Grambling\")\ndfe=dfe.replace(\"VCU\",\"Virginia Commonwealth\")\ndfe=dfe.replace(\"Fairleigh Dickinson\",\"FDU\")\ndfe=dfe.replace(\"SIU Edwardsville\",\"Southern Illinois-Edwardsville\")\ndfe=dfe.replace(\"LIU\",\"Long Island University\")\ndfe=dfe.replace(\"Nebraska Omaha\",\"Omaha\")\ndfe=dfe.replace(\"UMBC\",\"Maryland-Baltimore County\")\ndfe=dfe.replace(\"Miami FL\",\"Miami (FL)\")\ndfe=dfe.replace(\"SMU\",\"Southern Methodist\")\ndfe=dfe.replace(\"Penn\",\"Pennsylvania\")\ndfe=dfe.replace(\"Arkansas Pine Bluff\",\"Arkansas-Pine Bluff\")\ndfe=dfe.replace(\"USC Upstate\",\"South Carolina Upstate\")\ndfe=dfe.replace(\"St. Francis NY\",\"St. Francis (NY)\")\ndfe=dfe.replace(\"UMKC\",\"Kansas City\")\ndfe=dfe.replace(\"Central Connecticut\",\"Central Connecticut State\")\ndfe=dfe.replace(\"Tennessee Martin\",\"Tennessee-Martin\")\ndfe=dfe.replace(\"Saint Francis\",\"Saint Francis (PA)\")\ndfe=dfe.replace(\"Illinois Chicago\",\"Illinois-Chicago\")\ndfe=dfe.replace(\"Bethune Cookman\",\"Bethune-Cookman\")\ndfe=dfe.replace(\"N.C. State\",\"NC State\")\ndfe=dfe.replace(\"Charleston\",\"College of Charleston\")\ndfe=dfe.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\ndfe=dfe.replace(\"Loyola Chicago\",\"Loyola (IL)\")\ndfe=dfe.replace(\"Louisiana Monroe\",\"Louisiana-Monroe\")\ndfe=dfe.replace(\"Southern Miss\",\"Southern Mississippi\")\ndfe=dfe.replace(\"Texas A&M Corpus Chris\",\"Texas A&M-Corpus Christi\")\ndfe=dfe.replace(\"Saint Mary's\",\"Saint Mary's (CA)\")\ndfe=dfe.replace(\"UT Rio Grande Valley\",\"Texas-Rio Grande Valley\")\ndfe=dfe.replace(\"Gardner Webb\",\"Gardner-Webb\")\ndfe=dfe.replace(\"LSU\",\"Louisiana State\")\ndfe=dfe.replace(\"Loyola MD\",\"Loyola (MD)\")\ndfe=dfe.replace(\"UMass Lowell\",\"Massachusetts-Lowell\")\ndfe=dfe.replace(\"UNLV\",\"Nevada-Las Vegas\")\ndfe=dfe.replace(\"USC\",\"Southern California\")\ndfe=dfe.replace(\"Sam Houston State\",\"Sam Houston\")\ndfe=dfe.replace(\"Prairie View A&M\",\"Prairie View\")\ndfe=dfe.replace(\"Miami OH\",\"Miami (OH)\")\ndfe=dfe.replace(\"VMI\",\"Virginia Military Institute\")\ndfe=dfe.replace(\"St. John's\",\"St. John's (NY)\")\ndfe=dfe.replace(\"FIU\",\"Florida International\")\ndfe=dfe.replace(\"Queens\",\"Queens (NC)\")\ndfe=dfe.replace(\"Cal Baptist\",\"California Baptist\")\ndfe=dfe.replace(\"Mount State Mary's\",\"Mount St. Mary's\")\nrez={}\ndfe=dfe.astype({\"net\":float,\"rk\":float,\"kpi\":float,\"sor\":float,\"bpi\":float,\"kp\":float})\nrez={}\nfor i in range(2017,2027):\n    rez[i]={}\nfor row in dfe.itertuples():\n    q1w=float(str(row.q1).split(\"-\")[0])\n    q1l=float(str(row.q1).split(\"-\")[1])\n    q2w=float(str(row.q2).split(\"-\")[0])\n    q2l=float(str(row.q2).split(\"-\")[1])\n    q3w=float(str(row.q3).split(\"-\")[0])\n    q3l=float(str(row.q3).split(\"-\")[1])\n    q4w=float(str(row.q4).split(\"-\")[0])\n    q4l=float(str(row.q4).split(\"-\")[1])\n    q1aw=float(str(row.q1a).split(\"-\")[0])\n    q1al=float(str(row.q1a).split(\"-\")[1])\n    tgz=q1w+q1l+q2w+q2l+q3w+q3l+q4w+q4l\n    w=q1w+q2w+q3w+q4w\n    rez[int(row.season)][row.team]={'resrk':row.rk,'net':row.net,'kpi':row.kpi,'sor':row.sor,'avg':row.avg,'bpi':row.bpi,'kp':row.kp,\n'avgz':row.avgz,'q1w':q1w,'q2w':q2w,'q3w':q3w,'q4w':q4w,'q1l':q1l,'q2l':q2l,'q3l':q3l,'q4l':q4l,'q1aw':q1aw,'q1al':q1al}\narrw=[]\n\nfrom playwright.async_api import async_playwright\nimport asyncio\nfrom sklearn.pipeline import Pipeline\n\nasync def fetch(link):\n    async with async_playwright() as p:\n        browser=await p.chromium.launch(headless=True)\n        page=await browser.new_page()\n        await page.goto(link,wait_until=\"load\")\n        last=None\n        for _ in range(10):\n            await page.wait_for_load_state(\"networkidle\")\n            new=page.url\n            if new==last:\n                break\n            last=new\n        try:\n            await page.wait_for_selector(\"table\")\n        except Exception as e:\n            print(e)\n        html=await page.content()\n        await browser.close()\n        soup=BeautifulSoup(html)\n        return soup\nfrom playwright.async_api import async_playwright\nfrom bs4 import BeautifulSoup\nimport asyncio\n\n\n\nasync def fetchz(link, context):\n    page = await context.new_page()\n    await page.route(\"**/*\", lambda route: route.abort() if route.request.resource_type in [\"image\", \"stylesheet\", \"font\"] else route.continue_())\n    await page.goto(link, wait_until=\"domcontentloaded\",timeout=0)\n    last = None\n    for _ in range(10):\n        await page.wait_for_load_state(\"networkidle\")\n        new = page.url\n        if new == last:\n            break\n        last = new\n    try:\n        await page.wait_for_selector(\"table\",state=\"attached\")\n    except Exception as e:\n        print(e)\n    element = await page.query_selector(\"table\")\n    html = await element.inner_html()\n    soup = BeautifulSoup(html, \"html.parser\")\n    await page.close()\n    return soup\n\nasync def main(link):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True,args=[\"--disable-gpu\", \"--no-sandbox\"])\n        context = await browser.new_context()\n        result = await fetchz(link,context)\n        await browser.close()\n        return result\ndates={}\nimport nest_asyncio\nnest_asyncio.apply()\nfrom datetime import date\ntoday=date.today()\ntoday=str(today)\ntoday=today.replace(\"-\",\"\")\ndates=[2026]\narrw=[]\nfor s in dates:\n    print(s)\n    uk=int(s)-1\n    s=str(s)\n    nj=s.replace(\".0\",\"\")\n    s=s.replace(\".0\",\"\")\n    url='https://barttorvik.com/teamsheets.php?year='+str(s)\n    print(url)\n    loop = asyncio.get_event_loop()\n    table = loop.run_until_complete(main(url))\n    for tr in table.find_all(\"tr\"):\n        if \"AdjOE\" not in str(tr) and 'absolute error' not in str(tr) and 'RESUME' not in str(tr) and 'KPI' not in str(tr):\n            rowz=[]\n            n=0\n            for td in tr.find_all(\"td\"):\n                if 1==1:\n                    if int(s)<2024 and n==8:\n                        m=1\n                    elif int(s)==2025 and n==5:\n                        m=1\n                    elif int(s)==2025 and n==9:\n                        m=1\n                    elif int(s)==2026 and n==5:\n                        m=1\n                    elif int(s)==2026 and n==9:\n                        m=1\n                    elif n==1:\n                        fd=td.find_all(\"a\")[0].text\n                        fd=str(fd)\n                        if fd=='':\n                            print(tr.find_all(\"td\"))\n                        rowz.append(fd)\n                    else:\n                        rowz.append(td.text)\n                n+=1\n            rowz.append(uk)\n            arrw.append(rowz)\ndfa=pd.DataFrame(arrw)\ndfa.columns=['rk','team','net','kpi','sor','avg','bpi','kp','avgz','q1a','q1','q2','q12','q3','q4','season']\ndfa=dfa[dfa.rk!=2026]\ndf=df[df.net!=2025]\ndf=df[df.net!=2026]\ndfa=dfa[dfa.rk!=2025]\nconfs={}\nfor row in df.itertuples():\n    s = row.team\n    result = s.split(\"\\xa0\\xa0\\xa0\", 1)[0]\n    df.at[row.Index,\"team\"]=result\n\nfor row in df.itertuples():\n    confs[row.team]=row.conf\ndfa['conf']='?'\nfor row in dfa.itertuples():\n    s = row.team\n    result = s.split(\"\\xa0\\xa0\\xa0\", 1)[0]\n    dfa.at[row.Index,\"team\"]=result\ndfa=dfa.replace('\\xa0', ' ', regex=True)\nfor row in dfa.itertuples():\n    if \"   \" in str(row.team):\n        teamh=str(row.team).split(\"   \")[0]\n        dfa.at[row.Index,'team']=teamh\ndfa['team']=dfa['team'].str.replace(\" St.\",\" State\")\ndfa=dfa.replace(\"Albany\",\"Albany (NY)\")\ndfa=dfa.replace(\"BYU\",\"Brigham Young\")\ndfa=dfa.replace(\"Grambling State\",\"Grambling\")\ndfa=dfa.replace(\"VCU\",\"Virginia Commonwealth\")\ndfa=dfa.replace(\"Fairleigh Dickinson\",\"FDU\")\ndfa=dfa.replace(\"SIU Edwardsville\",\"Southern Illinois-Edwardsville\")\ndfa=dfa.replace(\"LIU\",\"Long Island University\")\ndfa=dfa.replace(\"Nebraska Omaha\",\"Omaha\")\ndfa=dfa.replace(\"UMBC\",\"Maryland-Baltimore County\")\ndfa=dfa.replace(\"Miami FL\",\"Miami (FL)\")\ndfa=dfa.replace(\"SMU\",\"Southern Methodist\")\ndfa=dfa.replace(\"Penn\",\"Pennsylvania\")\ndfa=dfa.replace(\"Arkansas Pine Bluff\",\"Arkansas-Pine Bluff\")\ndfa=dfa.replace(\"USC Upstate\",\"South Carolina Upstate\")\ndfa=dfa.replace(\"St. Francis NY\",\"St. Francis (NY)\")\ndfa=dfa.replace(\"UMKC\",\"Kansas City\")\ndfa=dfa.replace(\"Central Connecticut\",\"Central Connecticut State\")\ndfa=dfa.replace(\"Tennessee Martin\",\"Tennessee-Martin\")\ndfa=dfa.replace(\"Saint Francis\",\"Saint Francis (PA)\")\ndfa=dfa.replace(\"Illinois Chicago\",\"Illinois-Chicago\")\ndfa=dfa.replace(\"Bethune Cookman\",\"Bethune-Cookman\")\ndfa=dfa.replace(\"N.C. State\",\"NC State\")\ndfa=dfa.replace(\"Charleston\",\"College of Charleston\")\ndfa=dfa.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\ndfa=dfa.replace(\"Loyola Chicago\",\"Loyola (IL)\")\ndfa=dfa.replace(\"Louisiana Monroe\",\"Louisiana-Monroe\")\ndfa=dfa.replace(\"Southern Miss\",\"Southern Mississippi\")\ndfa=dfa.replace(\"Texas A&M Corpus Chris\",\"Texas A&M-Corpus Christi\")\ndfa=dfa.replace(\"Saint Mary's\",\"Saint Mary's (CA)\")\ndfa=dfa.replace(\"UT Rio Grande Valley\",\"Texas-Rio Grande Valley\")\ndfa=dfa.replace(\"Gardner Webb\",\"Gardner-Webb\")\ndfa=dfa.replace(\"LSU\",\"Louisiana State\")\ndfa=dfa.replace(\"Loyola MD\",\"Loyola (MD)\")\ndfa=dfa.replace(\"UMass Lowell\",\"Massachusetts-Lowell\")\ndfa=dfa.replace(\"UNLV\",\"Nevada-Las Vegas\")\ndfa=dfa.replace(\"USC\",\"Southern California\")\ndfa=dfa.replace(\"Sam Houston State\",\"Sam Houston\")\ndfa=dfa.replace(\"Prairie View A&M\",\"Prairie View\")\ndfa=dfa.replace(\"Miami OH\",\"Miami (OH)\")\ndfa=dfa.replace(\"VMI\",\"Virginia Military Institute\")\ndfa=dfa.replace(\"St. John's\",\"St. John's (NY)\")\ndfa=dfa.replace(\"FIU\",\"Florida International\")\ndfa=dfa.replace(\"Queens\",\"Queens (NC)\")\ndfa=dfa.replace(\"Cal Baptist\",\"California Baptist\")\ndfa=dfa.replace(\"Mount State Mary's\",\"Mount St. Mary's\")\nfor row in dfa.itertuples():\n    dfa.at[row.Index,'conf']=confs[row.team]\ndf=dfa\ndf=df.astype({\"q1\":\"string\",\"q2\":\"string\",\"q3\":\"string\",\"q4\":\"string\",\"q1a\":\"string\"})\nfor row in df.itertuples():\n    df.at[row.Index,'q1w']=float(str(row.q1).split(\"-\")[0])\n    df.at[row.Index,'q1l']=float(str(row.q1).split(\"-\")[1])\n    df.at[row.Index,'q1aw']=float(str(row.q1a).split(\"-\")[0])\n    df.at[row.Index,'q1al']=float(str(row.q1a).split(\"-\")[1])\n    df.at[row.Index,'q2w']=float(str(row.q2).split(\"-\")[0])\n    df.at[row.Index,'q2l']=float(str(row.q2).split(\"-\")[1])\n    df.at[row.Index,'q3w']=float(str(row.q3).split(\"-\")[0])\n    df.at[row.Index,'q3l']=float(str(row.q3).split(\"-\")[1])\n    df.at[row.Index,'q4w']=float(str(row.q4).split(\"-\")[0])\n    df.at[row.Index,'q4l']=float(str(row.q4).split(\"-\")[1])\ndf.at[row.Index,'Rec']=''\nfor row in df.itertuples():\n    w=float(row.q1w)+float(row.q2w)+float(row.q3w)+float(row.q4w)\n    l=float(row.q1l)+float(row.q2l)+float(row.q3l)+float(row.q4l)\n    df.at[row.Index,'Rec']=str(w)+\"-\"+str(l)\ndef safe_apply_class_weight(model):\n    \"\"\"\n    Safely applies class_weight='balanced' to any sklearn classifier,\n    including meta-estimators. Never raises errors.\n    \"\"\"\n    # Case 1: model supports class_weight directly\n    try:\n        model.set_params(class_weight=\"balanced\")\n        return model\n    except Exception:\n        pass\n\n    # Case 2: model has base_estimator (CalibratedClassifierCV, etc.)\n    if hasattr(model, \"base_estimator\") and model.base_estimator is not None:\n        try:\n            model.base_estimator.set_params(class_weight=\"balanced\")\n            return model\n        except Exception:\n            pass\n\n    # Case 3: model has estimator (OneVsRest, OneVsOne, MultiOutput)\n    if hasattr(model, \"estimator\") and model.estimator is not None:\n        try:\n            model.estimator.set_params(class_weight=\"balanced\")\n            return model\n        except Exception:\n            pass\n\n    # Case 4: model has estimators_ (Voting, Stacking after fit)\n    if hasattr(model, \"estimators_\"):\n        for est in model.estimators_:\n            try:\n                est.set_params(class_weight=\"balanced\")\n            except Exception:\n                pass\n        return model\n\n    # Case 5: model has estimators (Voting, Stacking before fit)\n    if hasattr(model, \"estimators\"):\n        for name, est in model.estimators:\n            if est is not None:\n                try:\n                    est.set_params(class_weight=\"balanced\")\n                except Exception:\n                    pass\n        return model\n\n    # If nothing worked, return unchanged\n    return model\ndf['team']=df['team'].dropna()\n\nx=[]\ny=[]\nimport os\nu=0\narrp=[]\nimport requests\nfrom bs4 import BeautifulSoup\nimport numpy as np\ns=2024\ncs={}\nu=0\npct={}\nvotes=[]\nvotes=[]\npcts={}\nyw=0\nfor i in range(0,12):\n    pcts[str(i)]={}\nbartdf=pd.read_csv(\"https://cfbzzz.alwaysdata.net/bracketology/goodbart.txt\")\nbartdf=bartdf.drop(\"WAB\",axis=1)\naldf=pd.read_csv(\"https://cfbzzz.alwaysdata.net/bracketology/al.txt\")\nfor i in range(2013,2026):\n    print(i)\n    bartdf=bartdf[bartdf.RK!=i]\nbartdf=bartdf.replace('\\xa0', ' ', regex=True)\nbartdf['ty']=False\nfor row in bartdf.itertuples():\n    if \"   \" in str(row.team):\n        bartdf.at[row.Index,'ty']=True\n        teamh=str(row.team).split(\"   \")[0]\n        bartdf.at[row.Index,'team']=teamh\nbartdf['team']=bartdf['team'].str.replace(\" St.\",\" State\")\nbartdf=bartdf.replace(\"Albany\",\"Albany (NY)\")\nbartdf=bartdf.replace(\"BYU\",\"Brigham Young\")\nbartdf=bartdf.replace(\"Grambling State\",\"Grambling\")\nbartdf=bartdf.replace(\"VCU\",\"Virginia Commonwealth\")\nbartdf=bartdf.replace(\"Fairleigh Dickinson\",\"FDU\")\nbartdf=bartdf.replace(\"SIU Edwardsville\",\"Southern Illinois-Edwardsville\")\nbartdf=bartdf.replace(\"LIU\",\"Long Island University\")\nbartdf=bartdf.replace(\"Nebraska Omaha\",\"Omaha\")\nbartdf=bartdf.replace(\"UMBC\",\"Maryland-Baltimore County\")\nbartdf=bartdf.replace(\"Miami FL\",\"Miami (FL)\")\nbartdf=bartdf.replace(\"SMU\",\"Southern Methodist\")\nbartdf=bartdf.replace(\"Penn\",\"Pennsylvania\")\nbartdf=bartdf.replace(\"Arkansas Pine Bluff\",\"Arkansas-Pine Bluff\")\nbartdf=bartdf.replace(\"USC Upstate\",\"South Carolina Upstate\")\nbartdf=bartdf.replace(\"St. Francis NY\",\"St. Francis (NY)\")\nbartdf=bartdf.replace(\"UMKC\",\"Kansas City\")\nbartdf=bartdf.replace(\"Central Connecticut\",\"Central Connecticut State\")\nbartdf=bartdf.replace(\"Tennessee Martin\",\"Tennessee-Martin\")\nbartdf=bartdf.replace(\"Saint Francis\",\"Saint Francis (PA)\")\nbartdf=bartdf.replace(\"Illinois Chicago\",\"Illinois-Chicago\")\nbartdf=bartdf.replace(\"Bethune Cookman\",\"Bethune-Cookman\")\nbartdf=bartdf.replace(\"N.C. State\",\"NC State\")\nbartdf=bartdf.replace(\"Charleston\",\"College of Charleston\")\nbartdf=bartdf.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\nbartdf=bartdf.replace(\"Loyola Chicago\",\"Loyola (IL)\")\nbartdf=bartdf.replace(\"Louisiana Monroe\",\"Louisiana-Monroe\")\nbartdf=bartdf.replace(\"Southern Miss\",\"Southern Mississippi\")\nbartdf=bartdf.replace(\"Texas A&M Corpus Chris\",\"Texas A&M-Corpus Christi\")\nbartdf=bartdf.replace(\"Saint Mary's\",\"Saint Mary's (CA)\")\nbartdf=bartdf.replace(\"UT Rio Grande Valley\",\"Texas-Rio Grande Valley\")\nbartdf=bartdf.replace(\"Gardner Webb\",\"Gardner-Webb\")\nbartdf=bartdf.replace(\"LSU\",\"Louisiana State\")\nbartdf=bartdf.replace(\"Loyola MD\",\"Loyola (MD)\")\nbartdf=bartdf.replace(\"UMass Lowell\",\"Massachusetts-Lowell\")\nbartdf=bartdf.replace(\"UNLV\",\"Nevada-Las Vegas\")\nbartdf=bartdf.replace(\"USC\",\"Southern California\")\nbartdf=bartdf.replace(\"Sam Houston State\",\"Sam Houston\")\nbartdf=bartdf.replace(\"Prairie View A&M\",\"Prairie View\")\nbartdf=bartdf.replace(\"Miami OH\",\"Miami (OH)\")\nbartdf=bartdf.replace(\"VMI\",\"Virginia Military Institute\")\nbartdf=bartdf.replace(\"St. John's\",\"St. John's (NY)\")\nbartdf=bartdf.replace(\"FIU\",\"Florida International\")\nbartdf=bartdf.replace(\"Queens\",\"Queens (NC)\")\nbartdf=bartdf.replace(\"Cal Baptist\",\"California Baptist\")\nbartdf=bartdf.replace(\"Mount State Mary's\",\"Mount St. Mary's\")\nfor i in range(2007,2026):\n    bartdf=bartdf[bartdf.RK!=i]\nalargez={}\nfor i in range(1949,2026):\n    alargez[float(i)]=[]\nfor row in aldf.itertuples():\n    if float(row.TY)==1:\n        alargez[float(row.Year)].append(row.Team)\nfor row in bartdf.itertuples():\n    if row.team in alargez[float(row.season)]:\n        bartdf.at[row.Index,'alarge']=1\n    elif row.ty==True:\n        bartdf=bartdf.drop(row.Index)\n    else:\n        bartdf.at[row.Index,'alarge']=0\nconft={}\no=0\nfor cf in set(bartdf.conf.tolist()):\n    conft[cf]=0\n    o+=1  \nbartdf['pct']=0\nbartdf=bartdf[bartdf.season>2017]\nfor row in bartdf.itertuples():\n    bartdf.at[row.Index,'net']=rez[int(row.season)][row.team]['net']\n    bartdf.at[row.Index,'kpi']=rez[int(row.season)][row.team]['kpi']\n    bartdf.at[row.Index,'kp']=rez[int(row.season)][row.team]['kp']\n    bartdf.at[row.Index,'sor']=rez[int(row.season)][row.team]['sor']\n    bartdf.at[row.Index,'bpi']=rez[int(row.season)][row.team]['bpi']\n    bartdf.at[row.Index,'q1w']=rez[int(row.season)][row.team]['q1w']\n    bartdf.at[row.Index,'q2w']=rez[int(row.season)][row.team]['q2w']\n    bartdf.at[row.Index,'q1aw']=rez[int(row.season)][row.team]['q1aw']\n    bartdf.at[row.Index,'q1al']=rez[int(row.season)][row.team]['q1al']\n    bartdf.at[row.Index,'q3w']=rez[int(row.season)][row.team]['q3w']\n    bartdf.at[row.Index,'q4w']=rez[int(row.season)][row.team]['q4w']\n    bartdf.at[row.Index,'q1l']=rez[int(row.season)][row.team]['q1l']\n    bartdf.at[row.Index,'q2l']=rez[int(row.season)][row.team]['q2l']\n    bartdf.at[row.Index,'q3l']=rez[int(row.season)][row.team]['q3l']\n    bartdf.at[row.Index,'q4l']=rez[int(row.season)][row.team]['q4l']\nfor row in bartdf.itertuples():\n    rec=str(row.Rec)\n    w=str(rec).split(\"–\")[0]\n    l=str(rec).split(\"–\")[1]\n    w=float(w)\n    l=float(l)\n    pctz=1/(w+l)*w\n    pct=str(row.Rec)\n    w=pct.split(\"–\")[0]\n    l=pct.split(\"–\")[1]\n    w=float(w)\n    l=float(l)\n    pct=w/(w+l)\n    bartdf.at[row.Index,'pct']=pct\ndef add_quad_sos_features(dfz):\n\n    # -----------------------------\n    # Total games\n    # -----------------------------\n    dfz[\"games\"] = (\n        dfz[\"q1w\"] + dfz[\"q1l\"] +\n        dfz[\"q2w\"] + dfz[\"q2l\"] +\n        dfz[\"q3w\"] + dfz[\"q3l\"] +\n        dfz[\"q4w\"] + dfz[\"q4l\"]\n    )\n    \n    # -----------------------------\n    # Quadrant game counts\n    # -----------------------------\n    dfz[\"q1_games\"] = dfz[\"q1w\"] + dfz[\"q1l\"]\n    dfz[\"q2_games\"] = dfz[\"q2w\"] + dfz[\"q2l\"]\n    dfz[\"q3_games\"] = dfz[\"q3w\"] + dfz[\"q3l\"]\n    dfz[\"q4_games\"] = dfz[\"q4w\"] + dfz[\"q4l\"]\n    dfz['q4_dominance']=dfz['q4_games'] / dfz['games']\n    dfz['q4_loss_ratio']=dfz['q4l'] / dfz['q4_games']\n    # Q1A games (premium Q1)\n    dfz[\"q1a_games\"] = dfz[\"q1aw\"] + dfz[\"q1al\"]\n\n    # -----------------------------\n    # Quadrant shares\n    # -----------------------------\n    safe_games = dfz[\"games\"].replace(0, 1)\n\n    dfz[\"q1_share\"] = dfz[\"q1_games\"] / safe_games\n    dfz[\"q2_share\"] = dfz[\"q2_games\"] / safe_games\n    dfz[\"q3_share\"] = dfz[\"q3_games\"] / safe_games\n    dfz[\"q4_share\"] = dfz[\"q4_games\"] / safe_games\n\n    # Share of Q1 that is Q1A\n    dfz[\"q1a_share_of_q1\"] = dfz[\"q1a_games\"] / dfz[\"q1_games\"].replace(0, 1)\n\n    # -----------------------------\n    # Opportunity / cupcake indicators\n    # -----------------------------\n    dfz[\"hi_opportunity_share\"] = (dfz[\"q1_games\"] + dfz[\"q2_games\"]) / safe_games\n    dfz[\"cupcake_share\"] = (dfz[\"q3_games\"] + dfz[\"q4_games\"]) / safe_games\n\n    # -----------------------------\n    # Weighted SOS proxy\n    # -----------------------------\n    dfz[\"quad_sos\"] = (\n        4 * dfz[\"q1_games\"] +\n        3 * dfz[\"q2_games\"] +\n        2 * dfz[\"q3_games\"] +\n        1 * dfz[\"q4_games\"]\n    )\n\n    dfz[\"quad_sos_per_game\"] = dfz[\"quad_sos\"] / safe_games\n\n    # -----------------------------\n    # Weighted win quality\n    # (Q1A wins > Q1 wins > Q2 wins > Q3 wins > Q4 wins)\n    # -----------------------------\n    dfz[\"quad_win_quality\"] = (\n        5 * dfz[\"q1aw\"] +                                # premium wins\n        4 * (dfz[\"q1w\"] - dfz[\"q1aw\"]) +                  # other Q1 wins\n        3 * dfz[\"q2w\"] +\n        2 * dfz[\"q3w\"] +\n        1 * dfz[\"q4w\"]\n    )\n\n    # -----------------------------\n    # Weighted loss severity\n    # (Q4 losses worst, Q1A losses least harmful)\n    # -----------------------------\n    dfz[\"quad_loss_severity\"] = (\n        5 * dfz[\"q4l\"] +                                 # worst losses\n        4 * dfz[\"q3l\"] +\n        2 * dfz[\"q2l\"] +\n        1 * (dfz[\"q1l\"] - dfz[\"q1al\"]) +                  # normal Q1 losses\n        0.5 * dfz[\"q1al\"]                                # Q1A losses least harmful\n    )\n\n    return dfz\n\nbartdf=add_quad_sos_features(bartdf)\nm=0\nbartdf=bartdf[bartdf.season>2017]\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n# Add these imports at the top of your file\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.neural_network import MLPClassifier\nbartdf=bartdf.fillna(0)\nnumeric_features = ['pct','EFG', 'EFGD', \n                    'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', \n                    'P2', 'P2D', 'P3', 'P3D', 'P3R', 'PR3D', 'ADJT','net']\ncategorical_features = ['conf']  # conference\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport requests\nhtml=requests.get(\"https://www.teamrankings.com/ncb/rankings/\").text\nsoup=BeautifulSoup(html)\nlks=soup.find_all(\"a\")\nlinks={}\nfor l in lks:\n    if \"basketball/ranking/\" in str(l):\n        links['https://teamrankings.com'+str(l['href'])]=l.text\narrw=[]\nimport sys\nlinks={'https://teamrankings.com/ncaa-basketball/ranking/predictive-by-other/': 'Predictive Rankings', \n       'https://teamrankings.com/ncaa-basketball/ranking/predictive-by-other': 'Predictive Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/home-by-other': 'Home Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/away-by-other': 'Away Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/neutral-by-other': 'Neutral Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/home-adv-by-other': 'Home Advantage', \n       'https://teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other': 'Strength Of Schedule',  \n       'https://teamrankings.com/ncaa-basketball/ranking/luck-by-other': 'Luck Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/consistency-by-other': 'Consistency Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-1-25-by-other': 'Vs. 1-25 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-26-50-by-other': 'Vs. 26-50 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-51-100-by-other': 'Vs. 51-100 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-101-200-by-other': 'Vs. 101-200 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-201-and-up-by-other': 'Vs. 201+ Rating'}\nimport sys\nimport time\ngh={}\nfrom datetime import date\ntoday=date.today()\nprint(today)\nfor urlz in links:\n    name=links[urlz]\n    print(name)\n    if name not in gh:\n        gh[name]={}\n    if 1==1:\n        dr = [today]\n        for dt in dr:\n            dt=str(dt)\n            dt=dt.replace(\".0\",\"\")\n            time.sleep(1)\n            url=urlz+\"?date=\"+str(dt)\n            print(url)\n            html=requests.get(url).text\n            soup=BeautifulSoup(html)\n            table=soup.find_all(\"table\")[0]\n            colstr=table.find_all(\"tr\")[0]\n            cols=[]\n            for th in colstr.find_all(\"th\"):\n                cols.append(th.text)\n            gh[name]=cols\n            for tr in table.find_all(\"tr\"):\n                if 'Rating' not in str(tr):\n                    rowy=[]\n                    for td in tr.find_all(\"td\"):\n                        rowy.append(td.text)\n                    rowy.append(float(s)-1)\n                    rowy.append(name)\n                    rowy.append(dt)\n                    arrw.append(rowy)\nhtml=requests.get(\"https://cfbzzz.alwaysdata.net/bracketology/list.php\").text\nsoup=BeautifulSoup(html)\ndfsdict={}\narrt=[]\nurls={}\n\nfor line in html.split(\"<br/>\"):\n    if '.txt' in str(line) and 'filez' not in str(line) and 'bart' not in str(line) and 'al.txt' not in str(line) and 'preds' not in str(line) and 'Home Advantage' not in str(line):\n        url='https://cfbzzz.alwaysdata.net/bracketology/'+line\n        url=url.replace(\" \",\"%20\")\n        dw=pd.read_csv(url)\n        dw=dw.astype({\"season\":float,\"date\":\"string\"})\n        dw=dw[dw.season!=2020]\n        names=set(dw.name.tolist())\n        for n in names:\n            name=n\n        urls[name]=url\n        print(name,dw.columns)\n        for i in range(2008,2026):\n            de=str(i)\n            de=de.replace(\".0\",\"\")\n            de=de+'-03-15'\n            if '2021' not in str(de):\n                dw=dw[dw.date!=de]\n        for row in dw.itertuples():\n            if row.date not in dfsdict:\n                dfsdict[row.date]={}\n            team=str(row.Team).split(\" (\")[0]\n            teamj=str(row.Team)\n            teamj=teamj.replace(\" (NY)\",\" NY\")\n            rec=str(teamj).split(\" (\")[1]\n            \n            rec=rec.replace(\")\",\"\")\n            w=str(rec).split(\"-\")[0]\n            l=str(rec).split(\"-\")[1]\n            if team not in dfsdict[row.date]:\n                dfsdict[row.date][team]={}\n            if name not in dfsdict[row.date][team]:\n                if name=='Away Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['away w']=w\n                    dfsdict[row.date][team][name]['away l']=l\n                elif name=='Home Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['home w']=w\n                    dfsdict[row.date][team][name]['home l']=l\n                elif name=='Neutral Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['neutral w']=w\n                    dfsdict[row.date][team][name]['neutral l']=l\n                elif name=='Vs. 1-25 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['1-25 w']=w\n                    dfsdict[row.date][team][name]['1-25 l']=l\n                elif name=='Vs. 26-50 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['26-50 w']=w\n                    dfsdict[row.date][team][name]['26-50 l']=l\n                elif name=='Vs. 51-100 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['51-100 w']=w\n                    dfsdict[row.date][team][name]['51-100 l']=l\n                elif name=='Vs. 101-200 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['101-200 w']=w\n                    dfsdict[row.date][team][name]['101-200 l']=l\n                elif name=='Vs. 201+ Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['201+ w']=w\n                    dfsdict[row.date][team][name]['201+ l']=l\n                elif name=='Predictive Rating':\n                    dfsdict[row.date][team]['Predictive Rating']=float(row.Rating)\n                    dfsdict[row.date][team]['w']=w\n                    dfsdict[row.date][team]['l']=l    \n                else:\n                    dfsdict[row.date][team][name]=float(row.Rating)\n                \n                dfsdict[row.date][team]['season']=float(row.season)\nfor k in gh.keys():\n    q=[]\n    for r in arrw:\n        if r[-2]==k:\n            q.append(r)\n            azw=r\n    cols=gh[k]\n    \n    if 'date' in str(cols):\n        m=1\n        cols.remove(\"date\")\n    if 'season' not in str(cols):\n        cols.append(\"season\")\n    if 'name' not in str(cols):\n        cols.append(\"name\")\n    cols.append(\"date\")\n    \n    print(cols)\n    dk=pd.DataFrame(q,columns=cols)\n    names=set(dk.name.tolist())\n    for n in names:\n        name=n\n    urls[name]=url\n    print(name,dk.columns)\n    for row in dk.itertuples():\n        if row.date not in dfsdict:\n            dfsdict[row.date]={}\n        team=str(row.Team).split(\" (\")[0]\n        teamj=str(row.Team)\n        teamj=teamj.replace(\" (NY)\",\" NY\")\n        rec=str(teamj).split(\" (\")[1]\n            \n        rec=rec.replace(\")\",\"\")\n        w=str(rec).split(\"-\")[0]\n        l=str(rec).split(\"-\")[1]\n        if team not in dfsdict[row.date]:\n            dfsdict[row.date][team]={}\n        if name not in dfsdict[row.date][team]:\n            \n            if name=='Away Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['away w']=w\n                dfsdict[row.date][team][name]['away l']=l\n            elif name=='Home Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['home w']=w\n                dfsdict[row.date][team][name]['home l']=l\n            elif name=='Neutral Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['neutral w']=w\n                dfsdict[row.date][team][name]['neutral l']=l\n            elif name=='Vs. 1-25 Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['1-25 w']=w\n                dfsdict[row.date][team][name]['1-25 l']=l\n            elif name=='Vs. 26-50 Rating':\n                \n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['26-50 w']=w\n                dfsdict[row.date][team][name]['26-50 l']=l\n            elif name=='Vs. 51-100 Rating':\n                 \n                 dfsdict[row.date][team][name]={}\n                 dfsdict[row.date][team][name]['51-100 w']=w\n                 dfsdict[row.date][team][name]['51-100 l']=l\n            elif name=='Vs. 101-200 Rating':\n                 dfsdict[row.date][team][name]={}\n                 dfsdict[row.date][team][name]['101-200 w']=w\n                 dfsdict[row.date][team][name]['101-200 l']=l\n            elif name=='Vs. 201+ Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['201+ w']=w\n                dfsdict[row.date][team][name]['201+ l']=l\n            elif name=='Predictive Rating':\n                dfsdict[row.date][team]['Predictive Rating']=float(row.Rating)\n                dfsdict[row.date][team]['w']=w\n                dfsdict[row.date][team]['l']=l\n            dfsdict[row.date][team]['season']=float(row.season)\narr=[]\nif '2021-03-15' in dfsdict.keys():\n    del dfsdict['2021-03-15']  \nfor dt in dfsdict:\n    \n    for key in dfsdict[dt]:\n        rowa=[dt]\n        rowa.append(key)\n        rowa.append(dfsdict[dt][key]['season'])\n        rowa.append(dfsdict[dt][key]['w'])\n        rowa.append(dfsdict[dt][key]['l'])\n        rowa.append(dfsdict[dt][key][\"Consistency Rating\"])\n        rowa.append(dfsdict[dt][key][\"Luck Rating\"])\n        rowa.append(dfsdict[dt][key][\"Away Rating\"]['away w'])\n        rowa.append(dfsdict[dt][key][\"Away Rating\"]['away l'])\n        rowa.append(dfsdict[dt][key][\"Home Rating\"]['home w'])\n        rowa.append(dfsdict[dt][key][\"Home Rating\"]['home l'])\n        rowa.append(dfsdict[dt][key][\"Neutral Rating\"]['neutral w'])\n        rowa.append(dfsdict[dt][key][\"Neutral Rating\"]['neutral l'])\n        rowa.append(dfsdict[dt][key][\"Strength Of Schedule\"])\n        rowa.append(dfsdict[dt][key][\"Predictive Rating\"])\n        rowa.append(dfsdict[dt][key][\"Vs. 1-25 Rating\"]['1-25 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 1-25 Rating\"]['1-25 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 26-50 Rating\"]['26-50 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 26-50 Rating\"]['26-50 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 51-100 Rating\"]['51-100 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 51-100 Rating\"]['51-100 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 101-200 Rating\"]['101-200 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 101-200 Rating\"]['101-200 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 201+ Rating\"]['201+ w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 201+ Rating\"]['201+ l'])\n        arr.append(rowa)\ndfh=pd.DataFrame(arr,columns=['date','team','season','w','l','consistency','luck','awayw','awayl','homew','homel','neutw','neutl','sos','predrating','q1w',\"q1l\",\"q2w\",\"q2l\",\"q3w\",\"q3l\",'q4w','q4l','q5w','q5l']) \nold=dfh[dfh.season<2025]\nx = dfh[numeric_features + categorical_features]\ny = dfh['alarge']  # 1 if team made tournament w/o auto bid, 0 otherwise\ny=y.astype(int)\npreprocessor_scaled = ColumnTransformer([\n    ('num', StandardScaler(), numeric_features),\n    ('cat', OneHotEncoder(), categorical_features)\n])\n\n# For models that do not need scaling (trees, ensembles)\npreprocessor_unscaled = ColumnTransformer([\n    ('num', 'passthrough', numeric_features),\n    ('cat', OneHotEncoder(), categorical_features)\n])\npipelines = {}\nfrom sklearn.utils import all_estimators\n\nclassifiers = all_estimators(type_filter=\"classifier\")\nfitted_models = {}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.utils import all_estimators\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# Classifiers that need extra parameters and their defaults\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.multioutput import ClassifierChain, MultiOutputClassifier\nfrom sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\nfrom sklearn.ensemble import StackingClassifier, VotingClassifier\nfrom sklearn.base import BaseEstimator\n\n# ---------------------------\n# 1. Define features\n\n\n# Assume x is your DataFrame of features, y is your target\n# ---------------------------\n# 2. Train/test split\nX_train, X_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.2, random_state=42\n)\nimport pandas as pd\nimport numpy as np\nfrom sklearn.utils import all_estimators\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\n\n# Linear models\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV, PassiveAggressiveClassifier\n\n# Neural networks\nfrom sklearn.neural_network import MLPClassifier\n\n# Tree-based ensembles\nfrom sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n                              GradientBoostingClassifier, AdaBoostClassifier,\n                              BaggingClassifier, HistGradientBoostingClassifier,\n                              StackingClassifier, VotingClassifier)\n\n# Decision trees\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n\n# Naive Bayes\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB, ComplementNB, GaussianNB, CategoricalNB\n\n# SVM / linear models\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.linear_model import SGDClassifier, RidgeClassifier, RidgeClassifierCV, Perceptron\n\n# Meta-classifiers\nfrom sklearn.multioutput import ClassifierChain, MultiOutputClassifier\nfrom sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\n\n# Discriminant analysis\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n\n# Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n# ---------------------------\n# 3. List all classifiers\nclassifiers = all_estimators(type_filter=\"classifier\")\nfitted_models = {}\n\n# ---------------------------\n# 4. Loop through classifiers\nfrom sklearn.utils import all_estimators\n\ndef supports_class_weight(Clf):\n    \"\"\"\n    Returns True if the classifier supports class_weight.\n    \"\"\"\n    try:\n        # Try to instantiate with no args\n        model = Clf()\n    except TypeError:\n        # If the model requires arguments, inspect its signature instead\n        try:\n            params = Clf().get_params()\n        except:\n            return False\n    else:\n        params = model.get_params()\n\n    return \"class_weight\" in params\n\n\n# Example: test all classifiers\nclassifiers = all_estimators(type_filter=\"classifier\")\ndef safe_apply_class_weight(model):\n    \"\"\"\n    Safely applies class_weight='balanced' to any sklearn classifier,\n    including meta-estimators. Never raises errors.\n    \"\"\"\n    # Case 1: model supports class_weight directly\n    try:\n        model.set_params(class_weight=\"balanced\")\n        return model\n    except Exception:\n        pass\n\n    # Case 2: model has base_estimator (CalibratedClassifierCV, etc.)\n    if hasattr(model, \"base_estimator\") and model.base_estimator is not None:\n        try:\n            model.base_estimator.set_params(class_weight=\"balanced\")\n            return model\n        except Exception:\n            pass\n\n    # Case 3: model has estimator (OneVsRest, OneVsOne, MultiOutput)\n    if hasattr(model, \"estimator\") and model.estimator is not None:\n        try:\n            model.estimator.set_params(class_weight=\"balanced\")\n            return model\n        except Exception:\n            pass\n\n    # Case 4: model has estimators_ (Voting, Stacking after fit)\n    if hasattr(model, \"estimators_\"):\n        for est in model.estimators_:\n            try:\n                est.set_params(class_weight=\"balanced\")\n            except Exception:\n                pass\n        return model\n\n    # Case 5: model has estimators (Voting, Stacking before fit)\n    if hasattr(model, \"estimators\"):\n        for name, est in model.estimators:\n            if est is not None:\n                try:\n                    est.set_params(class_weight=\"balanced\")\n                except Exception:\n                    pass\n        return model\n\n    # If nothing worked, return unchanged\n    return model\n\n\nfrom sklearn.utils import all_estimators\n\ndef supports_predict_proba(Clf):\n    \"\"\"\n    Returns True if a classifier supports predict_proba.\n    Handles meta-estimators and models requiring special parameters.\n    \"\"\"\n    try:\n        # Try to instantiate with default params\n        model = Clf()\n    except Exception:\n        # If instantiation fails, skip this model\n        return False\n\n    # Case 1: model has predict_proba directly\n    if hasattr(model, \"predict_proba\"):\n        return True\n\n    # Case 2: meta-estimators with base estimator\n    if hasattr(model, \"base_estimator\") and model.base_estimator is not None:\n        if hasattr(model.base_estimator, \"predict_proba\"):\n            return True\n\n    # Case 3: meta-estimators with estimator attribute\n    if hasattr(model, \"estimator\") and model.estimator is not None:\n        if hasattr(model.estimator, \"predict_proba\"):\n            return True\n\n    return False\n\n\ndef filter_models_with_predict_proba(model_names):\n    \"\"\"\n    Given a list of model names (strings), return only those that support predict_proba.\n    \"\"\"\n    classifiers = dict(all_estimators(type_filter=\"classifier\"))\n    supported = []\n\n    for name in model_names:\n        if name in classifiers:\n            Clf = classifiers[name]\n            if supports_predict_proba(Clf):\n                supported.append(name)\n\n    return supported\n\nfitted_models={}\nprint(\"fitting models for prediction...\")\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import (\n    GradientBoostingClassifier,\n    HistGradientBoostingClassifier,\n    RandomForestClassifier,\n    ExtraTreesClassifier,\n    BaggingClassifier\n)\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\ndf=df.replace('\\xa0', ' ', regex=True)\nfor row in df.itertuples():\n    if \"   \" in str(row.team):\n        teamh=str(row.team).split(\"   \")[0]\n        df.at[row.Index,'team']=teamh\ndf['team']=df['team'].str.replace(\" St.\",\" State\")\ndf=df.replace(\"Albany\",\"Albany (NY)\")\ndf=df.replace(\"BYU\",\"Brigham Young\")\ndf=df.replace(\"Grambling State\",\"Grambling\")\ndf=df.replace(\"VCU\",\"Virginia Commonwealth\")\ndf=df.replace(\"Fairleigh Dickinson\",\"FDU\")\ndf=df.replace(\"SIU Edwardsville\",\"Southern Illinois-Edwardsville\")\ndf=df.replace(\"LIU\",\"Long Island University\")\ndf=df.replace(\"Nebraska Omaha\",\"Omaha\")\ndf=df.replace(\"UMBC\",\"Maryland-Baltimore County\")\ndf=df.replace(\"Miami FL\",\"Miami (FL)\")\ndf=df.replace(\"SMU\",\"Southern Methodist\")\ndf=df.replace(\"Penn\",\"Pennsylvania\")\ndf=df.replace(\"Arkansas Pine Bluff\",\"Arkansas-Pine Bluff\")\ndf=df.replace(\"USC Upstate\",\"South Carolina Upstate\")\ndf=df.replace(\"St. Francis NY\",\"St. Francis (NY)\")\ndf=df.replace(\"UMKC\",\"Kansas City\")\ndf=df.replace(\"Central Connecticut\",\"Central Connecticut State\")\ndf=df.replace(\"Tennessee Martin\",\"Tennessee-Martin\")\ndf=df.replace(\"Saint Francis\",\"Saint Francis (PA)\")\ndf=df.replace(\"Illinois Chicago\",\"Illinois-Chicago\")\ndf=df.replace(\"Bethune Cookman\",\"Bethune-Cookman\")\ndf=df.replace(\"N.C. State\",\"NC State\")\ndf=df.replace(\"Charleston\",\"College of Charleston\")\ndf=df.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\ndf=df.replace(\"Loyola Chicago\",\"Loyola (IL)\")\ndf=df.replace(\"Louisiana Monroe\",\"Louisiana-Monroe\")\ndf=df.replace(\"Southern Miss\",\"Southern Mississippi\")\ndf=df.replace(\"Texas A&M Corpus Chris\",\"Texas A&M-Corpus Christi\")\ndf=df.replace(\"Saint Mary's\",\"Saint Mary's (CA)\")\ndf=df.replace(\"UT Rio Grande Valley\",\"Texas-Rio Grande Valley\")\ndf=df.replace(\"Gardner Webb\",\"Gardner-Webb\")\ndf=df.replace(\"LSU\",\"Louisiana State\")\ndf=df.replace(\"Loyola MD\",\"Loyola (MD)\")\ndf=df.replace(\"UMass Lowell\",\"Massachusetts-Lowell\")\ndf=df.replace(\"UNLV\",\"Nevada-Las Vegas\")\ndf=df.replace(\"USC\",\"Southern California\")\ndf=df.replace(\"Sam Houston State\",\"Sam Houston\")\ndf=df.replace(\"Prairie View A&M\",\"Prairie View\")\ndf=df.replace(\"Miami OH\",\"Miami (OH)\")\ndf=df.replace(\"VMI\",\"Virginia Military Institute\")\ndf=df.replace(\"St. John's\",\"St. John's (NY)\")\ndf=df.replace(\"FIU\",\"Florida International\")\ndf=df.replace(\"Queens\",\"Queens (NC)\")\ndf=df.replace(\"Cal Baptist\",\"California Baptist\")\ndf=df.replace(\"Mount State Mary's\",\"Mount St. Mary's\")\nfor row in df.itertuples():\n    df.at[row.Index,'net']=rez[int(row.season)][row.team]['net']\n    df.at[row.Index,'q1w']=rez[int(row.season)][row.team]['q1w']\n    df.at[row.Index,'q2w']=rez[int(row.season)][row.team]['q2w']\n    df.at[row.Index,'q3w']=rez[int(row.season)][row.team]['q3w']\n    df.at[row.Index,'q4w']=rez[int(row.season)][row.team]['q4w']\n    df.at[row.Index,'q1l']=rez[int(row.season)][row.team]['q1l']\n    df.at[row.Index,'q2l']=rez[int(row.season)][row.team]['q2l']\n    df.at[row.Index,'q3l']=rez[int(row.season)][row.team]['q3l']\n    df.at[row.Index,'q4l']=rez[int(row.season)][row.team]['q4l']\n\nimport pandas as pd\n\ndf=add_quad_sos_features(df)\ndf=df.fillna(0)\nprint(\"prediction time!\")\n# ---------------------------------------------------------\n# 1. Parse Rec column (vectorized)\n# ---------------------------------------------------------\nfor row in df.itertuples():\n    df.at[row.Index,'w']=float(str(row.Rec).split(\"-\")[0])\n    df.at[row.Index,'l']=float(str(row.Rec).split(\"-\")[1])\ndf['pct'] = df['w'] / (df['w'] + df['l'])\n\n# ---------------------------------------------------------\n# 2. Build the feature matrix ONCE\n# ---------------------------------------------------------\n\nteams = df['team'].tolist()\n\n# ---------------------------------------------------------\n# 3. Run each model ONCE on the entire dataset\n# ---------------------------------------------------------\n\nimport numpy as np\nimport pandas as pd\ndf_current=df\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import (\n    GradientBoostingClassifier,\n    HistGradientBoostingClassifier,\n    RandomForestClassifier,\n    ExtraTreesClassifier,\n    BaggingClassifier,\n    StackingClassifier,\n)\n\n# =========================================\n# 0. YOUR DATA\n# =========================================\n\n# bartdf: past seasons, with target 'alarge'\n# df_current: current season teams\n# numeric_features, categorical_features: same as before\n\nX_all = bartdf[numeric_features + categorical_features]\ny_all = bartdf['alarge'].astype(int)\ndf_current=df_current.rename(columns={\"games\":\"G\"})\nX_current = df_current[numeric_features + categorical_features]\n\n# Column transformers (define ONCE and reuse)\npreprocessor_linear = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), numeric_features),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n    ]\n)\n\npreprocessor_tree = ColumnTransformer(\n    transformers=[\n        (\"num\", \"passthrough\", numeric_features),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n    ]\n)\n\n# =========================================\n# 1. Define the 12 base estimators as pipelines\n# =========================================\n\n\n\nbase_estimators = []\n\n# -- 3 linear / margin models\nbase_estimators.append(\n    (\"LogisticRegressionCV\",\n     Pipeline([\n         (\"pre\", preprocessor_linear),\n         (\"clf\", LogisticRegressionCV(\n             cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n             solver=\"liblinear\",\n             max_iter=5000\n         ))\n     ]))\n)\n\nbase_estimators.append(\n    (\"LogisticRegression\",\n     Pipeline([\n         (\"pre\", preprocessor_linear),\n         (\"clf\", LogisticRegression(\n             C=1.0,\n             class_weight=\"balanced\",\n             max_iter=5000,\n             random_state=42\n         ))\n     ]))\n)\n\nbase_estimators.append(\n    (\"Calibrated_LinearSVC\",\n     Pipeline([\n         (\"pre\", preprocessor_linear),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=LinearSVC(random_state=42),\n             cv=5\n         ))\n     ]))\n)\n\n# -- 4 boosting models\nbase_estimators.append(\n    (\"Calibrated_GBC\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=GradientBoostingClassifier(random_state=42),\n             cv=5\n         ))\n     ]))\n)\n\nbase_estimators.append(\n    (\"Calibrated_GBC_v2\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=GradientBoostingClassifier(\n                 random_state=42,\n                 max_depth=3,\n                 learning_rate=0.05\n             ),\n             cv=5\n         ))\n     ]))\n)\n\nbase_estimators.append(\n    (\"Calibrated_HGBC\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=HistGradientBoostingClassifier(random_state=42),\n             cv=5\n         ))\n     ]))\n)\n\nbase_estimators.append(\n    (\"Calibrated_HGBC_v2\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=HistGradientBoostingClassifier(\n                 random_state=42,\n                 max_depth=3,\n                 learning_rate=0.05\n             ),\n             cv=5\n         ))\n     ]))\n)\n\n# -- 3 RF / ET\nbase_estimators.append(\n    (\"Calibrated_RF\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=RandomForestClassifier(\n                 n_estimators=500,\n                 max_depth=10,\n                 min_samples_leaf=5,\n                 class_weight=\"balanced\",\n                 random_state=42\n             ),\n             cv=5\n         ))\n     ]))\n)\n\nbase_estimators.append(\n    (\"Calibrated_RF_v2\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=RandomForestClassifier(\n                 n_estimators=300,\n                 max_depth=6,\n                 min_samples_leaf=3,\n                 class_weight=\"balanced\",\n                 random_state=42\n             ),\n             cv=5\n         ))\n     ]))\n)\n\nbase_estimators.append(\n    (\"Calibrated_ET\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=ExtraTreesClassifier(\n                 n_estimators=500,\n                 max_depth=10,\n                 min_samples_leaf=5,\n                 class_weight=\"balanced\",\n                 random_state=42\n             ),\n             cv=5\n         ))\n     ]))\n)\n\n# -- 1 bagging\nbase_estimators.append(\n    (\"Calibrated_Bagging\",\n     Pipeline([\n         (\"pre\", preprocessor_tree),\n         (\"clf\", CalibratedClassifierCV(\n             base_estimator=BaggingClassifier(\n                 n_estimators=200,\n                 random_state=42\n             ),\n             cv=5\n         ))\n     ]))\n)\n\n# =========================================\n# 2. Stacking classifier (fast meta logistic regression)\n# =========================================\nprint(\"appended estimators\")\n# final_estimator is your logistic stacker on base predict_proba outputs\nfinal_estimator = LogisticRegression(\n    C=1.0,\n    penalty=\"l2\",\n    solver=\"liblinear\",\n    max_iter=5000,\n    random_state=42\n)\nprint('done final estimator')\nstack = StackingClassifier(\n    estimators=base_estimators,\n    final_estimator=final_estimator,\n    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n    stack_method=\"predict_proba\",    # use base models' probabilities as features\n    n_jobs=-1                        # parallelize across models where possible\n)\nprint('done intializing stack')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.isotonic import IsotonicRegression\nimport numpy as np\nimport pandas as pd\n\nprint(\"Fast calibration using single train/test split...\")\nX_hist=x\ny_hist=y\n# 1. SINGLE SPLIT instead of 5-fold CV (80/20 is plenty for calibration)\nX_tr, X_calib, y_tr, y_calib = train_test_split(\n    X_hist, y_hist, test_size=0.2, stratify=y_hist, random_state=42\n)\n\n# 2. Fit stack ONCE on training split\n\nstack.fit(X_tr, y_tr)\nprint(\"done stack\")\n# 3. Get OOF probabilities ONCE on calibration split\nhist_probs = stack.predict_proba(X_calib)[:, 1]\nhist_labels = y_calib.values if hasattr(y_calib, 'values') else np.asarray(y_calib)\n\n# 4. Fit isotonic (very fast)\niso_calibrator = IsotonicRegression(y_min=0.0, y_max=1.0, out_of_bounds=\"clip\")\niso_calibrator.fit(hist_probs, hist_labels)\nprint(\"done iso fit\")\nprint(\"done stack 2\")\n# 5. Fit FINAL stack on ALL historical data (one more fit)\nstack.fit(X_hist, y_hist)\n\n# 6. Predict current season and calibrate (very fast)\nraw_probs_current = stack.predict_proba(X_current)[:, 1]\ncalibrated_probs_current = iso_calibrator.predict(raw_probs_current)\n\n# 7. Tail adjustment (vectorized, instant)\nalpha = 0.5          # strength of tail adjustment (0 = none, 1 = full isotonic)\ntail_threshold = 0.7 # start adjusting above this raw probability\n\nfinal_probs = raw_probs_current.copy()\ntail_mask = raw_probs_current > tail_threshold\nfinal_probs[tail_mask] = (\n    (1.0 - alpha) * raw_probs_current[tail_mask] +\n    alpha * calibrated_probs_current[tail_mask]\n)\n\n# Attach results - make sure df_current has same length as X_current\ndf=df.reset_index(drop=True)  # Ensure proper indexing\ndf[\"atlarge_prob_raw\"] = raw_probs_current\ndf[\"atlarge_prob_calibrated\"] = calibrated_probs_current\ndf[\"atlarge_prob_final\"] = final_probs\n\nprint(\"Calibration complete!\")\n\n# Fixed Purdue print - safer indexing\npurdue_row = df[df['team'].str.contains('Purdue', case=False, na=False)]\nif len(purdue_row) > 0:\n    print(f\"Purdue final prob: {purdue_row['atlarge_prob_final'].iloc[0]:.1%}\")\nelse:\n    print(\"Purdue not found in df_current\")\n\n\naqs = {}\ndf_current = df_current.astype({\"net\": float})\nfor conf in sorted(set(df_current.conf.tolist())):\n    uy = df_current[(df_current.conf == conf) & (df_current.season == 2025)]\n    if len(uy) == 0:\n        continue\n    uy = uy.sort_values(by=\"net\", ascending=True).head(1)\n    for t in uy.team.tolist():\n        aqs[t] = conf\n\n# Non-AQ candidates, ranked by FINAL calibrated probability\ncandidates = [t for t in df.team.tolist() if t not in aqs]\nteam_final_prob = dict(zip(df.team, df[\"atlarge_prob_final\"]))\n\navg_prob = {t: team_final_prob.get(t, 0.0) for t in candidates}\nsorted_teams = sorted(avg_prob.keys(), key=lambda x: avg_prob[x], reverse=True)\n\n# Take field + FFO + NFO\nN_AT_LARGE = 37\natlarge = sorted_teams[:N_AT_LARGE + 8]\n\n# ========================================================\n# 9. PRINT THE FIELD (same format as your original)\n# ========================================================\nBOLD = '\\033[1m'\nEND = '\\033[0m'\n\nprint(BOLD + \"<h1>IN THE FIELD</h1>\" + END)\nfor t in atlarge[:N_AT_LARGE]:\n    print(f\"<h3>{t}</h3>\")\n\nprint(BOLD + \"<h1>AUTOMATIC QUALIFIERS</h1>\" + END)\nfor t in aqs.keys():\n    print(f\"<h3>{t}{BOLD} (AQ)</h3>{END}\")\n\nprint(BOLD + \"<h1>FIRST FOUR OUT</h1>\" + END)\nfor t in atlarge[N_AT_LARGE:N_AT_LARGE+4]:\n    print(f\"<h3>{t}</h3>\")\n\nprint(BOLD + \"<h1>NEXT FOUR OUT</h1>\" + END)\nfor t in atlarge[N_AT_LARGE+4:N_AT_LARGE+8]:\n    print(f\"<h3>{t}</h3>\")\n\nprint(f\"\\nTotal at-large: {len(atlarge[:N_AT_LARGE])}\")\nprint(f\"Total AQs: {len(aqs)}\")\nprint(f\"Total field: {len(atlarge[:N_AT_LARGE]) + len(aqs)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T03:19:39.327007Z","iopub.execute_input":"2026-01-15T03:19:39.327398Z","iopub.status.idle":"2026-01-15T03:20:28.472614Z","shell.execute_reply.started":"2026-01-15T03:19:39.327373Z","shell.execute_reply":"2026-01-15T03:20:28.470404Z"}},"outputs":[{"name":"stdout","text":"2019\nhttps://barttorvik.com/teamsheets.php?year=2019\n2021\nhttps://barttorvik.com/teamsheets.php?year=2021\n2022\nhttps://barttorvik.com/teamsheets.php?year=2022\n2023\nhttps://barttorvik.com/teamsheets.php?year=2023\n2024\nhttps://barttorvik.com/teamsheets.php?year=2024\n2025\nhttps://barttorvik.com/teamsheets.php?year=2025\n2026\nhttps://barttorvik.com/teamsheets.php?year=2026\n2026\nhttps://barttorvik.com/teamsheets.php?year=2026\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-105-1e73bce14fb6>:553: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.875' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  bartdf.at[row.Index,'pct']=pct\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-105-1e73bce14fb6>\u001b[0m in \u001b[0;36m<cell line: 653>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbartdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbartdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alarge'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 1 if team made tournament w/o auto bid, 0 otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['P2', 'P2D', 'P3', 'P3D', 'P3R', 'PR3D'] not in index\""],"ename":"KeyError","evalue":"\"['P2', 'P2D', 'P3', 'P3D', 'P3R', 'PR3D'] not in index\"","output_type":"error"}],"execution_count":105},{"cell_type":"code","source":"bartdf=bartdf.rename(columns={\"2P\":\"P2\",\"2PD\":\"P2D\",\"3P\":\"P3\",\"3PD\":\"P3D\",\"3PR\":\"P3R\",\"3PRD\":\"PR3D\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T03:21:11.637180Z","iopub.execute_input":"2026-01-15T03:21:11.637572Z","iopub.status.idle":"2026-01-15T03:21:11.645475Z","shell.execute_reply.started":"2026-01-15T03:21:11.637540Z","shell.execute_reply":"2026-01-15T03:21:11.644482Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'RK', 'team', 'conf', 'G', 'Rec', 'ADJOE', 'ADJDE',\n       'BARTHAG', 'EFG', 'EFGD', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD',\n       '2P', '2PD', '3P', '3PD', '3PR', '3PRD', 'ADJT', 'season', 'ty',\n       'alarge', 'pct', 'net', 'kpi', 'kp', 'sor', 'bpi', 'q1w', 'q2w', 'q1aw',\n       'q1al', 'q3w', 'q4w', 'q1l', 'q2l', 'q3l', 'q4l', 'games', 'q1_games',\n       'q2_games', 'q3_games', 'q4_games', 'q4_dominance', 'q4_loss_ratio',\n       'q1a_games', 'q1_share', 'q2_share', 'q3_share', 'q4_share',\n       'q1a_share_of_q1', 'hi_opportunity_share', 'cupcake_share', 'quad_sos',\n       'quad_sos_per_game', 'quad_win_quality', 'quad_loss_severity'],\n      dtype='object')"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:48:05.714931Z","iopub.execute_input":"2026-01-15T02:48:05.715355Z","iopub.status.idle":"2026-01-15T02:48:05.744653Z","shell.execute_reply.started":"2026-01-15T02:48:05.715323Z","shell.execute_reply":"2026-01-15T02:48:05.743696Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"      rk                      team    net  kpi  sor    avg  bpi   kp   avgz  \\\n0      1                  Michigan    1.0    1    9    5.3    3    1    1.7   \n1      2                   Arizona    2.0    6    1    3.3    2    2      2   \n2      3                      Duke    3.0    7    4      5    1    9    8.3   \n3      4                Vanderbilt    4.0    2    5      4   13    5      7   \n4      5                   Gonzaga    5.0   12    8   10.7    4    8    7.3   \n..   ...                       ...    ...  ...  ...    ...  ...  ...    ...   \n360  361              Gardner-Webb  361.0  345  332  342.7  363  359  359.7   \n361  362                Binghamton  362.0  365  323    350  355  361  359.3   \n362  363              Morgan State  363.0  359  341  351.3  361  363  362.3   \n363  364              Coppin State  364.0  362  327  351.3  364  364  364.3   \n364  365  Mississippi Valley State  365.0  364  340    356  365  365  364.7   \n\n     q1a  ... quad_sos quad_sos_per_game quad_win_quality quad_loss_severity  \\\n0    1-0  ...     42.0          2.800000             40.0                2.0   \n1    3-0  ...     39.0          2.437500             42.0                0.0   \n2    4-1  ...     44.0          2.750000             44.0                0.5   \n3    1-0  ...     41.0          2.562500             42.0                0.0   \n4    1-1  ...     43.0          2.388889             40.0                0.5   \n..   ...  ...      ...               ...              ...                ...   \n360  0-2  ...     34.0          2.266667              0.0               48.0   \n361  0-0  ...     23.0          1.533333              1.0               59.0   \n362  0-0  ...     25.0          1.666667              2.0               51.0   \n363  0-0  ...     38.0          2.000000              2.0               61.0   \n364  0-0  ...     40.0          2.352941              0.0               54.0   \n\n        w     l       pct  atlarge_prob_raw  atlarge_prob_calibrated  \\\n0    14.0   1.0  0.933333          0.998590                      1.0   \n1    16.0   0.0  1.000000          0.998466                      1.0   \n2    15.0   1.0  0.937500          0.998676                      1.0   \n3    16.0   0.0  1.000000          0.998663                      1.0   \n4    17.0   1.0  0.944444          0.998643                      1.0   \n..    ...   ...       ...               ...                      ...   \n360   0.0  15.0  0.000000          0.001098                      0.0   \n361   1.0  14.0  0.066667          0.001098                      0.0   \n362   2.0  13.0  0.133333          0.001098                      0.0   \n363   2.0  17.0  0.105263          0.001098                      0.0   \n364   0.0  17.0  0.000000          0.001098                      0.0   \n\n     atlarge_prob_final  \n0              0.999295  \n1              0.999233  \n2              0.999338  \n3              0.999332  \n4              0.999321  \n..                  ...  \n360            0.001098  \n361            0.001098  \n362            0.001098  \n363            0.001098  \n364            0.001098  \n\n[365 rows x 53 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rk</th>\n      <th>team</th>\n      <th>net</th>\n      <th>kpi</th>\n      <th>sor</th>\n      <th>avg</th>\n      <th>bpi</th>\n      <th>kp</th>\n      <th>avgz</th>\n      <th>q1a</th>\n      <th>...</th>\n      <th>quad_sos</th>\n      <th>quad_sos_per_game</th>\n      <th>quad_win_quality</th>\n      <th>quad_loss_severity</th>\n      <th>w</th>\n      <th>l</th>\n      <th>pct</th>\n      <th>atlarge_prob_raw</th>\n      <th>atlarge_prob_calibrated</th>\n      <th>atlarge_prob_final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Michigan</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5.3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.7</td>\n      <td>1-0</td>\n      <td>...</td>\n      <td>42.0</td>\n      <td>2.800000</td>\n      <td>40.0</td>\n      <td>2.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>0.933333</td>\n      <td>0.998590</td>\n      <td>1.0</td>\n      <td>0.999295</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Arizona</td>\n      <td>2.0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3.3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3-0</td>\n      <td>...</td>\n      <td>39.0</td>\n      <td>2.437500</td>\n      <td>42.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.998466</td>\n      <td>1.0</td>\n      <td>0.999233</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Duke</td>\n      <td>3.0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>9</td>\n      <td>8.3</td>\n      <td>4-1</td>\n      <td>...</td>\n      <td>44.0</td>\n      <td>2.750000</td>\n      <td>44.0</td>\n      <td>0.5</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>0.937500</td>\n      <td>0.998676</td>\n      <td>1.0</td>\n      <td>0.999338</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Vanderbilt</td>\n      <td>4.0</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>13</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1-0</td>\n      <td>...</td>\n      <td>41.0</td>\n      <td>2.562500</td>\n      <td>42.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.998663</td>\n      <td>1.0</td>\n      <td>0.999332</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Gonzaga</td>\n      <td>5.0</td>\n      <td>12</td>\n      <td>8</td>\n      <td>10.7</td>\n      <td>4</td>\n      <td>8</td>\n      <td>7.3</td>\n      <td>1-1</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>2.388889</td>\n      <td>40.0</td>\n      <td>0.5</td>\n      <td>17.0</td>\n      <td>1.0</td>\n      <td>0.944444</td>\n      <td>0.998643</td>\n      <td>1.0</td>\n      <td>0.999321</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>361</td>\n      <td>Gardner-Webb</td>\n      <td>361.0</td>\n      <td>345</td>\n      <td>332</td>\n      <td>342.7</td>\n      <td>363</td>\n      <td>359</td>\n      <td>359.7</td>\n      <td>0-2</td>\n      <td>...</td>\n      <td>34.0</td>\n      <td>2.266667</td>\n      <td>0.0</td>\n      <td>48.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>0.000000</td>\n      <td>0.001098</td>\n      <td>0.0</td>\n      <td>0.001098</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>362</td>\n      <td>Binghamton</td>\n      <td>362.0</td>\n      <td>365</td>\n      <td>323</td>\n      <td>350</td>\n      <td>355</td>\n      <td>361</td>\n      <td>359.3</td>\n      <td>0-0</td>\n      <td>...</td>\n      <td>23.0</td>\n      <td>1.533333</td>\n      <td>1.0</td>\n      <td>59.0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>0.066667</td>\n      <td>0.001098</td>\n      <td>0.0</td>\n      <td>0.001098</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>363</td>\n      <td>Morgan State</td>\n      <td>363.0</td>\n      <td>359</td>\n      <td>341</td>\n      <td>351.3</td>\n      <td>361</td>\n      <td>363</td>\n      <td>362.3</td>\n      <td>0-0</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>1.666667</td>\n      <td>2.0</td>\n      <td>51.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>0.133333</td>\n      <td>0.001098</td>\n      <td>0.0</td>\n      <td>0.001098</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>364</td>\n      <td>Coppin State</td>\n      <td>364.0</td>\n      <td>362</td>\n      <td>327</td>\n      <td>351.3</td>\n      <td>364</td>\n      <td>364</td>\n      <td>364.3</td>\n      <td>0-0</td>\n      <td>...</td>\n      <td>38.0</td>\n      <td>2.000000</td>\n      <td>2.0</td>\n      <td>61.0</td>\n      <td>2.0</td>\n      <td>17.0</td>\n      <td>0.105263</td>\n      <td>0.001098</td>\n      <td>0.0</td>\n      <td>0.001098</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>365</td>\n      <td>Mississippi Valley State</td>\n      <td>365.0</td>\n      <td>364</td>\n      <td>340</td>\n      <td>356</td>\n      <td>365</td>\n      <td>365</td>\n      <td>364.7</td>\n      <td>0-0</td>\n      <td>...</td>\n      <td>40.0</td>\n      <td>2.352941</td>\n      <td>0.0</td>\n      <td>54.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>0.000000</td>\n      <td>0.001098</td>\n      <td>0.0</td>\n      <td>0.001098</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 53 columns</p>\n</div>"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"aw=0\nfor k in avg_prob:\n    aw+=1\n    if k=='Lipscomb':\n        print(aw)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:25:18.198888Z","iopub.execute_input":"2026-01-15T02:25:18.199357Z","iopub.status.idle":"2026-01-15T02:25:18.204247Z","shell.execute_reply.started":"2026-01-15T02:25:18.199324Z","shell.execute_reply":"2026-01-15T02:25:18.203237Z"}},"outputs":[{"name":"stdout","text":"132\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"df[df.team=='Louisiana State']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:26:00.855396Z","iopub.execute_input":"2026-01-15T02:26:00.855785Z","iopub.status.idle":"2026-01-15T02:26:00.879419Z","shell.execute_reply.started":"2026-01-15T02:26:00.855750Z","shell.execute_reply":"2026-01-15T02:26:00.878203Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"    rk             team   net kpi sor   avg bpi  kp  avgz  q1a  ... quad_sos  \\\n45  46  Louisiana State  46.0  54  58  54.7  47  42  44.7  1-2  ...     33.0   \n\n   quad_sos_per_game quad_win_quality quad_loss_severity     w    l   pct  \\\n45            2.0625             20.0                6.0  12.0  4.0  0.75   \n\n    atlarge_prob_raw  atlarge_prob_calibrated  atlarge_prob_final  \n45          0.001554                      0.0            0.001554  \n\n[1 rows x 53 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rk</th>\n      <th>team</th>\n      <th>net</th>\n      <th>kpi</th>\n      <th>sor</th>\n      <th>avg</th>\n      <th>bpi</th>\n      <th>kp</th>\n      <th>avgz</th>\n      <th>q1a</th>\n      <th>...</th>\n      <th>quad_sos</th>\n      <th>quad_sos_per_game</th>\n      <th>quad_win_quality</th>\n      <th>quad_loss_severity</th>\n      <th>w</th>\n      <th>l</th>\n      <th>pct</th>\n      <th>atlarge_prob_raw</th>\n      <th>atlarge_prob_calibrated</th>\n      <th>atlarge_prob_final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>46</td>\n      <td>Louisiana State</td>\n      <td>46.0</td>\n      <td>54</td>\n      <td>58</td>\n      <td>54.7</td>\n      <td>47</td>\n      <td>42</td>\n      <td>44.7</td>\n      <td>1-2</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>2.0625</td>\n      <td>20.0</td>\n      <td>6.0</td>\n      <td>12.0</td>\n      <td>4.0</td>\n      <td>0.75</td>\n      <td>0.001554</td>\n      <td>0.0</td>\n      <td>0.001554</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 53 columns</p>\n</div>"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"mids={}\narrh=[]\nws={}\nls={}\npowz=['SEC','B10','B12','BE','ACC']\nfor row in df.itertuples():\n    if row.conf not in powz:\n        ws[row.team]=row.w\n        ls[row.team]=row.l\n        mids[row.team]=row.atlarge_prob_final\njs=sorted(mids,key=mids.get,reverse=True)[:25]\nfor k in js:\n    num=mids[k]*100\n    if num<1:\n        num=\"<1\"\n    else:\n        num=round(num,1)\n    num=str(num)\n    num=num.replace(\".0\",\"\")\n    num=num+\"%\"\n    arrh.append([k,num,ws[k],ls[k]])\nqa=pd.DataFrame(arrh,columns=['team','prob','Proj W','Proj L'])\nqa.to_html(\"midmjz.html\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:28:30.863964Z","iopub.execute_input":"2026-01-13T19:28:30.864266Z","iopub.status.idle":"2026-01-13T19:28:30.880705Z","shell.execute_reply.started":"2026-01-13T19:28:30.864221Z","shell.execute_reply":"2026-01-13T19:28:30.879784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:59:20.109070Z","iopub.execute_input":"2026-01-15T02:59:20.109398Z","iopub.status.idle":"2026-01-15T02:59:20.115485Z","shell.execute_reply.started":"2026-01-15T02:59:20.109374Z","shell.execute_reply":"2026-01-15T02:59:20.114576Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"['pct',\n 'G',\n 'net',\n 'q1w',\n 'q2w',\n 'q3w',\n 'q4w',\n 'q1l',\n 'q2l',\n 'q3l',\n 'q4l',\n 'q1_games',\n 'q2_games',\n 'q3_games',\n 'q4_games',\n 'hi_opportunity_share',\n 'cupcake_share',\n 'quad_sos_per_game',\n 'quad_win_quality',\n 'quad_sos',\n 'quad_loss_severity',\n 'q4_dominance',\n 'q4_loss_ratio',\n 'kpi',\n 'sor',\n 'bpi',\n 'q1aw',\n 'q1al']"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"for c in df.columns:\n    if c not in numeric_features:\n        print(c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:59:04.627491Z","iopub.execute_input":"2026-01-15T02:59:04.627838Z","iopub.status.idle":"2026-01-15T02:59:04.636841Z","shell.execute_reply.started":"2026-01-15T02:59:04.627813Z","shell.execute_reply":"2026-01-15T02:59:04.635785Z"}},"outputs":[{"name":"stdout","text":"rk\nteam\navg\nkp\navgz\nq1a\nq1\nq2\nq12\nq3\nq4\nseason\nconf\nRec\ngames\nq1a_games\nq1_share\nq2_share\nq3_share\nq4_share\nq1a_share_of_q1\nw\nl\natlarge_prob_raw\natlarge_prob_calibrated\natlarge_prob_final\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nhtml=requests.get(\"https://www.teamrankings.com/ncb/conference-tournaments/\")\nsoup=BeautifulSoup(html.text)\nrats={}\nfor row in df.itertuples():\n    rats[row.team]=row.net\nlinks=soup.find_all(\"a\")\nlinkz={}\nfor link in links:\n    liny=link\n    if 'bracket' in str(link) and 'ncaa' not in str(link) and 'Pac 12' not in str(link):\n        link='https://www.teamrankings.com/ncb/conference-tournaments/'+(link['href'])\n        linkz[str(liny.text).replace(\" Tournament\",\"\").replace(\" Bracket 2026\",\"\")]=link\nneut=['MAC']\nconfg={}\nprobz={}\ndel link[\"Pac 12\"]\nfor link in linkz:\n    print(link)\n    probz[link]={}\n    confg[link]={}\n    url=linkz[link]\n    html=requests.get(url).text\n    soup=BeautifulSoup(html)\n    table=soup.find_all(\"table\")[2]\n    seed=1\n    for tr in table.find_all(\"tr\"):\n        if 'Current' not in str(tr) and 'conf W' not in str(tr):\n            tds=tr.find_all(\"td\")\n            confg[link][seed]=tds[0].text\n            prob=str(tds[8].text).replace(\"%\",\"\")\n            probz[link][tds[0].text]=float(prob)\n            seed+=1\n    if link=='ACC':\n        probzy=sorted(probz[link],key=probz[link].get,reverse=True)[:8]\nprobj=probzy\nprobz={}\nfor k in probj:\n    probz[k]={}\n    s=0\n    for t in probj[k]:\n        probz[k][t]=s\n        s+=1\n    \ndef getw(arro,link):\n    if probz[link][arro[0]]>probz[link][arro[1]]:\n        return probz[link][arro[1]]\n    else:\n        return probz[link][arro[0]]\nfor c in confg:\n    if c=='ACC':\n        print(c)\n        seeds=confg[c]\n        bracket = [seeds[0], seeds[3], seeds[2], seeds[1], seeds[4], seeds[7], seeds[6], seeds[5]]  # Standard 1-8,4-5,2-7,3-6 quarters\n        round1 = [\n            getw([bracket[0],bracket[7]],link),\n            getw([bracket[3],bracket[4]],link),\n            getw([bracket[1],bracket[6]],link),\n            getw([bracket[2],bracket[5]],link)\n        ]\n        round2=[\n            getw([round1[0],round1[1]],link),\n            getw([round1[2],round1[3]],link)\n        ]\n        champ=[\n            getw([round2[0],round2[1]],link)\n        ]\n        print(champ)\n        \n        \n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T23:51:35.643700Z","iopub.execute_input":"2026-01-13T23:51:35.644028Z","iopub.status.idle":"2026-01-13T23:51:36.448444Z","shell.execute_reply.started":"2026-01-13T23:51:35.644002Z","shell.execute_reply":"2026-01-13T23:51:36.446767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def getw(arro,link):\n    if probz[link][arro[0]]>probz[link][arro[1]]:\n        return probz[link][arro[1]]\n    else:\n        return probz[link][arro[0]]\nfor c in confg:\n    if c=='ACC':\n        print(c)\n        seeds=confg[c]\n        bracket = [seeds[0], seeds[3], seeds[2], seeds[1], seeds[4], seeds[7], seeds[6], seeds[5]]  # Standard 1-8,4-5,2-7,3-6 quarters\n        round1 = [\n            getw([bracket[0],bracket[7]],link),\n            getw([bracket[3],bracket[4]],link),\n            getw([bracket[1],bracket[6]],link),\n            getw([bracket[2],bracket[5]],link)\n        ]\n        round2=[\n            getw([round1[0],round1[1]],link),\n            getw([round1[2],round1[3]],link)\n        ]\n        champ=[\n            getw([round2[0],round2[1]],link)\n        ]\n        print(champ)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T20:41:28.104504Z","iopub.execute_input":"2026-01-13T20:41:28.104836Z","iopub.status.idle":"2026-01-13T20:41:28.121219Z","shell.execute_reply.started":"2026-01-13T20:41:28.104816Z","shell.execute_reply":"2026-01-13T20:41:28.119426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['team']=df['team'].str.replace(\" St\",\" State\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:36:32.152903Z","iopub.execute_input":"2026-01-15T18:36:32.153383Z","iopub.status.idle":"2026-01-15T18:36:32.171431Z","shell.execute_reply.started":"2026-01-15T18:36:32.153342Z","shell.execute_reply":"2026-01-15T18:36:32.170239Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"df=df.replace(\"Miami OH\",\"Miami (OH)\")\ndf=df.replace('AR-Pine Bluff',\"Arkansas-Pine Bluff\")\ndf=df.replace(\"Abl Christian\",\"Abilene Christian\")\ndf=df.replace(\"App Stateate\",\"Appalachian State\")\ntz=set(df.team.tolist())\nfor t in tz:\n    if t[0]=='A':\n        print(t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:38:56.657404Z","iopub.execute_input":"2026-01-15T18:38:56.657822Z","iopub.status.idle":"2026-01-15T18:38:56.864994Z","shell.execute_reply.started":"2026-01-15T18:38:56.657795Z","shell.execute_reply":"2026-01-15T18:38:56.864101Z"}},"outputs":[{"name":"stdout","text":"Alcorn State\nAmerican\nArkansas-Pine Bluff\nAppalachian State\nAlbany\nArkansas State\nAbilene Christian\nAkron\nArizona State\nAlabama State\nAuburn\nAustin Peay\nArkansas\nAir Force\nAlabama\nArizona\nAlabama A&M\nArmy\n","output_type":"stream"}],"execution_count":146},{"cell_type":"code","source":"arrz=[]\narr=[]\nfor t in aqs:\n    stry=t\n    arr.append(stry)\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narry=[]\nfor t in atlarge[:37]:\n    arry.append(t)\narri=[]\nfor t in atlarge[37:41]:\n    arri.append(t)\nfor i in range(0,33):\n    arri.append(\"\")\narrii=[]\nfor t in atlarge[41:45]:\n    arrii.append(t)\nfor i in range(0,33):\n    arrii.append(\"\")\narrw=[]\nfor t in atlarge[33:37]:\n    arrw.append(t)\nfor i in range(0,33):\n    arrw.append(\"\")\nimport numpy as np\narrz = np.stack((arr,arry,arrw,arri,arrii), axis=1)\n\ndfz=pd.DataFrame(arrz,columns=['AQS','At-Large','Last Four In','First Four Out','Next Four Out'])\ndfz.reset_index(drop=True,inplace=True)\ndfz = dfz.style.set_table_styles(\n    [{'selector': 'th', 'props': [('font-size', '20px')]}]\n)\ndfz = dfz.map(lambda x: 'font-size:16px', subset=['AQS','At-Large','Last Four In','First Four Out','Next Four Out'])\ndfz.to_html(\"goodproby.html\",index_col=0)\ndfz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:13:56.173514Z","iopub.execute_input":"2026-01-13T19:13:56.173828Z","iopub.status.idle":"2026-01-13T19:13:56.198748Z","shell.execute_reply.started":"2026-01-13T19:13:56.173808Z","shell.execute_reply":"2026-01-13T19:13:56.197807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"powz=['SEC','B10','B12','BE','ACC']\najk={}\narrq=[]\nfor row in df.itertuples():\n    if 1==1:\n        q=[]\n        if row.conf not in powz:\n            for k in pcts:\n                q.append(pcts[k][row.team])\n            proby=np.mean(q)\n            ajk[row.team]=proby\ntzu=sorted(ajk,key=ajk.get,reverse=True)[:25]\ni=1\nfor k in tzu:\n   arrq.append([i,k,round((ajk[k]*100),1)])\n   i+=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:08:07.468747Z","iopub.execute_input":"2026-01-13T19:08:07.469071Z","iopub.status.idle":"2026-01-13T19:08:07.486814Z","shell.execute_reply.started":"2026-01-13T19:08:07.469043Z","shell.execute_reply":"2026-01-13T19:08:07.485534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dfs=pd.DataFrame(arrq,columns=[\"rank\",\"team\",\"probability\"])\ndfs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T18:01:57.310884Z","iopub.execute_input":"2026-01-13T18:01:57.311452Z","iopub.status.idle":"2026-01-13T18:01:57.326591Z","shell.execute_reply.started":"2026-01-13T18:01:57.311404Z","shell.execute_reply":"2026-01-13T18:01:57.324696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Create a sample DataFrame\ndf = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(4, 2)) # Adjust figure size as needed\n\n# Hide the axis\nax.axis('off')\n\n# Render the DataFrame as a table\ntbl = ax.table(cellText=df.values, colLabels=df.columns, loc='center')\n\n# Optional: Adjust table properties (e.g., scale)\ntbl.auto_set_font_size(False)\ntbl.set_fontsize(10)\ntbl.scale(1.2, 1.2)\n\n# Save the figure as an image file\nplt.savefig(\"dataframe_matplotlib.png\", bbox_inches='tight', dpi=150)\nplt.close() # Close the figure to prevent it from displaying in notebooks\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"op=sorted(ajk,key=ajk.get,reverse=True)[:25]\nfor t in op:\n    probt=ajk[t]\n    probt=probt*100\n    print(t+\": \"+str(probt))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T01:06:43.981945Z","iopub.execute_input":"2026-01-12T01:06:43.982400Z","iopub.status.idle":"2026-01-12T01:06:43.992368Z","shell.execute_reply.started":"2026-01-12T01:06:43.982364Z","shell.execute_reply":"2026-01-12T01:06:43.991270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for key in f:\n    if test_accuracy[key]!=f[key]:\n        print(key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T22:43:38.238221Z","iopub.execute_input":"2026-01-02T22:43:38.238599Z","iopub.status.idle":"2026-01-02T22:43:38.242971Z","shell.execute_reply.started":"2026-01-02T22:43:38.238569Z","shell.execute_reply":"2026-01-02T22:43:38.241770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"arrz=[]\narr=[]\nfor t in aqs:\n    stry=t+\" (\"+aqs[t]+\")\"\n    arr.append(stry)\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narr.append(\"\")\narry=[]\nfor t in atlarge[:37]:\n    arry.append(t)\narri=[]\nfor t in atlarge[37:41]:\n    arri.append(t)\nfor i in range(0,33):\n    arri.append(\"\")\narrii=[]\nfor t in atlarge[41:45]:\n    arrii.append(t)\nfor i in range(0,33):\n    arrii.append(\"\")\narrw=[]\nfor t in atlarge[33:37]:\n    arrw.append(t)\nfor i in range(0,33):\n    arrw.append(\"\")\nimport numpy as np\narrz = np.stack((arr,arry,arrw,arri,arrii), axis=1)\n\ndfz=pd.DataFrame(arrz,columns=['AQS','At-Large','Last Four In','First Four Out','Next Four Out'])\ndfz = dfz.style.set_table_styles(\n    [{'selector': 'th', 'props': [('font-size', '20px')]}]\n)\ndfz = dfz.map(lambda x: 'font-size:16px', subset=['AQS','At-Large','Last Four In','First Four Out','Next Four Out'])\n\ndfz.to_html(\"tableqawaz.html\")\nprint(\"good\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T02:39:58.762983Z","iopub.execute_input":"2026-01-13T02:39:58.763346Z","iopub.status.idle":"2026-01-13T02:39:58.788782Z","shell.execute_reply.started":"2026-01-13T02:39:58.763318Z","shell.execute_reply":"2026-01-13T02:39:58.787266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"teamk={}\nimport numpy as np\nfor tm in set(df.team.tolist()):\n    jk=[]\n    for key in pcts:\n        jk.append(pcts[key][tm])\n    \n    \n    jk=np.mean(jk)\n    teamk[tm]=jk\narrj=[]\nteamkz=sorted(teamk,key=teamk.get,reverse=True)\nfor key in teamkz:\n    pfh=float(teamk[key])\n    pfh=pfh*100\n    pfh=round(pfh,1)\n    arrj.append([key,pfh])\n    print(key,\":\",pfh)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T14:29:18.237558Z","iopub.execute_input":"2026-01-03T14:29:18.238005Z","iopub.status.idle":"2026-01-03T14:29:18.431134Z","shell.execute_reply.started":"2026-01-03T14:29:18.237969Z","shell.execute_reply":"2026-01-03T14:29:18.430083Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qw=pd.DataFrame(arrj,columns=['team','probability'])\nqw=qw.head(100)\nqw[qw.team=='Miami OH']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T22:38:37.872949Z","iopub.execute_input":"2025-12-31T22:38:37.873434Z","iopub.status.idle":"2025-12-31T22:38:37.887113Z","shell.execute_reply.started":"2025-12-31T22:38:37.873390Z","shell.execute_reply":"2025-12-31T22:38:37.885884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"qw.to_html(\"probs.html\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T20:36:29.283766Z","iopub.execute_input":"2025-12-30T20:36:29.284102Z","iopub.status.idle":"2025-12-30T20:36:29.295452Z","shell.execute_reply.started":"2025-12-30T20:36:29.284076Z","shell.execute_reply":"2025-12-30T20:36:29.294366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dfw=pd.read_csv(\"https://ontheroadtovote.com/alarge.csv\")\ndfw=dfw[dfw.Year>2006]\ndfw=dfw[dfw.TY==1]\ndfw=dfw.replace(\"Louisiana State\",\"LSU\")\ndfw=dfw.replace(\"Loyola (MD)\",\"Loyola MD\")\ndfw=dfw.replace(\"Fairleigh-Dickinson\",\"FDU\")\ndfw=dfw.replace(\"Fairleigh Dickinson\",\"FDU\")\ndfw=dfw.replace(\"Southern California\",\"USC\")\ndfw=dfw.replace(\"Miami (FL)\",\"Miami FL\")\ndfw=dfw.replace(\"Brigham Young\",\"BYU\")\ndfw=dfw.replace(\"St. John's (NY)\",\"St. John's\")\ndfw=dfw.replace(\"Nevada-Las Vegas\",\"UNLV\")\ndfw=dfw.replace(\"Saint Mary's (CA)\",\"Saint Mary's\")\ndfw=dfw.replace(\"Virginia Commonwealth\",\"VCU\")\ndfw=dfw.replace(\"Southern Mississippi\",\"Southern Miss\")\ndfw=dfw.replace(\"NC State\",\"N.C. State\")\nte=set(dfw.Team.tolist())\nsr={}\n\n    \ndf['team']=df['team'].str.replace(\" St.\",\" State\")\nfor row in dfw.itertuples():\n    if float(row.Year) not in sr:\n        sr[float(row.Year)]={}\n    sr[float(row.Year)][str(row.Team)]=float(row.TY)\n    \nfor row in df.itertuples():\n    if row.team in sr[float(row.season)]:\n        df.at[row.Index,'alarge']=sr[float(row.season)][row.team]\n    else:\n        df.at[row.Index,'alarge']=0\ndf.to_csv(\"barts.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T17:13:00.452224Z","iopub.status.idle":"2025-12-23T17:13:00.452546Z","shell.execute_reply":"2025-12-23T17:13:00.452414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from bs4 import BeautifulSoup\narr=[]\nimport requests\n\nfor s in range(2008,2025):\n    s=str(s)\n    url=\"https://barttorvik.com/trank.php?begin=\"+str(seasons[s][0])+\"&end=\"+str(seasons[s][1])+\"&conlimit=All&year=\"+str(s)+\"&top=0&hteam=&quad=5&rpi=\"\n    html=requests.get(url).text\n    print(s)\n    soup=BeautifulSoup(html)\n    table=soup.find_all(\"table\")[0]\n    for tr in table.find_all(\"tr\"):\n        if \"Rk\" not in str(tr):\n            tds=tr.find_all(\"td\")\n            row=[]\n            row.append(float(s)-1)\n            for i in range(0,len(tds)):\n                if i==4:\n                    y=tds[i].find(\"a\").text\n                    x=tds[i].find(\"span\").text\n                    row.append(y)\n                    row.append(x)\n                else:\n                    row.append(tds[i].text)\n            arr.append(row)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T17:14:52.852472Z","iopub.execute_input":"2025-12-23T17:14:52.852866Z","iopub.status.idle":"2025-12-23T17:14:53.667213Z","shell.execute_reply.started":"2025-12-23T17:14:52.852836Z","shell.execute_reply":"2025-12-23T17:14:53.665964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install playwright\n!playwright install\n!playwright install-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T23:24:32.513874Z","iopub.execute_input":"2026-01-14T23:24:32.514124Z","iopub.status.idle":"2026-01-14T23:26:18.356486Z","shell.execute_reply.started":"2026-01-14T23:24:32.514102Z","shell.execute_reply":"2026-01-14T23:26:18.354768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seasons={\"2008\":[\"20071105\",\"20080316\"],\"2009\":[\"20081110\",\"20090310\"],\"2010\":[\"20091109\",\"20100309\"],\"2011\":[\"20101108\",\"20110313\"],\"2012\":[\"20111107\",\"20120311\"],\"2013\":[\"20121109\",\"20130317\"],\"2014\":[\"20131108\",\"20140316\"],\"2015\":[\"20141114\",\"20150315\"],\"2016\":[\"20151113\",\"20160313\"],\"2017\":[\"20161111\",\"20170312\"],\"2018\":[\"20171110\",\"20180311\"],\"2019\":[\"20181106\",\"20190317\"],\"2021\":[\"20201125\",\"20210314\"],\"2022\":[\"20211109\",\"20220313\"],\"2023\":[\"20221107\",\"20230312\"],\"2024\":[\"20231106\",\"20240317\"],\"2025\":[\"20241105\",\"20250317\"]}\nfrom playwright.async_api import async_playwright\nimport asyncio\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport time\nimport requests\n\nasync def fetch(link):\n    async with async_playwright() as p:\n        browser=await p.chromium.launch(headless=True)\n        page=await browser.new_page()\n        await page.goto(link,wait_until=\"load\")\n        last=None\n        for _ in range(10):\n            await page.wait_for_load_state(\"networkidle\")\n            new=page.url\n            if new==last:\n                break\n            last=new\n        try:\n            await page.wait_for_selector(\"table\")\n        except Exception as e:\n            print(e)\n        html=await page.content()\n        await browser.close()\n        soup=BeautifulSoup(html)\n        return soup\nfrom playwright.async_api import async_playwright\nfrom bs4 import BeautifulSoup\nimport asyncio\n\n\n\nasync def fetchz(link, context):\n    page = await context.new_page()\n    await page.route(\"**/*\", lambda route: route.abort() if route.request.resource_type in [\"image\", \"stylesheet\", \"font\"] else route.continue_())\n    await page.goto(link, wait_until=\"domcontentloaded\",timeout=0)\n    last = None\n    for _ in range(10):\n        await page.wait_for_load_state(\"networkidle\")\n        new = page.url\n        if new == last:\n            break\n        last = new\n    try:\n        await page.wait_for_selector(\"table\",state=\"attached\")\n    except Exception as e:\n        print(e)\n    element = await page.query_selector(\"table\")\n    html = await element.inner_html()\n    soup = BeautifulSoup(html, \"html.parser\")\n    await page.close()\n    return soup\n\nasync def main(link):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True,args=[\"--disable-gpu\", \"--no-sandbox\"])\n        context = await browser.new_context()\n        result = await fetchz(link,context)\n        await browser.close()\n        return result\nimport nest_asyncio\nnest_asyncio.apply()\nimport time\nprint(\"done\")\nfor s in seasons:\n    print(s)\n    uk=int(s)-1\n    s=str(s)\n    nj=s.replace(\".0\",\"\")\n    s=s.replace(\".0\",\"\")\n    time.sleep(0.05)\n    io=float(s)-1\n    io=str(io)\n    io=io.replace(\".0\",\"\")\n    d1=io+\"1201\"\n    io=float(s)\n    io=str(io)\n    io=io.replace(\".0\",\"\")\n    d2=io+\"0115\"\n    d3=io+\"0215\"\n    dr = [d1,d2,d3,seasons[s][1]]\n    for dt in dr:\n        dt=str(dt)\n        dt=dt.replace(\" 00:00:00\",\"\")\n        url=\"https://barttorvik.com/trank-time-machine.php?date=\"+str(seasons[nj][1])+\"&year=\"+str(s)\n        url=\"https://barttorvik.com/trank.php?year=\"+str(s)+\"&sort=&hteam=&t2value=&conlimit=All&state=All&begin=\"+str(seasons[nj][0])+\"&end=\"+str(dt)+\"&top=0&revquad=0&quad=5&venue=All&type=All&mingames=0#\"\n        url=\"https://www.teamrankings.com/ncaa-basketball/ranking/vs-1-25-by-other?date=\"+str(dt)\n        print(url)\n        loop = asyncio.get_event_loop()\n        table = loop.run_until_complete(main(url))\n        for tr in table.find_all(\"tr\"):\n            if \"AdjOE\" not in str(tr) and 'absolute error' not in str(tr):\n                rowz=[]\n                n=0\n                for td in tr.find_all(\"td\"):\n                    if n!=4:\n                        rowz.append(td.text)\n                    else:\n                        fd=td.find_all(\"a\")[0].text\n                        fd=str(fd)\n                        if fd=='':\n                            print(tr.find_all(\"td\"))\n                        rowz.append(fd)\n                    n+=1\n                rowz.append(uk)\n                arrw.append(rowz)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T15:50:58.507417Z","iopub.execute_input":"2026-01-15T15:50:58.507783Z","iopub.status.idle":"2026-01-15T15:50:58.536332Z","shell.execute_reply.started":"2026-01-15T15:50:58.507754Z","shell.execute_reply":"2026-01-15T15:50:58.534630Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-6de20fa8a819>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseasons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"2008\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20071105\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20080316\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2009\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20081110\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20090310\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2010\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20091109\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20100309\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2011\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20101108\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20110313\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2012\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20111107\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20120311\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2013\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20121109\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20130317\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2014\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20131108\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20140316\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2015\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20141114\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20150315\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2016\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20151113\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20160313\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2017\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20161111\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20170312\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2018\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20171110\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20180311\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2019\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20181106\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20190317\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2021\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20201125\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20210314\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2022\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20211109\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20220313\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2023\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20221107\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20230312\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2024\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20231106\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20240317\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2025\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"20241105\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"20250317\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplaywright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masync_playwright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'playwright'"],"ename":"ModuleNotFoundError","evalue":"No module named 'playwright'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom bs4 import BeautifulSoup\nimport requests\nhtml=requests.get(\"https://www.teamrankings.com/ncb/rankings/\").text\nsoup=BeautifulSoup(html)\nlks=soup.find_all(\"a\")\nlinks={}\nfor l in lks:\n    if \"basketball/ranking/\" in str(l):\n        links['https://teamrankings.com'+str(l['href'])]=l.text\narrw=[]\nlinks={\n       'https://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other': 'Strength Of Schedule' \n}\nimport sys\nimport time\ngh={}\nfor urlz in links:\n    name=links[urlz]\n    print(name)\n    if name not in gh:\n        gh[name]={}\n    for s in seasons:\n        print(s)\n        time.sleep(1)\n        s=str(s)\n        s=s.replace(\".0\",\"\")\n        io=float(s)-1\n        io=str(io)\n        io=io.replace(\".0\",\"\")\n        d1=io+\"-12-02\"\n        io=float(s)\n        io=str(io)\n        io=io.replace(\".0\",\"\")\n        d2=io+\"-01-16\"\n        d3=io+\"-02-16\"\n        d4=float(seasons[s][1])+1\n        d4=str(d4)\n        d4=d4.replace(\".0\",\"\")\n        d4=d4[0]+d4[1]+d4[2]+d4[3]+\"-\"+d4[4]+d4[5]+\"-\"+d4[6]+d4[7]\n        dr = [d4]\n        \n        for dt in dr:\n            dt=str(dt)\n            dt=dt.replace(\".0\",\"\")\n            time.sleep(1)\n            url=urlz+\"?date=\"+str(dt)\n            print(url)\n            html=requests.get(url).text\n            soup=BeautifulSoup(html)\n            table=soup.find_all(\"table\")[0]\n            colstr=table.find_all(\"tr\")[0]\n            cols=[]\n            for th in colstr.find_all(\"th\"):\n                cols.append(th.text)\n            gh[name]=cols\n            for tr in table.find_all(\"tr\"):\n                if 'Rating' not in str(tr):\n                    rowy=[]\n                    for td in tr.find_all(\"td\"):\n                        rowy.append(td.text)\n                    rowy.append(float(s)-1)\n                    rowy.append(name)\n                    rowy.append(dt)\n                    arrw.append(rowy)\nfor k in gh.keys():\n    q=[]\n    for r in arrw:\n        if r[-2]==k:\n            q.append(r)\n            azw=r\n    cols=gh[k]\n    \n    if 'date' in str(cols):\n        m=1\n        cols.remove(\"date\")\n    if 'season' not in str(cols):\n        cols.append(\"season\")\n    if 'name' not in str(cols):\n        cols.append(\"name\")\n    cols.append(\"date\")\n    \n    print(cols)\n    dk=pd.DataFrame(q,columns=cols)\n    namey=k+\"newq.txt\"\n    dk.to_csv(namey)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:13:15.300507Z","iopub.execute_input":"2026-01-15T18:13:15.300905Z","iopub.status.idle":"2026-01-15T18:14:05.086553Z","shell.execute_reply.started":"2026-01-15T18:13:15.300875Z","shell.execute_reply":"2026-01-15T18:14:05.085210Z"}},"outputs":[{"name":"stdout","text":"Strength Of Schedule\n2008\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2008-03-17\n2009\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2009-03-11\n2010\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2010-03-10\n2011\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2011-03-14\n2012\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2012-03-12\n2013\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2013-03-18\n2014\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2014-03-17\n2015\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2015-03-16\n2016\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2016-03-14\n2017\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2017-03-13\n2018\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2018-03-12\n2019\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2019-03-18\n2021\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2021-03-15\n2022\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2022-03-14\n2023\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2023-03-13\n2024\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2024-03-18\n2025\nhttps://www.teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2025-03-18\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n","output_type":"stream"}],"execution_count":125},{"cell_type":"code","source":"for k in gh.keys():\n    q=[]\n    for r in arrw:\n        if r[-2]==k:\n            q.append(r)\n            azw=r\n    cols=gh[k]\n    \n    if 'date' in str(cols):\n        m=1\n        cols.remove(\"date\")\n    if 'season' not in str(cols):\n        cols.append(\"season\")\n    if 'name' not in str(cols):\n        cols.append(\"name\")\n    cols.append(\"date\")\n    \n    print(cols)\n    dk=pd.DataFrame(q,columns=cols)\n    namey=k+\"updated.txt\"\n    dk.to_csv(namey)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:35:18.335919Z","iopub.execute_input":"2026-01-15T17:35:18.336293Z","iopub.status.idle":"2026-01-15T17:35:18.590455Z","shell.execute_reply.started":"2026-01-15T17:35:18.336266Z","shell.execute_reply":"2026-01-15T17:35:18.589415Z"}},"outputs":[{"name":"stdout","text":"['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"for g in ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:48:20.997129Z","iopub.execute_input":"2026-01-15T17:48:20.997521Z","iopub.status.idle":"2026-01-15T17:48:21.002961Z","shell.execute_reply.started":"2026-01-15T17:48:20.997488Z","shell.execute_reply":"2026-01-15T17:48:21.002002Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"Pandas(Index=364, Rank='365', Team='Coppin St (2-8)', Rating='-23.5', Hi='273', Lo='365', Last='364', season=2024.0, name='Vs. 201+ Rating', date='2026-01-15')"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"import pandas as pd\nfrom bs4 import BeautifulSoup\nimport requests\nhtml=requests.get(\"https://www.teamrankings.com/ncb/rankings/\").text\nsoup=BeautifulSoup(html)\nlks=soup.find_all(\"a\")\nlinks={}\nfor l in lks:\n    if \"basketball/ranking/\" in str(l):\n        links['https://teamrankings.com'+str(l['href'])]=l.text\narrw=[]\nimport sys\nlinks={'https://teamrankings.com/ncaa-basketball/ranking/predictive-by-other/': 'Predictive Rankings', \n       'https://teamrankings.com/ncaa-basketball/ranking/predictive-by-other': 'Predictive Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/home-by-other': 'Home Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/away-by-other': 'Away Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/neutral-by-other': 'Neutral Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/home-adv-by-other': 'Home Advantage', \n       'https://teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other': 'Strength Of Schedule',  \n       'https://teamrankings.com/ncaa-basketball/ranking/luck-by-other': 'Luck Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/consistency-by-other': 'Consistency Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-1-25-by-other': 'Vs. 1-25 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-26-50-by-other': 'Vs. 26-50 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-51-100-by-other': 'Vs. 51-100 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-101-200-by-other': 'Vs. 101-200 Rating', \n       'https://teamrankings.com/ncaa-basketball/ranking/vs-201-and-up-by-other': 'Vs. 201+ Rating'}\nimport sys\nimport time\ngh={}\nfrom datetime import date\ntoday=date.today()\nprint(today)\nfor urlz in links:\n    name=links[urlz]\n    print(name)\n    if name not in gh:\n        gh[name]={}\n    if 1==1:\n        dr = [today]\n        for dt in dr:\n            dt=str(dt)\n            dt=dt.replace(\".0\",\"\")\n            time.sleep(1)\n            url=urlz+\"?date=\"+str(dt)\n            print(url)\n            html=requests.get(url).text\n            soup=BeautifulSoup(html)\n            table=soup.find_all(\"table\")[0]\n            colstr=table.find_all(\"tr\")[0]\n            cols=[]\n            for th in colstr.find_all(\"th\"):\n                cols.append(th.text)\n            gh[name]=cols\n            for tr in table.find_all(\"tr\"):\n                if 'Rating' not in str(tr):\n                    rowy=[]\n                    for td in tr.find_all(\"td\"):\n                        rowy.append(td.text)\n                    rowy.append(float(s)-1)\n                    rowy.append(name)\n                    rowy.append(dt)\n                    arrw.append(rowy)\nhtml=requests.get(\"https://cfbzzz.alwaysdata.net/bracketology/list.php\").text\nsoup=BeautifulSoup(html)\ndfsdict={}\narrt=[]\nurls={}\n\nfor line in html.split(\"<br/>\"):\n    if '.txt' in str(line) and 'filez' not in str(line) and 'bart' not in str(line) and 'al.txt' not in str(line) and 'preds' not in str(line) and 'Home Advantage' not in str(line):\n        url='https://cfbzzz.alwaysdata.net/bracketology/'+line\n        url=url.replace(\" \",\"%20\")\n        dw=pd.read_csv(url)\n        dw=dw.astype({\"season\":float,\"date\":\"string\"})\n        dw=dw[dw.season!=2020]\n        names=set(dw.name.tolist())\n        for n in names:\n            name=n\n        urls[name]=url\n        print(name,dw.columns)\n        for i in range(2008,2026):\n            de=str(i)\n            de=de.replace(\".0\",\"\")\n            de=de+'-03-15'\n            if '2021' not in str(de):\n                dw=dw[dw.date!=de]\n        for row in dw.itertuples():\n            if row.date not in dfsdict:\n                dfsdict[row.date]={}\n            team=str(row.Team).split(\" (\")[0]\n            teamj=str(row.Team)\n            teamj=teamj.replace(\" (NY)\",\" NY\")\n            rec=str(teamj).split(\" (\")[1]\n            \n            rec=rec.replace(\")\",\"\")\n            w=str(rec).split(\"-\")[0]\n            l=str(rec).split(\"-\")[1]\n            if team not in dfsdict[row.date]:\n                dfsdict[row.date][team]={}\n            if name not in dfsdict[row.date][team]:\n                if name=='Away Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['away w']=w\n                    dfsdict[row.date][team][name]['away l']=l\n                elif name=='Home Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['home w']=w\n                    dfsdict[row.date][team][name]['home l']=l\n                elif name=='Neutral Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['neutral w']=w\n                    dfsdict[row.date][team][name]['neutral l']=l\n                elif name=='Vs. 1-25 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['1-25 w']=w\n                    dfsdict[row.date][team][name]['1-25 l']=l\n                elif name=='Vs. 26-50 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['26-50 w']=w\n                    dfsdict[row.date][team][name]['26-50 l']=l\n                elif name=='Vs. 51-100 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['51-100 w']=w\n                    dfsdict[row.date][team][name]['51-100 l']=l\n                elif name=='Vs. 101-200 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['101-200 w']=w\n                    dfsdict[row.date][team][name]['101-200 l']=l\n                elif name=='Vs. 201+ Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['201+ w']=w\n                    dfsdict[row.date][team][name]['201+ l']=l\n                elif name=='Predictive Rating':\n                    dfsdict[row.date][team]['Predictive Rating']=float(row.Rating)\n                    dfsdict[row.date][team]['w']=w\n                    dfsdict[row.date][team]['l']=l    \n                else:\n                    dfsdict[row.date][team][name]=float(row.Rating)\n                \n                dfsdict[row.date][team]['season']=float(row.season)\nfor k in gh.keys():\n    q=[]\n    for r in arrw:\n        if r[-2]==k:\n            q.append(r)\n            azw=r\n    cols=gh[k]\n    \n    if 'date' in str(cols):\n        m=1\n        cols.remove(\"date\")\n    if 'season' not in str(cols):\n        cols.append(\"season\")\n    if 'name' not in str(cols):\n        cols.append(\"name\")\n    cols.append(\"date\")\n    \n    print(cols)\n    dk=pd.DataFrame(q,columns=cols)\n    names=set(dk.name.tolist())\n    for n in names:\n        name=n\n    urls[name]=url\n    print(name,dk.columns)\n    for row in dk.itertuples():\n        if row.date not in dfsdict:\n            dfsdict[row.date]={}\n        team=str(row.Team).split(\" (\")[0]\n        teamj=str(row.Team)\n        teamj=teamj.replace(\" (NY)\",\" NY\")\n        rec=str(teamj).split(\" (\")[1]\n            \n        rec=rec.replace(\")\",\"\")\n        w=str(rec).split(\"-\")[0]\n        l=str(rec).split(\"-\")[1]\n        if team not in dfsdict[row.date]:\n            dfsdict[row.date][team]={}\n        if name not in dfsdict[row.date][team]:\n            \n            if name=='Away Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['away w']=w\n                dfsdict[row.date][team][name]['away l']=l\n            elif name=='Home Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['home w']=w\n                dfsdict[row.date][team][name]['home l']=l\n            elif name=='Neutral Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['neutral w']=w\n                dfsdict[row.date][team][name]['neutral l']=l\n            elif name=='Vs. 1-25 Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['1-25 w']=w\n                dfsdict[row.date][team][name]['1-25 l']=l\n            elif name=='Vs. 26-50 Rating':\n                \n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['26-50 w']=w\n                dfsdict[row.date][team][name]['26-50 l']=l\n            elif name=='Vs. 51-100 Rating':\n                 \n                 dfsdict[row.date][team][name]={}\n                 dfsdict[row.date][team][name]['51-100 w']=w\n                 dfsdict[row.date][team][name]['51-100 l']=l\n            elif name=='Vs. 101-200 Rating':\n                 dfsdict[row.date][team][name]={}\n                 dfsdict[row.date][team][name]['101-200 w']=w\n                 dfsdict[row.date][team][name]['101-200 l']=l\n            elif name=='Vs. 201+ Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['201+ w']=w\n                dfsdict[row.date][team][name]['201+ l']=l\n            elif name=='Predictive Rating':\n                dfsdict[row.date][team]['Predictive Rating']=float(row.Rating)\n                dfsdict[row.date][team]['w']=w\n                dfsdict[row.date][team]['l']=l\n            dfsdict[row.date][team]['season']=float(row.season)\narr=[]\nif '2021-03-15' in dfsdict.keys():\n    del dfsdict['2021-03-15']  \nfor dt in dfsdict:\n    \n    for key in dfsdict[dt]:\n        rowa=[dt]\n        rowa.append(key)\n        rowa.append(dfsdict[dt][key]['season'])\n        rowa.append(dfsdict[dt][key]['w'])\n        rowa.append(dfsdict[dt][key]['l'])\n        rowa.append(dfsdict[dt][key][\"Consistency Rating\"])\n        rowa.append(dfsdict[dt][key][\"Luck Rating\"])\n        rowa.append(dfsdict[dt][key][\"Away Rating\"]['away w'])\n        rowa.append(dfsdict[dt][key][\"Away Rating\"]['away l'])\n        rowa.append(dfsdict[dt][key][\"Home Rating\"]['home w'])\n        rowa.append(dfsdict[dt][key][\"Home Rating\"]['home l'])\n        rowa.append(dfsdict[dt][key][\"Neutral Rating\"]['neutral w'])\n        rowa.append(dfsdict[dt][key][\"Neutral Rating\"]['neutral l'])\n        rowa.append(dfsdict[dt][key][\"Strength Of Schedule\"])\n        rowa.append(dfsdict[dt][key][\"Predictive Rating\"])\n        rowa.append(dfsdict[dt][key][\"Vs. 1-25 Rating\"]['1-25 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 1-25 Rating\"]['1-25 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 26-50 Rating\"]['26-50 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 26-50 Rating\"]['26-50 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 51-100 Rating\"]['51-100 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 51-100 Rating\"]['51-100 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 101-200 Rating\"]['101-200 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 101-200 Rating\"]['101-200 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 201+ Rating\"]['201+ w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 201+ Rating\"]['201+ l'])\n        arr.append(rowa)\ndf=pd.DataFrame(arr,columns=['date','team','season','w','l','consistency','luck','awayw','awayl','homew','homel','neutw','neutl','sos','predrating','q1w',\"q1l\",\"q2w\",\"q2l\",\"q3w\",\"q3l\",'q4w','q4l','q5w','q5l'])  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:41:48.117284Z","iopub.execute_input":"2026-01-15T17:41:48.117690Z","iopub.status.idle":"2026-01-15T17:42:19.891366Z","shell.execute_reply.started":"2026-01-15T17:41:48.117663Z","shell.execute_reply":"2026-01-15T17:42:19.890241Z"}},"outputs":[{"name":"stdout","text":"2026-01-15\nPredictive Rankings\nhttps://teamrankings.com/ncaa-basketball/ranking/predictive-by-other/?date=2026-01-15\nPredictive Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/predictive-by-other?date=2026-01-15\nHome Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/home-by-other?date=2026-01-15\nAway Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/away-by-other?date=2026-01-15\nNeutral Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/neutral-by-other?date=2026-01-15\nHome Advantage\nhttps://teamrankings.com/ncaa-basketball/ranking/home-adv-by-other?date=2026-01-15\nStrength Of Schedule\nhttps://teamrankings.com/ncaa-basketball/ranking/schedule-strength-by-other?date=2026-01-15\nLuck Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/luck-by-other?date=2026-01-15\nConsistency Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/consistency-by-other?date=2026-01-15\nVs. 1-25 Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/vs-1-25-by-other?date=2026-01-15\nVs. 26-50 Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/vs-26-50-by-other?date=2026-01-15\nVs. 51-100 Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/vs-51-100-by-other?date=2026-01-15\nVs. 101-200 Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/vs-101-200-by-other?date=2026-01-15\nVs. 201+ Rating\nhttps://teamrankings.com/ncaa-basketball/ranking/vs-201-and-up-by-other?date=2026-01-15\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"seasons['2009']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:00:06.377567Z","iopub.execute_input":"2026-01-15T18:00:06.377918Z","iopub.status.idle":"2026-01-15T18:00:06.383796Z","shell.execute_reply.started":"2026-01-15T18:00:06.377890Z","shell.execute_reply":"2026-01-15T18:00:06.382726Z"}},"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"['20081110', '20090310']"},"metadata":{}}],"execution_count":118},{"cell_type":"code","source":"html=requests.get(\"https://cfbzzz.alwaysdata.net/bracketology/list.php\").text\nsoup=BeautifulSoup(html)\ndfsdict={}\narrt=[]\nurls={}\n\nfor line in html.split(\"<br/>\"):\n    if '.txt' in str(line) and 'filez' not in str(line) and 'bart' not in str(line) and 'al.txt' not in str(line) and 'preds' not in str(line) and 'Home Advantage' not in str(line):\n        url='https://cfbzzz.alwaysdata.net/bracketology/'+line\n        url=url.replace(\" \",\"%20\")\n        dw=pd.read_csv(url)\n        dw=dw.astype({\"season\":float,\"date\":\"string\"})\n        dw=dw[dw.season!=2020]\n        names=set(dw.name.tolist())\n        for n in names:\n            name=n\n        urls[name]=url\n        print(name,dw.columns)\n        for i in range(2008,2026):\n            de=str(i)\n            de=de.replace(\".0\",\"\")\n            de=de+'-03-15'\n            if '2021' not in str(de):\n                dw=dw[dw.date!=de]\n        for row in dw.itertuples():\n            if row.date not in dfsdict:\n                dfsdict[row.date]={}\n            team=str(row.Team).split(\" (\")[0]\n            teamj=str(row.Team)\n            teamj=teamj.replace(\" (NY)\",\" NY\")\n            rec=str(teamj).split(\" (\")[1]\n            \n            rec=rec.replace(\")\",\"\")\n            w=str(rec).split(\"-\")[0]\n            l=str(rec).split(\"-\")[1]\n            if team not in dfsdict[row.date]:\n                dfsdict[row.date][team]={}\n            if name not in dfsdict[row.date][team]:\n                if name=='Away Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['away w']=w\n                    dfsdict[row.date][team][name]['away l']=l\n                elif name=='Home Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['home w']=w\n                    dfsdict[row.date][team][name]['home l']=l\n                elif name=='Neutral Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['neutral w']=w\n                    dfsdict[row.date][team][name]['neutral l']=l\n                elif name=='Vs. 1-25 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['1-25 w']=w\n                    dfsdict[row.date][team][name]['1-25 l']=l\n                elif name=='Vs. 26-50 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['26-50 w']=w\n                    dfsdict[row.date][team][name]['26-50 l']=l\n                elif name=='Vs. 51-100 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['51-100 w']=w\n                    dfsdict[row.date][team][name]['51-100 l']=l\n                elif name=='Vs. 101-200 Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['101-200 w']=w\n                    dfsdict[row.date][team][name]['101-200 l']=l\n                elif name=='Vs. 201+ Rating':\n                    dfsdict[row.date][team][name]={}\n                    dfsdict[row.date][team][name]['201+ w']=w\n                    dfsdict[row.date][team][name]['201+ l']=l\n                elif name=='Predictive Rating':\n                    dfsdict[row.date][team]['Predictive Rating']=float(row.Rating)\n                    dfsdict[row.date][team]['w']=w\n                    dfsdict[row.date][team]['l']=l    \n                else:\n                    dfsdict[row.date][team][name]=float(row.Rating)\n                \n                dfsdict[row.date][team]['season']=float(row.season)\nfor k in gh.keys():\n    q=[]\n    for r in arrw:\n        if r[-2]==k:\n            q.append(r)\n            azw=r\n    cols=gh[k]\n    \n    if 'date' in str(cols):\n        m=1\n        cols.remove(\"date\")\n    if 'season' not in str(cols):\n        cols.append(\"season\")\n    if 'name' not in str(cols):\n        cols.append(\"name\")\n    cols.append(\"date\")\n    \n    print(cols)\n    dk=pd.DataFrame(q,columns=cols)\n    names=set(dk.name.tolist())\n    for n in names:\n        name=n\n    urls[name]=url\n    print(name,dk.columns)\n    for row in dk.itertuples():\n        if row.date not in dfsdict:\n            dfsdict[row.date]={}\n        team=str(row.Team).split(\" (\")[0]\n        teamj=str(row.Team)\n        teamj=teamj.replace(\" (NY)\",\" NY\")\n        rec=str(teamj).split(\" (\")[1]\n            \n        rec=rec.replace(\")\",\"\")\n        w=str(rec).split(\"-\")[0]\n        l=str(rec).split(\"-\")[1]\n        if team not in dfsdict[row.date]:\n            dfsdict[row.date][team]={}\n        if name not in dfsdict[row.date][team]:\n            \n            if name=='Away Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['away w']=w\n                dfsdict[row.date][team][name]['away l']=l\n            elif name=='Home Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['home w']=w\n                dfsdict[row.date][team][name]['home l']=l\n            elif name=='Neutral Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['neutral w']=w\n                dfsdict[row.date][team][name]['neutral l']=l\n            elif name=='Vs. 1-25 Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['1-25 w']=w\n                dfsdict[row.date][team][name]['1-25 l']=l\n            elif name=='Vs. 26-50 Rating':\n                \n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['26-50 w']=w\n                dfsdict[row.date][team][name]['26-50 l']=l\n            elif name=='Vs. 51-100 Rating':\n                 \n                 dfsdict[row.date][team][name]={}\n                 dfsdict[row.date][team][name]['51-100 w']=w\n                 dfsdict[row.date][team][name]['51-100 l']=l\n            elif name=='Vs. 101-200 Rating':\n                 dfsdict[row.date][team][name]={}\n                 dfsdict[row.date][team][name]['101-200 w']=w\n                 dfsdict[row.date][team][name]['101-200 l']=l\n            elif name=='Vs. 201+ Rating':\n                dfsdict[row.date][team][name]={}\n                dfsdict[row.date][team][name]['201+ w']=w\n                dfsdict[row.date][team][name]['201+ l']=l\n            elif name=='Predictive Rating':\n                dfsdict[row.date][team]['Predictive Rating']=float(row.Rating)\n                dfsdict[row.date][team]['w']=w\n                dfsdict[row.date][team]['l']=l\n            dfsdict[row.date][team]['season']=float(row.season)\narr=[]\nif '2021-03-15' in dfsdict.keys():\n    del dfsdict['2021-03-15']  \nfor dt in dfsdict:\n    \n    for key in dfsdict[dt]:\n        rowa=[dt]\n        rowa.append(key)\n        rowa.append(dfsdict[dt][key]['season'])\n        rowa.append(dfsdict[dt][key]['w'])\n        rowa.append(dfsdict[dt][key]['l'])\n        rowa.append(dfsdict[dt][key][\"Consistency Rating\"])\n        rowa.append(dfsdict[dt][key][\"Luck Rating\"])\n        rowa.append(dfsdict[dt][key][\"Away Rating\"]['away w'])\n        rowa.append(dfsdict[dt][key][\"Away Rating\"]['away l'])\n        rowa.append(dfsdict[dt][key][\"Home Rating\"]['home w'])\n        rowa.append(dfsdict[dt][key][\"Home Rating\"]['home l'])\n        rowa.append(dfsdict[dt][key][\"Neutral Rating\"]['neutral w'])\n        rowa.append(dfsdict[dt][key][\"Neutral Rating\"]['neutral l'])\n        rowa.append(dfsdict[dt][key][\"Strength Of Schedule\"])\n        rowa.append(dfsdict[dt][key][\"Predictive Rating\"])\n        rowa.append(dfsdict[dt][key][\"Vs. 1-25 Rating\"]['1-25 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 1-25 Rating\"]['1-25 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 26-50 Rating\"]['26-50 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 26-50 Rating\"]['26-50 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 51-100 Rating\"]['51-100 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 51-100 Rating\"]['51-100 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 101-200 Rating\"]['101-200 w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 101-200 Rating\"]['101-200 l'])\n        rowa.append(dfsdict[dt][key][\"Vs. 201+ Rating\"]['201+ w'])\n        rowa.append(dfsdict[dt][key][\"Vs. 201+ Rating\"]['201+ l'])\n        arr.append(rowa)\ndf=pd.DataFrame(arr,columns=['date','team','season','w','l','consistency','luck','awayw','awayl','homew','homel','neutw','neutl','sos','predrating','q1w',\"q1l\",\"q2w\",\"q2l\",\"q3w\",\"q3l\",'q4w','q4l','q5w','q5l'])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:29:11.610220Z","iopub.execute_input":"2026-01-15T18:29:11.610702Z","iopub.status.idle":"2026-01-15T18:29:51.046165Z","shell.execute_reply.started":"2026-01-15T18:29:11.610662Z","shell.execute_reply":"2026-01-15T18:29:51.044661Z"}},"outputs":[{"name":"stdout","text":"Consistency Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nLuck Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nAway Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nHome Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nNeutral Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nStrength Of Schedule Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nPredictive Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nPredictive Rankings Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nVs. 1-25 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 26-50 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 51-100 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 26-50 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 201+ Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 26-50 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 51-100 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 101-200 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 1-25 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nPredictive Rankings Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nPredictive Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nNeutral Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nLuck Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nAway Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nVs. 101-200 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nConsistency Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nHome Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'v 1-25', 'v 26-50', 'v 51-100',\n       'Hi', 'Lo', 'Last', 'season', 'name', 'date'],\n      dtype='object')\nVs. 201+ Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 101-200 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nStrength Of Schedule Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 201+ Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\nVs. 51-100 Rating Index(['Unnamed: 0', 'Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season',\n       'name', 'date'],\n      dtype='object')\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\nStrength Of Schedule Index(['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date'], dtype='object')\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             raise AssertionError(\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: 24 columns passed, passed data had 25 columns","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-140-2fe230094e37>\u001b[0m in \u001b[0;36m<cell line: 189>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mrowa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfsdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Vs. 201+ Rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'201+ l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'team'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'season'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'consistency'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'luck'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'awayw'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'awayl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'homew'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'homel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'neutw'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'neutl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predrating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q1w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"q1l\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"q2w\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"q2l\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"q3w\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"q3l\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q4w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q4l'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q5w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q5l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[1;32m    852\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                         \u001b[0;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 24 columns passed, passed data had 25 columns"],"ename":"ValueError","evalue":"24 columns passed, passed data had 25 columns","output_type":"error"}],"execution_count":140},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['date','team','season','w','l','consistency','luck','awayw','awayl','homew','homel','neutw','neutl','sos','predrating','q1w',\"q1l\",\"q2w\",\"q2l\",\"q3w\",\"q3l\",'q4w','q4l','q5w','q5l'])  \ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T18:30:22.145119Z","iopub.execute_input":"2026-01-15T18:30:22.145524Z","iopub.status.idle":"2026-01-15T18:30:22.249548Z","shell.execute_reply.started":"2026-01-15T18:30:22.145492Z","shell.execute_reply":"2026-01-15T18:30:22.248449Z"}},"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"             date            team  season   w   l  consistency  luck awayw  \\\n0      2007-12-02         Hofstra  2007.0   1   3          2.7  -0.5     0   \n1      2007-12-02         St Fran  2007.0   3   3          2.8   0.4     0   \n2      2007-12-02  Saint Joseph's  2007.0   4   2          2.9  -0.2     1   \n3      2007-12-02            Ohio  2007.0   2   2          2.9  -0.2     0   \n4      2007-12-02    G Washington  2007.0   2   2          3.0  -0.1     0   \n...           ...             ...     ...  ..  ..          ...   ...   ...   \n22487  2025-03-18         Buffalo  2024.0   9  22         10.7   1.0     3   \n22488  2025-03-18       Morgan St  2024.0  14  18         11.0  -0.3     2   \n22489  2025-03-18   AR-Pine Bluff  2024.0   6  25         11.2  -1.7     2   \n22490  2025-03-18     Maryland ES  2024.0   6  25         11.2  -2.5     1   \n22491  2025-03-18  Miss Valley St  2024.0   3  28         12.2   0.1     1   \n\n      awayl homew  ... q1w q1l q2w  q2l  q3w q3l q4w q4l q5w q5l  \n0         2     1  ...   0   0   0    0    0   1   1   1   0   1  \n1         3     3  ...   0   0   0    0    0   0   0   2   3   1  \n2         1     2  ...   0   1   0    0    0   1   1   0   3   0  \n3         2     2  ...   0   0   0    0    1   2   0   0   1   0  \n4         2     2  ...   0   1   0    0    0   0   0   1   2   0  \n...     ...   ...  ...  ..  ..  ..  ...  ...  ..  ..  ..  ..  ..  \n22487    13     6  ...   0   0   0    1    0   2   0   9   7  10  \n22488    13    11  ...   0   1   0    1    0   1   1   5   9  10  \n22489    17     4  ...   0   1   0    3    0   1   0   1   4  19  \n22490    17     5  ...   0   3   0    1    0   1   0   7   2  13  \n22491    19     2  ...   0   2   0    2    0   5   0   1   1  18  \n\n[22492 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>team</th>\n      <th>season</th>\n      <th>w</th>\n      <th>l</th>\n      <th>consistency</th>\n      <th>luck</th>\n      <th>awayw</th>\n      <th>awayl</th>\n      <th>homew</th>\n      <th>...</th>\n      <th>q1w</th>\n      <th>q1l</th>\n      <th>q2w</th>\n      <th>q2l</th>\n      <th>q3w</th>\n      <th>q3l</th>\n      <th>q4w</th>\n      <th>q4l</th>\n      <th>q5w</th>\n      <th>q5l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-12-02</td>\n      <td>Hofstra</td>\n      <td>2007.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2.7</td>\n      <td>-0.5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-12-02</td>\n      <td>St Fran</td>\n      <td>2007.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2.8</td>\n      <td>0.4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-12-02</td>\n      <td>Saint Joseph's</td>\n      <td>2007.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2.9</td>\n      <td>-0.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-12-02</td>\n      <td>Ohio</td>\n      <td>2007.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.9</td>\n      <td>-0.2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-12-02</td>\n      <td>G Washington</td>\n      <td>2007.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>-0.1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22487</th>\n      <td>2025-03-18</td>\n      <td>Buffalo</td>\n      <td>2024.0</td>\n      <td>9</td>\n      <td>22</td>\n      <td>10.7</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>13</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>7</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>22488</th>\n      <td>2025-03-18</td>\n      <td>Morgan St</td>\n      <td>2024.0</td>\n      <td>14</td>\n      <td>18</td>\n      <td>11.0</td>\n      <td>-0.3</td>\n      <td>2</td>\n      <td>13</td>\n      <td>11</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>22489</th>\n      <td>2025-03-18</td>\n      <td>AR-Pine Bluff</td>\n      <td>2024.0</td>\n      <td>6</td>\n      <td>25</td>\n      <td>11.2</td>\n      <td>-1.7</td>\n      <td>2</td>\n      <td>17</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>22490</th>\n      <td>2025-03-18</td>\n      <td>Maryland ES</td>\n      <td>2024.0</td>\n      <td>6</td>\n      <td>25</td>\n      <td>11.2</td>\n      <td>-2.5</td>\n      <td>1</td>\n      <td>17</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>22491</th>\n      <td>2025-03-18</td>\n      <td>Miss Valley St</td>\n      <td>2024.0</td>\n      <td>3</td>\n      <td>28</td>\n      <td>12.2</td>\n      <td>0.1</td>\n      <td>1</td>\n      <td>19</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>22492 rows × 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":141},{"cell_type":"code","source":"\nfor k in gh.keys():\n    q=[]\n    for r in arrw:\n        if r[-2]==k:\n            q.append(r)\n            azw=r\n    cols=gh[k]\n    \n    if 'date' in str(cols):\n        m=1\n        cols.remove(\"date\")\n    if 'season' not in str(cols):\n        cols.append(\"season\")\n    if 'name' not in str(cols):\n        cols.append(\"name\")\n    cols.append(\"date\")\n    \n    print(cols)\n    dk=pd.DataFrame(q,columns=cols)\n    namey=k+\"new.txt\"\n    dk.to_csv(namey)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T15:59:35.993802Z","iopub.execute_input":"2026-01-15T15:59:35.994176Z","iopub.status.idle":"2026-01-15T15:59:36.391054Z","shell.execute_reply.started":"2026-01-15T15:59:35.994149Z","shell.execute_reply":"2026-01-15T15:59:36.389892Z"}},"outputs":[{"name":"stdout","text":"['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n['Rank', 'Team', 'Rating', 'Hi', 'Lo', 'Last', 'season', 'name', 'date']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dfsdict.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T17:22:49.646369Z","iopub.execute_input":"2026-01-15T17:22:49.646694Z","iopub.status.idle":"2026-01-15T17:22:49.652564Z","shell.execute_reply.started":"2026-01-15T17:22:49.646670Z","shell.execute_reply":"2026-01-15T17:22:49.651538Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"dict_keys(['2007-12-02', '2008-01-16', '2008-02-16', '2008-03-15', '2008-12-02', '2009-01-16', '2009-02-16', '2009-03-15', '2009-12-02', '2010-01-16', '2010-02-16', '2010-03-15', '2010-12-02', '2011-01-16', '2011-02-16', '2011-03-15', '2011-12-02', '2012-01-16', '2012-02-16', '2012-03-15', '2012-12-02', '2013-01-16', '2013-02-16', '2013-03-15', '2013-12-02', '2014-01-16', '2014-02-16', '2014-03-15', '2014-12-02', '2015-01-16', '2015-02-16', '2015-03-15', '2015-12-02', '2016-01-16', '2016-02-16', '2016-03-15', '2016-12-02', '2017-01-16', '2017-02-16', '2017-03-15', '2017-12-02', '2018-01-16', '2018-02-16', '2018-03-15', '2018-12-02', '2019-01-16', '2019-02-16', '2019-03-15', '2021-12-02', '2022-01-16', '2022-02-16', '2022-03-15', '2022-12-02', '2023-01-16', '2023-02-16', '2023-03-15', '2023-12-02', '2024-01-16', '2024-02-16', '2024-03-15', '2024-12-02', '2025-01-16', '2025-02-16', '2025-03-15', '2008-03-17', '2009-03-11', '2010-03-10', '2011-03-14', '2012-03-12', '2013-03-18', '2014-03-17', '2015-03-16', '2016-03-14', '2017-03-13', '2018-03-12', '2019-03-18', '2022-03-14', '2023-03-13', '2024-03-18', '2025-03-18', '2026-01-15'])"},"metadata":{}}],"execution_count":98},{"cell_type":"markdown","source":"# GET ALARGE BIDS","metadata":{}},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport pandas as pd\nimport requests\narr=[]\nimport time\nfor i in range(1950,2026):\n    y=i-1\n    print(i)\n    time.sleep(3)\n    url=\"https://www.sports-reference.com/cbb/seasons/men/\"+str(i)+\"-standings.html\"\n    html=requests.get(url).text\n    html=html.replace(\"<!--\",\"\")\n    html=html.replace(\"-->\",\"\")\n    soup=BeautifulSoup(html)\n    \n    for t in soup.find_all(\"table\"):\n        for tr in t.find_all(\"tr\"):\n            if \"Polls\" not in str(tr) and \"Wins\" not in str(tr):\n                tds=tr.find_all(\"td\")\n                school=tds[0].text\n                conf=tds[1].text\n                w=tds[2].text\n                l=tds[3].text\n                pct=tds[4].text\n                wc=tds[6].text\n                lc=tds[7].text\n                pctconf=tds[8].text\n                pf=tds[10].text\n                pa=tds[11].text\n                srs=tds[13].text\n                sos=tds[14].text\n                if(\"NCAA Tournament\" in str(tr)):\n                    if (\"Tournament Champion\" in str(tr)):\n                        m=1\n                    else:\n                        atlarge=1\n                else:\n                    atlarge=0\n                arr.append([int(y)-1,school,conf,w,l,pct,wc,lc,pctconf,pf,pa,srs,sos,atlarge])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T20:45:12.522675Z","iopub.execute_input":"2025-12-24T20:45:12.523123Z","iopub.status.idle":"2025-12-24T20:50:25.914270Z","shell.execute_reply.started":"2025-12-24T20:45:12.523095Z","shell.execute_reply":"2025-12-24T20:50:25.912894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cdf=pd.DataFrame(arr,columns=['Year','Team','Conf','W','L','PCT','CW','CL','CPCT','PF','PA','SRS','SOS','TY'])\nfor row in cdf.itertuples():\n    cdf.at[row.Index,'Year']=float(row.Year+1)\ncdf.to_csv(\"al.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T20:52:32.588860Z","iopub.execute_input":"2025-12-24T20:52:32.589304Z","iopub.status.idle":"2025-12-24T20:52:33.180677Z","shell.execute_reply.started":"2025-12-24T20:52:32.589266Z","shell.execute_reply":"2025-12-24T20:52:33.179523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport yt_dlp\nimport os\n\n# Define the video URL\nvideo_url = 'https://www.youtube.com/watch?v=3lKW4r2W9Pk'  # Replace with the actual video URL\n!yt-dlp --cookies cookies.txt https://www.youtube.com/watch?v=3lKW4r2W9Pk\n# yt-dlp configuration options\nydl_opts = {\n    'format': 'bestvideo+bestaudio/best',  # Selects the best available video and audio quality\n    'merge_output_format': 'mp4',          # Merges the video and audio into an MP4 file\n    'outtmpl': '%(title)s.%(ext)s',        # Output file name template (e.g., \"Video Title.mp4\")\n    'noplaylist': True,                    # Ensures only a single video is downloaded, even if it's part of a playlist\n    'quiet': False   \n    # 'ffmpeg_location': 'C:/path/to/ffmpeg/bin/ffmpeg.exe', # Uncomment and set if FFmpeg is not in PATH\n}\n\ntry:\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        ydl.download([video_url])\n    print(f\"Successfully downloaded: {video_url}\")\nexcept Exception as e:\n    print(f\"An error occurred during download: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T17:13:00.469086Z","iopub.status.idle":"2025-12-23T17:13:00.469416Z","shell.execute_reply":"2025-12-23T17:13:00.469293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv(\"goodbart.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T01:19:22.133410Z","iopub.execute_input":"2026-01-15T01:19:22.133760Z","iopub.status.idle":"2026-01-15T01:19:22.471540Z","shell.execute_reply.started":"2026-01-15T01:19:22.133731Z","shell.execute_reply":"2026-01-15T01:19:22.470072Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"bartdf=pd.read_csv(\"https://cfbzzz.alwaysdata.net/bracketology/goodbart.txt\")\naldf=pd.read_csv(\"https://cfbzzz.alwaysdata.net/bracketology/al.txt\")\nfor i in range(2013,2026):\n    print(i)\n    bartdf=bartdf[bartdf.RK!=i]\nbartdf=bartdf.replace('\\xa0', ' ', regex=True)\nbartdf['ty']=False\nfor row in bartdf.itertuples():\n    if \"   \" in str(row.team):\n        bartdf.at[row.Index,'ty']=True\n        teamh=str(row.team).split(\"   \")[0]\n        bartdf.at[row.Index,'team']=teamh\nbartdf['team']=bartdf['team'].str.replace(\" St.\",\" State\")\nbartdf=bartdf.replace(\"Albany\",\"Albany (NY)\")\nbartdf=bartdf.replace(\"BYU\",\"Brigham Young\")\nbartdf=bartdf.replace(\"Grambling State\",\"Grambling\")\nbartdf=bartdf.replace(\"VCU\",\"Virginia Commonwealth\")\nbartdf=bartdf.replace(\"Fairleigh Dickinson\",\"FDU\")\nbartdf=bartdf.replace(\"SIU Edwardsville\",\"Southern Illinois-Edwardsville\")\nbartdf=bartdf.replace(\"LIU\",\"Long Island University\")\nbartdf=bartdf.replace(\"Nebraska Omaha\",\"Omaha\")\nbartdf=bartdf.replace(\"UMBC\",\"Maryland-Baltimore County\")\nbartdf=bartdf.replace(\"Miami FL\",\"Miami (FL)\")\nbartdf=bartdf.replace(\"SMU\",\"Southern Methodist\")\nbartdf=bartdf.replace(\"Penn\",\"Pennsylvania\")\nbartdf=bartdf.replace(\"Arkansas Pine Bluff\",\"Arkansas-Pine Bluff\")\nbartdf=bartdf.replace(\"USC Upstate\",\"South Carolina Upstate\")\nbartdf=bartdf.replace(\"St. Francis NY\",\"St. Francis (NY)\")\nbartdf=bartdf.replace(\"UMKC\",\"Kansas City\")\nbartdf=bartdf.replace(\"Central Connecticut\",\"Central Connecticut State\")\nbartdf=bartdf.replace(\"Tennessee Martin\",\"Tennessee-Martin\")\nbartdf=bartdf.replace(\"Saint Francis\",\"Saint Francis (PA)\")\nbartdf=bartdf.replace(\"Illinois Chicago\",\"Illinois-Chicago\")\nbartdf=bartdf.replace(\"Bethune Cookman\",\"Bethune-Cookman\")\nbartdf=bartdf.replace(\"N.C. State\",\"NC State\")\nbartdf=bartdf.replace(\"Charleston\",\"College of Charleston\")\nbartdf=bartdf.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\nbartdf=bartdf.replace(\"Loyola Chicago\",\"Loyola (IL)\")\nbartdf=bartdf.replace(\"Louisiana Monroe\",\"Louisiana-Monroe\")\nbartdf=bartdf.replace(\"Southern Miss\",\"Southern Mississippi\")\nbartdf=bartdf.replace(\"Texas A&M Corpus Chris\",\"Texas A&M-Corpus Christi\")\nbartdf=bartdf.replace(\"Saint Mary's\",\"Saint Mary's (CA)\")\nbartdf=bartdf.replace(\"UT Rio Grande Valley\",\"Texas-Rio Grande Valley\")\nbartdf=bartdf.replace(\"Gardner Webb\",\"Gardner-Webb\")\nbartdf=bartdf.replace(\"LSU\",\"Louisiana State\")\nbartdf=bartdf.replace(\"Loyola MD\",\"Loyola (MD)\")\nbartdf=bartdf.replace(\"UMass Lowell\",\"Massachusetts-Lowell\")\nbartdf=bartdf.replace(\"UNLV\",\"Nevada-Las Vegas\")\nbartdf=bartdf.replace(\"USC\",\"Southern California\")\nbartdf=bartdf.replace(\"Sam Houston State\",\"Sam Houston\")\nbartdf=bartdf.replace(\"Prairie View A&M\",\"Prairie View\")\nbartdf=bartdf.replace(\"Miami OH\",\"Miami (OH)\")\nbartdf=bartdf.replace(\"VMI\",\"Virginia Military Institute\")\nbartdf=bartdf.replace(\"St. John's\",\"St. John's (NY)\")\nbartdf=bartdf.replace(\"FIU\",\"Florida International\")\nbartdf=bartdf.replace(\"Queens\",\"Queens (NC)\")\nbartdf=bartdf.replace(\"Cal Baptist\",\"California Baptist\")\nbartdf=bartdf.replace(\"Mount State Mary's\",\"Mount St. Mary's\")\nalargez={}\nfor i in range(1949,2026):\n    alargez[float(i)]=[]\nfor row in aldf.itertuples():\n    if float(row.TY)==1:\n        alargez[float(row.Year)].append(row.Team)\nfor row in bartdf.itertuples():\n    if row.team in alargez[float(row.season)]:\n        bartdf.at[row.Index,'alarge']=1\n    elif row.ty==True:\n        bartdf=bartdf.drop(row.Index)\n    else:\n        bartdf.at[row.Index,'alarge']=0\nrow.Unnamed: 0,row.RK,row.team,row.conf,row.G,row.Rec,row.ADJOE,row.ADJDE,row.BARTHAG,row.EFG,row.EFGD,row.TOR,row.TORD,row.ORB,row.DRB,row.FTR,row.FTRD,row.2P,row.2PD,row.3P,row.3PD,row.3PR,row.3PRD,row.ADJT,row.WAB,row.season,row.ty,row.alarge","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T21:40:14.416980Z","iopub.execute_input":"2025-12-24T21:40:14.417440Z","iopub.status.idle":"2025-12-24T21:40:19.781924Z","shell.execute_reply.started":"2025-12-24T21:40:14.417404Z","shell.execute_reply":"2025-12-24T21:40:19.780607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dfa","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:00:08.432143Z","iopub.execute_input":"2026-01-15T02:00:08.432482Z","iopub.status.idle":"2026-01-15T02:00:08.448338Z","shell.execute_reply.started":"2026-01-15T02:00:08.432447Z","shell.execute_reply":"2026-01-15T02:00:08.447468Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"      rk                    team  net  kpi  sor    avg  bpi   kp   avgz  q1a  \\\n1      1                Michigan    1    1    9    5.3    3    1    1.7  1-0   \n2      2                 Arizona    2    6    1    3.3    2    2      2  3-0   \n3      3                    Duke    3    7    4      5    1    9    8.3  4-1   \n4      4              Vanderbilt    4    2    5      4   13    5      7  1-0   \n5      5                 Gonzaga    5   12    8   10.7    4    8    7.3  1-1   \n..   ...                     ...  ...  ...  ...    ...  ...  ...    ...  ...   \n361  361            Gardner Webb  361  345  332  342.7  363  359  359.7  0-2   \n362  362              Binghamton  362  365  323    350  355  361  359.3  0-0   \n363  363              Morgan St.  363  359  341  351.3  361  363  362.3  0-0   \n364  364              Coppin St.  364  362  327  351.3  364  364  364.3  0-0   \n365  365  Mississippi Valley St.  365  364  340    356  365  365  364.7  0-0   \n\n      q1   q2  q12   q3    q4  season conf  \n1    4-0  5-1  9-1  3-0   2-0  2025.0  B10  \n2    5-0  4-0  9-0  0-0   7-0  2025.0  B12  \n3    7-1  1-0  8-1  2-0   5-0  2025.0  ACC  \n4    5-0  4-0  9-0  2-0   5-0  2025.0  SEC  \n5    3-1  4-0  7-1  5-0   5-0  2025.0  WCC  \n..   ...  ...  ...  ...   ...     ...  ...  \n361  0-2  0-5  0-7  0-3   0-5  2025.0    ?  \n362  0-1  0-2  0-3  0-1  1-10  2025.0    ?  \n363  0-1  0-3  0-4  0-1   2-8  2025.0    ?  \n364  0-3  0-2  0-5  0-6   2-6  2025.0    ?  \n365  0-5  0-3  0-8  0-2   0-7  2025.0    ?  \n\n[365 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rk</th>\n      <th>team</th>\n      <th>net</th>\n      <th>kpi</th>\n      <th>sor</th>\n      <th>avg</th>\n      <th>bpi</th>\n      <th>kp</th>\n      <th>avgz</th>\n      <th>q1a</th>\n      <th>q1</th>\n      <th>q2</th>\n      <th>q12</th>\n      <th>q3</th>\n      <th>q4</th>\n      <th>season</th>\n      <th>conf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Michigan</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5.3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.7</td>\n      <td>1-0</td>\n      <td>4-0</td>\n      <td>5-1</td>\n      <td>9-1</td>\n      <td>3-0</td>\n      <td>2-0</td>\n      <td>2025.0</td>\n      <td>B10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Arizona</td>\n      <td>2</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3.3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3-0</td>\n      <td>5-0</td>\n      <td>4-0</td>\n      <td>9-0</td>\n      <td>0-0</td>\n      <td>7-0</td>\n      <td>2025.0</td>\n      <td>B12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Duke</td>\n      <td>3</td>\n      <td>7</td>\n      <td>4</td>\n      <td>5</td>\n      <td>1</td>\n      <td>9</td>\n      <td>8.3</td>\n      <td>4-1</td>\n      <td>7-1</td>\n      <td>1-0</td>\n      <td>8-1</td>\n      <td>2-0</td>\n      <td>5-0</td>\n      <td>2025.0</td>\n      <td>ACC</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Vanderbilt</td>\n      <td>4</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>13</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1-0</td>\n      <td>5-0</td>\n      <td>4-0</td>\n      <td>9-0</td>\n      <td>2-0</td>\n      <td>5-0</td>\n      <td>2025.0</td>\n      <td>SEC</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Gonzaga</td>\n      <td>5</td>\n      <td>12</td>\n      <td>8</td>\n      <td>10.7</td>\n      <td>4</td>\n      <td>8</td>\n      <td>7.3</td>\n      <td>1-1</td>\n      <td>3-1</td>\n      <td>4-0</td>\n      <td>7-1</td>\n      <td>5-0</td>\n      <td>5-0</td>\n      <td>2025.0</td>\n      <td>WCC</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>361</td>\n      <td>Gardner Webb</td>\n      <td>361</td>\n      <td>345</td>\n      <td>332</td>\n      <td>342.7</td>\n      <td>363</td>\n      <td>359</td>\n      <td>359.7</td>\n      <td>0-2</td>\n      <td>0-2</td>\n      <td>0-5</td>\n      <td>0-7</td>\n      <td>0-3</td>\n      <td>0-5</td>\n      <td>2025.0</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>362</td>\n      <td>Binghamton</td>\n      <td>362</td>\n      <td>365</td>\n      <td>323</td>\n      <td>350</td>\n      <td>355</td>\n      <td>361</td>\n      <td>359.3</td>\n      <td>0-0</td>\n      <td>0-1</td>\n      <td>0-2</td>\n      <td>0-3</td>\n      <td>0-1</td>\n      <td>1-10</td>\n      <td>2025.0</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>363</td>\n      <td>Morgan St.</td>\n      <td>363</td>\n      <td>359</td>\n      <td>341</td>\n      <td>351.3</td>\n      <td>361</td>\n      <td>363</td>\n      <td>362.3</td>\n      <td>0-0</td>\n      <td>0-1</td>\n      <td>0-3</td>\n      <td>0-4</td>\n      <td>0-1</td>\n      <td>2-8</td>\n      <td>2025.0</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>364</td>\n      <td>Coppin St.</td>\n      <td>364</td>\n      <td>362</td>\n      <td>327</td>\n      <td>351.3</td>\n      <td>364</td>\n      <td>364</td>\n      <td>364.3</td>\n      <td>0-0</td>\n      <td>0-3</td>\n      <td>0-2</td>\n      <td>0-5</td>\n      <td>0-6</td>\n      <td>2-6</td>\n      <td>2025.0</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>365</td>\n      <td>Mississippi Valley St.</td>\n      <td>365</td>\n      <td>364</td>\n      <td>340</td>\n      <td>356</td>\n      <td>365</td>\n      <td>365</td>\n      <td>364.7</td>\n      <td>0-0</td>\n      <td>0-5</td>\n      <td>0-3</td>\n      <td>0-8</td>\n      <td>0-2</td>\n      <td>0-7</td>\n      <td>2025.0</td>\n      <td>?</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 17 columns</p>\n</div>"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"tyz=\"\"\nfor c in bartdf.columns:\n    tyz+=(\"row.\"+c+\",\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T21:43:16.616646Z","iopub.execute_input":"2025-12-24T21:43:16.617025Z","iopub.status.idle":"2025-12-24T21:43:16.622585Z","shell.execute_reply.started":"2025-12-24T21:43:16.616998Z","shell.execute_reply":"2025-12-24T21:43:16.621323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"arrw=[]\n\nfrom playwright.async_api import async_playwright\nimport asyncio\nfrom sklearn.pipeline import Pipeline\n\nasync def fetch(link):\n    async with async_playwright() as p:\n        browser=await p.chromium.launch(headless=True)\n        page=await browser.new_page()\n        await page.goto(link,wait_until=\"load\")\n        last=None\n        for _ in range(10):\n            await page.wait_for_load_state(\"networkidle\")\n            new=page.url\n            if new==last:\n                break\n            last=new\n        try:\n            await page.wait_for_selector(\"table\")\n        except Exception as e:\n            print(e)\n        html=await page.content()\n        await browser.close()\n        soup=BeautifulSoup(html)\n        return soup\nfrom playwright.async_api import async_playwright\nfrom bs4 import BeautifulSoup\nimport asyncio\n\n\n\nasync def fetchz(link, context):\n    page = await context.new_page()\n    await page.route(\"**/*\", lambda route: route.abort() if route.request.resource_type in [\"image\", \"stylesheet\", \"font\"] else route.continue_())\n    await page.goto(link, wait_until=\"domcontentloaded\",timeout=0)\n    last = None\n    for _ in range(10):\n        await page.wait_for_load_state(\"networkidle\")\n        new = page.url\n        if new == last:\n            break\n        last = new\n    try:\n        await page.wait_for_selector(\"table\",state=\"attached\")\n    except Exception as e:\n        print(e)\n    element = await page.query_selector(\"table\")\n    html = await element.inner_html()\n    soup = BeautifulSoup(html, \"html.parser\")\n    await page.close()\n    return soup\n\nasync def main(link):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True,args=[\"--disable-gpu\", \"--no-sandbox\"])\n        context = await browser.new_context()\n        result = await fetchz(link,context)\n        await browser.close()\n        return result\nimport nest_asyncio\nnest_asyncio.apply()\nfrom datetime import date\ntoday=date.today()\ntoday=str(today)\ntoday=today.replace(\"-\",\"\")\narrw=[]\nfor s in dates:\n    print(s)\n    uk=int(s)-1\n    s=str(s)\n    nj=s.replace(\".0\",\"\")\n    s=s.replace(\".0\",\"\")\n    url='https://barttorvik.com/tranketology.php'\n    print(url)\n    loop = asyncio.get_event_loop()\n    table = loop.run_until_complete(main(url))\n    for tr in table.find_all(\"tr\"):\n        if \"AdjOE\" not in str(tr) and 'absolute error' not in str(tr) and 'RESUME' not in str(tr) and 'KPI' not in str(tr):\n            rowz=[]\n            n=0\n            for td in tr.find_all(\"td\"):\n                if 1==1:\n                    if int(s)<2024 and n==8:\n                        m=1\n                    elif int(s)==2025 and n==5:\n                        m=1\n                    elif int(s)==2025 and n==9:\n                        m=1\n                    elif int(s)==2026 and n==5:\n                        m=1\n                    elif int(s)==2026 and n==9:\n                        m=1\n                    elif n==1:\n                        fd=td.find_all(\"a\")[0].text\n                        fd=str(fd)\n                        if fd=='':\n                            print(tr.find_all(\"td\"))\n                        rowz.append(fd)\n                    else:\n                        rowz.append(td.text)\n                n+=1\n            rowz.append(uk)\n            arrw.append(rowz)\ndfa=pd.DataFrame(arrw)\ndfa.columns=['rk','team','net','kpi','sor','avg','bpi','kp','avgz','q1a','q1','q2','q12','q3','q4','season']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T03:12:39.841401Z","iopub.execute_input":"2026-01-15T03:12:39.841744Z","iopub.status.idle":"2026-01-15T03:12:45.124591Z","shell.execute_reply.started":"2026-01-15T03:12:39.841716Z","shell.execute_reply":"2026-01-15T03:12:45.123336Z"}},"outputs":[{"name":"stdout","text":"2026\nhttps://barttorvik.com/tranketology.php\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-97-b8abb69883bf>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0marrw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mdfa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mdfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rk'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'team'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kpi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sor'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bpi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'avgz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q1a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q12'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'q4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'season'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6312\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6315\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 9 elements, new values have 16 elements"],"ename":"ValueError","evalue":"Length mismatch: Expected axis has 9 elements, new values have 16 elements","output_type":"error"}],"execution_count":97},{"cell_type":"code","source":"for t in set(bartdf.team.tolist()):\n    if t not in set(aldf.Team.tolist()):\n        print('bartdf=bartdf.replace(\"'+t+'\",\"\")')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T21:31:52.776289Z","iopub.execute_input":"2025-12-24T21:31:52.776737Z","iopub.status.idle":"2025-12-24T21:31:52.935279Z","shell.execute_reply.started":"2025-12-24T21:31:52.776709Z","shell.execute_reply":"2025-12-24T21:31:52.934190Z"}},"outputs":[],"execution_count":null}]}
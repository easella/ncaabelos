{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30396,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/savageopress12345/mechanical-soup-error?scriptVersionId=118868915\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"ty=df22[df22.Year==2023]\npoints=set(ty.PTS.tolist()+ty.OPP.tolist())\ngames={}\narr=[]\nfor row in ty.itertuples():\n    if row.PTS>row.OPP:\n        name=row.Schl+\"||\"+row.Opp+\"||\"+str(row.PTS)+\"||\"+str(row.OPP)\n        games[name]=row.PTS\n        arr.append([row.Schl,row.Opp,row.PTS,row.OPP,row.Venue,row.Date])\n    if row.PTS<row.OPP:\n        name=row.Opp+\"||\"+row.Schl+\"||\"+str(row.OPP)+\"||\"+str(row.PTS)\n        games[name]=row.OPP\n        arr.append([row.Opp,row.Schl,row.OPP,row.PTS,row.Venue,row.Date])\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.368641Z","iopub.execute_input":"2024-05-10T01:17:40.369141Z","iopub.status.idle":"2024-05-10T01:17:40.692662Z","shell.execute_reply.started":"2024-05-10T01:17:40.369101Z","shell.execute_reply":"2024-05-10T01:17:40.691548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['Winner','Loser','Winner PTS','Loser PTS','Venue','Date'])\ndf=df.sort_values(by='Loser PTS')\ndf=df.iloc[0:10]\nfor row in df.itertuples():\n    print(row)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.694520Z","iopub.execute_input":"2024-05-10T01:17:40.695127Z","iopub.status.idle":"2024-05-10T01:17:40.735929Z","shell.execute_reply.started":"2024-05-10T01:17:40.695088Z","shell.execute_reply":"2024-05-10T01:17:40.735028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[item for item in sorted(games, key=games.get)][0:10]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.737447Z","iopub.execute_input":"2024-05-10T01:17:40.737860Z","iopub.status.idle":"2024-05-10T01:17:40.760119Z","shell.execute_reply.started":"2024-05-10T01:17:40.737823Z","shell.execute_reply":"2024-05-10T01:17:40.759052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myKeys = list(games.keys())\n{i: games[i] for i in myKeys}[0:5]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.762689Z","iopub.execute_input":"2024-05-10T01:17:40.764039Z","iopub.status.idle":"2024-05-10T01:17:40.798949Z","shell.execute_reply.started":"2024-05-10T01:17:40.763977Z","shell.execute_reply":"2024-05-10T01:17:40.791804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1949-1959h.csv\")\ndf3=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1959-1969h.csv\")\ndf4=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1969-1970h.csv\")\ndf5=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1971-1979h.csv\")\nimport re\ndef has_numbers(inputString):\n    return bool(re.search(r'\\d', inputString))\ndf6=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1980-1985h.csv\")\ndf7=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1986-1987h.csv\")\ndf7=df7[df7.Year!=1988]\ndf8=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1988-1989h.csv\")\ndf9=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1990-1992h.csv\")\ndf10=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1993-1994h.csv\")\ndf10=df10[df10.Year<\"1995-96\"]\ndf11=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1995-1996h.csv\")\ndf12=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1997-1999h.csv\")\ndf13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf14=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2005-2011h.csv\")\ndf15=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2012-2020h.csv\")\ndf16=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2021h.csv\")\ndf17=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1949-1988n.csv\")\ndf17=df17[df17.Year!='1971-72']\ndf20=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1971-1972n.csv\")\ndf17=pd.concat([df20,df17])\ndf18=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1989-1999n.csv\")\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:42:10.261709Z","iopub.execute_input":"2024-05-10T01:42:10.262191Z","iopub.status.idle":"2024-05-10T01:42:10.289584Z","shell.execute_reply.started":"2024-05-10T01:42:10.262151Z","shell.execute_reply":"2024-05-10T01:42:10.288175Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport time\nstart_time = time.time()\nprint('done files')\nimport numpy as np\nfrom datetime import datetime\nimport random\nimport string\nfrom decimal import Decimal\nclass Elo:\n    def __init__(self,k,g=1,homefield = 110): \n        self.ratingDict={}\n        self.k = k\n        self.g = g\n        self.homefield= homefield\n    def addPlayer(self,name,rating = 1500):\n        self.ratingDict[name] = rating\n    def gameOver(self, winner, loser, winnerHome,neutral,wp,lp,yr,date,hfa,k):\n        homef=hfa\n        if('True' in str(neutral)):\n            homef=0\n        if(winnerHome==True):\n            \n            elod=(eloLeague.ratingDict[winner]+homef)-(eloLeague.ratingDict[loser])\n        if(winnerHome!=True):\n            \n            elod=(eloLeague.ratingDict[winner])-(homef+eloLeague.ratingDict[loser])\n        \n        elo=float(elod)\n        wp=float(wp)\n        lp=float(lp)\n        o=abs(wp-lp)\n        y=float(((o)+3))\n        \n        mov=((o+3)**0.8)/(7.5+0.006*elod)\n        if winnerHome==True:\n            \n            result = self.expectResult(self.ratingDict[winner]+homef, self.ratingDict[loser])\n        else:\n            result = self.expectResult(self.ratingDict[winner], self.ratingDict[loser]+homef)\n        shift=(self.k*mov)*(1 - result) \n        self.ratingDict[winner]+=shift\n        self.ratingDict[loser]-=shift\n    def expectResult(self, p1, p2):\n        global exp\n        exp = (Decimal(p2)-Decimal(p1))/Decimal(400.0)\n        n2=Decimal(10.0)\n        j=Decimal(exp)\n        o=Decimal(1)/((n2**(j))+Decimal(1))\n        return float(o)\nimport requests\nfrom bs4 import BeautifulSoup,Comment\nimport re, csv\nfrom bs4 import BeautifulSoup as bs\nuteams=requests.get(\"https://ontheroadtovote.com/ncaaf/caabteams.json\").json() \nd2urls={}\nd2urls[2001]='https://ontheroadtovote.com/ncaaf/prefbs/2001.html'\nfor i in range(2002,2024):\n    url='https://ontheroadtovote.com/ncaaf/prefbs/masseyratings.com'+str(i)+\".webarchive\"\n    d2urls[str(i)]=url\nthearr=[]\nabbreviations = [\n    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#States.\n    \"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"IA\",\n    \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\", \"MI\", \"MN\", \"MO\",\n    \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\",\n    \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\",\n    \"WV\", \"WY\",\n    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Federal_district.\n    \"DC\",\n    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Inhabited_territories.\n    \"AS\", \"GU\", \"MP\", \"PR\", \"VI\",\n]\nimport re\nimport pandas as pd\nstandings=pd.read_csv(\"https://ontheroadtovote.com/ncaab/d1vsnond1/teams/d1standings.txt\")\nfrom datetime import date\ntoday=str(date.today())\nfrom datetime import timedelta\nstandings=pd.read_csv(\"https://ontheroadtovote.com/ncaab/updatedstandings.csv\")\nw=0\nl=0\nnames=[]\ndef replace(n):\n    string=n\n    for letter in letters:\n        string=string.replace(letter+\" Stateate\",letter+\" State\")\n    return string\nnames=set()\nfrom datetime import date\ntoday=date.today()\noldconfs=pd.read_csv(\"https://ontheroadtovote.com/ncaab/old.csv\")\nimport json\nhbcus=['Texas Southern','Coppin State','Morgan State','North Carolina Central','Morgan State','Howard','Norfolk State','South Carolina State','Delaware State','Grambling','Southern','Alcorn State','North Carolina A&T','Tennessee State','Chicago State','Hampton','Bethune-Cookman','Alabama A&M','Prairie View A&M','Mississippi Valley State','Alabama State','Arkansas-Pine Bluff','Florida A&M','Jackson State','Maryland-Eastern Shore']\nw=0\nl=0\nfrom datetime import datetime\ndf2 = {'Unnamed: 0':'t','Rk':4,'School':'Hiram','Conf':'Independent','Year':1893,'W':1,'L':0}\noldconfs.append(df2,ignore_index=True)\nmsqe={}\ncurrSeason=1949\nfor i in range(9,22):\n    msqe[str(i)]=set()\ndf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/cbbstandings.csv\")\nconfs={}\nfor i in range(1949,2025):\n    confs[i]={}\ndf=df.replace(\"PCC (North)\",\"PCC\")\ndf=df.replace(\"PCC (South)\",\"PCC\")\ndf=df.replace(\"Mid-Atl (Eastern)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (Western)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (East)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (West)\",\"Mid-Atl\")\ndf=df.replace(\"ECC (West)\",\"ECC\")\ndf=df.replace(\"ECC (East)\",\"ECC\")\ndf=df.replace(\"ECBL (East)\",\"ECBL\")\ndf=df.replace(\"ECBL (West)\",\"ECBL\")\ndf=df.replace(\"EAA (West)\",\"EAA\")\ndf=df.replace(\"EAA (East)\",\"EAA\")\ndf=df.replace(\"ECACM (North)\",\"ECACM\")\ndf=df.replace(\"ECACM (South)\",\"ECACM\")\ndf=df.replace(\"A-10 (East)\",\"A-10\")\ndf=df.replace(\"A-10 (West)\",\"A-10\")\ndf=df.replace(\"MAAC (South)\",\"MAAC\")\ndf=df.replace(\"MAAC (North)\",\"MAAC\")\ndf=df.replace(\"CUSA (Blue)\",\"CUSA\")\ndf=df.replace(\"CUSA (Red)\",\"CUSA\")\ndf=df.replace(\"CUSA (White)\",\"CUSA\")\ndf=df.replace(\"Big East (East)\",\"Big East\")\ndf=df.replace(\"MAC (East)\",\"MAC\")\ndf=df.replace(\"SEC (East)\",\"SEC\")\ndf=df.replace(\"Southern (North)\",'Southern')\ndf=df.replace(\"Southern (South)\",\"Southern\")\ndf=df.replace(\"WAC (Pacific)\",\"WAC\")\ndf=df.replace(\"CUSA (National)\",\"CUSA\")\ndf=df.replace(\"TAAC (East)\",\"TAAC\")\ndf=df.replace(\"Sun Belt (West)\",\"Sun Belt\")\ndf=df.replace(\"TAAC (West)\",\"TAAC\")\ndf=df.replace(\"A-Sun (North)\",\"A-Sun\")\ndf=df.replace(\"MAC (West)\",\"MAC\")\ndf=df.replace(\"Big East (West)\",\"Big East\")\ndf=df.replace(\"SEC (West)\",\"SEC\")\ndf=df.replace(\"Southland (West)\",\"Southland\")\ndf=df.replace(\"Southland (East)\",\"Southland\")\ndf=df.replace(\"OVC (East)\",\"OVC\")\ndf=df.replace(\"OVC (West)\",\"OVC\")\ndf=df.replace(\"Big South (North)\",\"Big South\")\ndf=df.replace(\"Big South (South)\",\"Big South\")\ndf=df.replace(\"A-Sun (East)\",\"A-Sun\")\ndf=df.replace(\"Patriot (Central)\",\"Patriot\")\ndf=df.replace(\"WAC (Mountain)\",\"WAC\")\ndf=df.replace(\"CUSA (American)\",\"CUSA\")\ndf=df.replace(\"Big West (West)\",\"Big West\")\ndf=df.replace(\"CUSA (East)\",\"CUSA\")\ndf=df.replace(\"Patriot (North)\",\"Patriot\")\ndf=df.replace(\"CUSA (West)\",\"CUSA\")\ndf=df.replace(\"A-Sun (West)\",\"A-Sun\")\ndf=df.replace(\"Patriot (South)\",\"Patriot\")\ndf=df.replace(\"A-Sun (South)\",\"A-Sun\")\ndf=df.replace(\"MEAC (Southern)\",\"MEAC\")\ndf=df.replace(\"MEAC (Northern)\",\"MEAC\")\ndf=df.replace(\"Sun Belt (East)\",\"Sun Belt\")\ndf=df.replace(\"Big West (West)\",\"Big West\")\ndf=df.replace(\"Big West (East)\",\"Big West\")\ndf=df.replace(\"Big East (Big East 6)\",\"Big East\")\ndf=df.replace(\"Big East (Big East 7)\",\"Big East\")\nstandings=pd.read_csv(\"https://ontheroadtovote.com/ncaab/d1vsnond1/teams/d1standings.txt\")\nstandings=standings.replace(\"Florida Gulf Cost\",\"Florida Gulf Coast\")\nfor row in standings.itertuples():\n    if float(row.Year)>1948:\n        confs[float(row.Year)][str(row.Schl)]=str(row.Conference)\nfor row in df.itertuples():\n    s=row.School\n    s=s.replace(\"FDU\",'Fairleigh Dickinson')\n    s=s.replace(\"UCF\",\"Central Florida\")\n    confs[float(row.Year)][str(s)]=row.Conf\npreds={}\nswac=['Grambling','Alcorn State',\"Jackson State\",'Prairie View','Texas Southern','Arkansas-Pine Bluff','Southern','Bethune-Cookman','Alabama State','Florida A&M','Alabama A&M','Mississippi Valley State']\nmeac=['North Carolina Central','Coppin State','Maryland-Eastern Shore','Norfolk State','Howard','South Carolina State','Morgan State','Delaware State']\nconfy={}\nfor conf in set(df.Conf.tolist()):\n    confy[conf]={}\nfor row in df.itertuples():\n    confy[row.Conf][float(row.Year)]=[]\nfor row in df.itertuples():\n    confy[row.Conf]=[]\n\n\nkval=20\neloLeague = Elo(k = kval)\nprint(\"go through games\")\ndid=[]\nrev=0.73\nwe=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/prefbs/allbbz.csv\")\ntz={}\nh=requests.get(\"https://ontheroadtovote.com/ncaaf/prefbs/alltz.txt\").text\nh=str(h)\nh=h.split(\"\\n\")\nwe['homep']=we['homep'].fillna(\"35\")\nwe=we.astype({\"homep\":float,\"awayp\":float})\n\nfor line in h:\n    tz[line.split(\"|\")[0]]=line.split(\"|\")[1]\nfor i in range(1949,2000):\n    wez=we[we.season==i]\n    for row in wez.itertuples():\n        s=str(row.home)\n        o=str(row.away)\n        if s in tz:\n            s=tz[s]\n        if o in tz:\n            o=tz[o]\n        sz=row.season\n        o=o.strip()\n        s=s.strip()\n        if o=='Bowling Green':\n            o='Bowling Green State'\n        if s=='Bowling Green':\n            s='Bowling Green State'\n        row=[float(row.date),s,o,row.homep,row.awayp,row.venue,row.season,row.notes,False]\n        if s in confs[float(sz)] and o in confs[float(sz)]:\n            thearr.append(row)\nprint(\"did old\")\nprint(len(thearr))\ndf13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf13=df13[df13.Year!='Year']\ndf13[df13.Year=='2000-01']\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")\ndf19=df19[df19.Year!='Year']\ndf19[df19.Year=='2000-01']\ndf2=pd.concat([df19,df13])\ndf2=df2.sort_values(by='Date')\nuteams['Bowling Green']='Bowling Green State'\nfor row in df2.itertuples():\n    o=row.Opp\n    s=row.Schl\n    if o in uteams:\n        o=uteams[o]\n    if s in uteams:\n        s=uteams[s]\n    if o in confs[2000] and s in confs[2000]:\n        thearr.append([row.Date,s,o,row.PTS,row.OPP,'vs',2000,'notes',row.neutral])\nfor key in d2urls:\n    print(key)\n    r = requests.get(d2urls[key])\n    soup = BeautifulSoup(r.text, 'lxml')\n    p = re.compile(r'([^0-9-]+)\\s{3,}')\n    p2 = re.compile(r'\\s(\\d+)\\s')\n    aa=str(BeautifulSoup(r.text, 'lxml'))\n    aa=str(aa)\n    aa=(aa.split(\"<hr/><pre>\")[1])\n    aa=aa.replace(\"               \",\",\")\n    aa=aa.replace(\"  \",\",\")\n    for i in range(0,10):\n        aa=aa.replace(str(i)+\" \",str(i)+\",\") \n    aa=aa.replace(\",,,,,,\",\",\")\n    \n    q=aa\n    q=q.split(\"\\n\")\n    for line in q:\n        line=str(line)\n        if 'Games' not in str(line) and str(line)!='' and '<' not in str(line):\n            j=line[1]\n            n=False\n            if \"@\" not in str(line):\n                n=True\n            line = list(line.split(','))\n            v=\"vs\"\n            if \"@\" in str(line[1]):\n                v=\"vs\"\n            else:\n                v='@'\n            date=str(line[0])\n            line=str(line)\n            line=line.replace(\"[\",\"\")\n            line=line.replace(\"]\",\"\")\n            line=line.replace(\"'\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\",@\",\",\")\n            line=line.replace(\"@\",\"\")\n            line = list(line.split(','))\n            lines=[]\n            for l in line:\n                if l==' ' :\n                    m=1\n                else:\n                    lines.append(l)\n            line=lines\n            s=line[1]\n            s=s.lstrip()\n            s=s.rstrip()\n            o=line[3]\n            o=o.lstrip()\n            o=o.rstrip()\n            o=o.replace(\"amp;\",\"\")\n            s=s.replace(\"amp;\",\"\")\n            if s in uteams:\n                s=uteams[s]\n            if o in uteams:\n                o=uteams[o]\n            if len(line)>7:\n                notes=line[7]\n                notes=notes.strip()\n                if notes in abbreviations:\n                    n=True\n            if s  not in confs[float(key)] or o not in confs[float(key)]:\n                m=1\n            else:\n                row=[date,s,o,line[2],line[4],v,float(key),'notes',n]\n            thearr.append(row)\n\nfrom bs4 import BeautifulSoup,Comment\ndf22=pd.DataFrame(thearr,columns=['Date','Schl',\"Opp\",'PTS','OPP','Venue','Year','Notes','neutral'])\ndf22=df22.astype({\"Venue\":\"string\"})\ndf22=df22.astype({\"neutral\":\"string\"})\nprint(\"created df22\")\nprint(set(df22.Year.tolist()))\ndf22['Venue']=df22['Venue'].replace(\"NA?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"A?\",\"@\")\ndf22['Venue']=df22['Venue'].replace(\"AH?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"AN?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"HA?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"HN?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"NA?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"NN\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"NH?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"N\\xa0\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"N?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"H?\",\"H\")\ndf22['Venue']=df22['Venue'].replace(\"A?\",\"A\")\ndf22['Venue']=df22['Venue'].replace(\"n\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"?\",\"N\")\ndf22=df22.fillna(\"35\")\ndf22=df22.astype({\"PTS\":float,\"OPP\":float})\nfor row in df22.itertuples():\n    if row.Venue=='A':\n        df22.at[row.Index,'Venue']='@'\n    if row.Venue=='H' or row.Venue=='N':\n        df22.at[row.Index,'Venue']='vs'\n    if row.Venue=='N':\n        df22.at[row.Index,'neutral']='True'\n    else:\n        df22.at[row.Index,'neutral']='False'\ndf22=df22.astype({\"Date\":\"string\"})\ndf22['Date']=df22['Date'].str.replace(\"-\",\"\")\nfrom datetime import date\ndf22=df22.astype({\"Date\":float})\ntoday=str(date.today())\ntoday=today.replace(\"-\",\"\")\ndf22=df22.replace(\"Texas Christian\",'TCU')\nhfas={}\nfor game in df22.itertuples():\n    if game.Schl in confs[game.Year] and game.Opp in confs[game.Year]:\n        \n        if confs[float(game.Year)][game.Schl]!=confs[float(game.Year)][game.Opp]:\n            sconf=confs[float(game.Year)][game.Schl]\n            confy[sconf].append(game.PTS-game.OPP)\n            oconf=confs[float(game.Year)][game.Opp]\n            confy[oconf].append(game.OPP-game.PTS)\nfor game in df22.itertuples():\n    \n    if game.Schl in confs[game.Year] and game.Opp in confs[game.Year]:\n        if game.neutral==True or game.neutral=='True':\n            m=1\n        else:\n            \n            sc=confs[game.Year][game.Schl]\n            oc=confs[game.Year][game.Opp]\n            if sc not in hfas:\n                hfas[sc]=[]\n            if oc not in hfas:\n                hfas[oc]=[]\n            if game.Venue!='@':\n                hfas[sc].append(game.PTS-game.OPP)\n            else:\n                hfas[oc].append(game.OPP-game.PTS)\nkval=20\nfor key in hfas:\n    \n    hfas[key]=(np.mean(hfas[key]))\n    hfas[key]=round(hfas[key])*kval\n    hfas[key]=round(hfas[key])\nmean=np.mean(list(hfas.values()))\nmean=round(mean,-1)\nrev=0.70\nfor key in hfas:\n    num=((1-rev)*hfas[key])+(rev*(3*kval))\n    num=hfas[key]\n    hfas[key]=num\nl=0\nw=0\nfor row in df22.itertuples():\n    if row.Schl not in did:\n        num=round(np.mean(confy[confs[row.Year][row.Schl]]))\n        num=num*kval\n        num=num*(1-rev)\n        eloLeague.addPlayer(row.Schl,rating=1500+num)\n        did.append(row.Schl)\n    if row.Opp not in did:\n        num=round(np.mean(confy[confs[row.Year][row.Opp]]))\n        num=num*kval\n        num=num*(1-rev)\n        eloLeague.addPlayer(row.Opp,rating=1500+num)\n        did.append(row.Opp)\nkeys={}\narr=[]\nfor i in range(2011,2015):\n    url='https://ontheroadtovote.com/ncaaf/prefbs/ys/'+str(i)+\"rat.txt\"\n    df=pd.read_csv(url)\n    for row in df.itertuples():\n        date=str(row.Date)\n        date=date.replace(\"-\",\"\")\n        rating=str(row.Rating)\n        if \"--\" in str(rating) and float(row.Year)==2019:\n            rating=-0.1\n        rat=float(rating)\n        arr.append([row.Team,rat,float(row.Year),float(date)])\nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/2015-2016rat.txt'\ndf=pd.read_csv(url)\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    arr.append([row.Team,float(row.Rating),float(row.Year),float(date)])\nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/2017-2018rat.txt'\ndf=pd.read_csv(url)\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    arr.append([row.Team,float(row.Rating),float(row.Year),float(date)]) \nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/2019-2023rat.txt'\ndf=pd.read_csv(url)\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    rating=str(row.Rating)\n    if \"--\" in str(rating) and float(row.Year)==2019:\n        rating=-0.1\n    rat=float(rating)\n    arr.append([row.Team,rat,float(row.Year),float(date)])\nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/posty.txt'\ndf=pd.read_csv(url)\ndf=df.astype({\"Year\":float})\ndf=df[df.Year>2010]\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    arr.append([row.Team,float(row.Rating),float(row.Year),float(date)])\ndf=pd.DataFrame(arr,columns=['Team','Rating','Year','Date'])\ndf=pd.DataFrame(arr,columns=['Team','Rating','Year','Date'])\ndf=df.replace(\"Abl Christian\",\"Abilene Christian\")\ndf=df.replace(\"AR Lit Rock\",\"Little Rock\")\ndf=df.replace(\"Alab A&M\",\"Alabama A&M\")\ndf=df.replace(\"IPFW\",\"Purdue Fort Wayne\")\ndf=df.replace(\"N Carolina\",\"North Carolina\")\ndf=df.replace(\"Hsn Christian\",\"Houston Christian\")\ndf=df.replace(\"LIU\",\"Long Island University\")\ndf['Team']=df['Team'].str.replace(\" St\",\" State\")\ndf['Team']=df['Team'].str.replace(\" Stateate\",\" State\")\ndf['Team']=df['Team'].str.replace(\" Stateate\",\" State\")\ndf=df.replace(\"Ark Pine Bl\",\"Arkansas-Pine Bluff\")\ndf=df.replace(\"Albany\",\"Albany (NY)\")\ndf=df.replace(\"Boston U\",\"Boston University\")\ndf=df.replace(\"S Carolina\",\"South Carolina\")\ndf=df.replace(\"Boston Col\",\"Boston College\")\ndf=df.replace(\"Beth-Cook\",\"Bethune-Cookman\")\ndf=df.replace(\"Bowling Grn\",\"Bowling Green\")\ndf=df.replace(\"Cal Baptist\",\"California Baptist\")\ndf['Team']=df['Team'].str.replace(\"CS \",\"Cal State \")\ndf['Team']=df['Team'].str.replace(\" Mich\",\" Michigan\")\ndf=df.replace(\"Central Ark\",\"Central Arkansas\")\ndf=df.replace(\"Central Conn\",\"Central Connecticut\")\ndf=df.replace(\"Cal State Nrdge\",\"Cal State Northridge\")\ndf=df.replace(\"Charl South\",\"Charleston Southern\")\ndf=df.replace(\"Coastal Car\",\"Coastal Carolina\")\ndf=df.replace(\"Col Charlestn\",\"College of Charleston\")\ndf['Team']=df['Team'].str.replace(\"E \",\"Eastern \")\ndf=df.replace(\"Eastern Tenn State\",\"East Tennessee State\")\ndf=df.replace(\"Eastern Michiganigan\",\"Eastern Michigan\")\ndf=df.replace(\"Eastern Carolina\",\"East Carolina\")\ndf=df.replace(\"USC\",\"Southern California\")\ndf=df.replace(\"LSU\",\"Louisiana State\")\ndf=df.replace(\"Florida Intl\",\"Florida International\")\ndf=df.replace(\"Fla Atlantic\",\"Florida Atlantic\")\ndf=df.replace(\"Fla Gulf Cst\",\"Florida Gulf Coast\")\ndf['Team']=df['Team'].str.replace(\"GA \",\"Georgia \")\ndf['Team']=df['Team'].str.replace(\"Geo \",\"George \")\ndf=df.replace(\"Grd Canyon\",\"Grand Canyon\")\ndf=df.replace(\"Loyola-Chi\",\"Loyola (IL)\")\ndf=df.replace(\"Lg Beach State\",\"Long Beach State\")\ndf=df.replace(\"Incar Word\",\"Incarnate Word\")\ndf=df.replace(\"IL-Chicago\",\"Illinois-Chicago\")\ndf=df.replace(\"Gard-Webb\",\"Gardner-Webb\")\ndf=df.replace(\"Grambling State\",\"Grambling\")\ndf=df.replace(\"Jksnville State\",\"Jacksonville State\")\ndf=df.replace(\"James Mad\",\"James Madison\")\ndf=df.replace(\"LIU-Brooklyn\",\"Long Island University\")\ndf=df.replace(\"LA Tech\",\"Louisiana Tech\")\ndf=df.replace(\"F Dickinson\",\"Fairleigh Dickinson\")\ndf=df.replace(\"Loyola-MD\",\"Loyola (MD)\")\ndf=df.replace(\"Loyola Mym\",\"Loyola Marymount\")\ndf=df.replace(\"Mass Lowell\",\"Massachusetts-Lowell\")\ndf=df.replace(\"Middle Tenn\",\"Middle Tennessee\")\ndf=df.replace(\"Miss State\",\"Mississippi State\")\ndf=df.replace(\"Miss Val State\",\"Mississippi Valley State\")\ndf=df.replace(\"Centenary\",\"Centenary (LA)\")\ndf=df.replace(\"Maryland BC\",\"Maryland-Baltimore County\")\ndf=df.replace(\"Maryland ES\",\"Maryland-Eastern Shore\")\ndf['Team']=df['Team'].str.replace(\"NC-\",\"UNC \")\ndf['Team']=df['Team'].str.replace(\"N \",\"Northern \")\ndf['Team']=df['Team'].str.replace(\"Northern Dakota State\",\"North Dakota State\")\ndf['Team']=df['Team'].str.replace(\"Northern Florida\",\"North Florida\")\ndf['Team']=df['Team'].str.replace(\"Northern Hampshire\",\"New Hampshire\")\ndf=df.replace(\"Nicholls\",\"Nicholls State\")\ndf=df.replace(\"NW State\",\"Northwestern State\")\ndf=df.replace(\"NC A&T\",\"North Carolina A&T\")\ndf=df.replace(\"Neb-Omaha\",\"Omaha\")\ndf=df.replace(\"App State\",\"Appalachian State\")\ndf=df.replace(\"Miami\",\"Miami (FL)\")\ndf=df.replace(\"Queens\",\"Queens (NY)\")\ndf=df.replace(\"NorthernMex State\",\"New Mexico State\")\ndf=df.replace(\"S Indiana\",\"Southern Indiana\")\ndf=df.replace(\"S Illinois\",\"Southern Illinois\")\ndf=df.replace(\"S Alabama\",\"South Alabama\")\ndf=df.replace(\"S Carolina\",\"South Carolina\")\ndf=df.replace(\"S Florida\",\"South Florida\")\ndf=df.replace(\"S Mississippi\",\"Southern Mississippi\")\ndf=df.replace(\"S Methodist\",\"Southern Methodist\")\ndf=df.replace(\"S Dakota St\",\"South Dakota State\")\ndf=df.replace(\"S Car State\",\"South Carolina State\")\ndf=df.replace(\"Wm & Mary\",\"William & Mary\")\ndf=df.replace(\"S Utah\",\"Southern Utah\")\ndf=df.replace(\"SC Upstate\",\"South Carolina Upstate\")\ndf=df.replace(\"Rob Morris\",\"Robert Morris\")\ndf=df.replace(\"SEastern Louisiana\",\"Southeastern Louisiana\")\ndf=df.replace(\"SEastern Missouri\",\"Southeast Missouri State\")\ndf=df.replace(\"SIU Edward\",\"Southern Illinois-Edwardsville\")\ndf=df.replace(\"Sac State\",\"Sacramento State\")\ndf=df.replace(\"Sacred Hrt\",\"Sacred Heart\")\ndf=df.replace(\"Sam Hous State\",\"Sam Houston\")\ndf=df.replace(\"UNC Grnsboro\",\"UNC Greensboro\")\ndf=df.replace(\"S Dakota State\",\"South Dakota State\")\ndf=df.replace(\"Citadel\",\"The Citadel\")\ndf=df.replace(\"VA Tech\",\"Virginia Tech\")\ndf=df.replace(\"BYU\",\"Brigham Young\")\ndf=df.replace(\"VCU\",\"Virginia Commonwealth\")\ndf=df.replace(\"U Mass\",\"Massachusetts\")\ndf=df.replace(\"NC Central\",\"North Carolina Central\")\ndf=df.replace(\"W Kentucky\",\"Western Kentucky\")\ndf=df.replace(\"UCSB\",\"UC Santa Barbara\")\ndf=df.replace(\"St Peters\",\"Saint Peter's\")\ndf=df.replace(\"Neb Omaha\",\"Omaha\")\ndf=df.replace(\"St Fran (NY)\",\"St. Francis (NY)\")\ndf=df.replace(\"St Fran (PA)\",\"Saint Francis (PA)\")\ndf=df.replace(\"TNorthern State\",\"Tennessee State\")\ndf=df.replace(\"TNorthern Martin\",\"Tennessee-Martin\")\ndf=df.replace(\"UCSB\",\"UC Santa Barbara\")\ndf=df.replace(\"TX A&M-CC\",\"Texas A&M-Corpus Christi\")\ndf=df.replace(\"Central Connecticut\",\"Central Connecticut State\")\ndf=df.replace(\"VMI\",\"Virginia Military Institute\")\ndf=df.replace(\"U Penn\",\"Pennsylvania\")\ndf=df.replace(\"Wash State\",\"Washington State\")\ndf=df.replace(\"TX Southern\",\"Texas Southern\")\ndf=df.replace(\"TX A&M-Com\",\"Texas A&M-Commerce\")\ndf=df.replace(\"W Illinois\",\"Western Illinois\")\ndf=df.replace(\"Loyola Mymt\",\"Loyola Marymount\")\ndf=df.replace(\"UCF\",\"Central Florida\")\ndf=df.replace(\"W Virginia\",\"West Virginia\")\ndf=df.replace(\"TNorthern Tech\",\"Tennessee Tech\")\ndf=df.replace(\"WI-Milwkee\",\"Milwaukee\")\ndf=df.replace(\"St Marys\",\"Saint Mary's (CA)\")\ndf=df.replace(\"George Wshgtn\",\"George Washington\")\ndf=df.replace(\"St Johns\",\"St. John's (NY)\")\ndf=df.replace(\"W Carolina\",\"Western Carolina\")\ndf=df.replace(\"Cal State Bakersfld\",\"Cal State Bakersfield\")\ndf=df.replace(\"UL Monroe\",\"Louisiana-Monroe\")\ndf=df.replace(\"Northern Mex State\",\"New Mexico State\")\ndf=df.replace(\"UCSD\",\"UC San Diego\")\ndf=df.replace(\"W Michiganigan\",\"Western Michigan\")\ndf=df.replace(\"TNorthern Martin\",\"Tennessee-Martin\")\ndf=df.replace(\"WI-Grn Bay\",\"Green Bay\")\ndf=df.replace(\"TX-Pan Am\",\"Texas-Rio Grande Valley\")\ndf=df.replace(\"Detroit\",\"Detroit Mercy\")\ndf=df.replace(\"Queens (NY)\",\"Queens (NC)\")\ndf=df.replace(\"St Josephs\",\"Saint Joseph's\")\ndf=df.replace(\"St Bonavent\",\"St. Bonaventure\")\ndf=df.replace(\"Ste F Austin\",\"Stephen F. Austin\")\ndf=df.replace(\"UNC Wilmgton\",\"UNC Wilmington\")\ndf=df.replace(\"UNLV\",\"Nevada-Las Vegas\")\ndf=df.replace(\"TX El Paso\",\"UTEP\")\ndf=df.replace(\"Bowling Green\",\"Bowling Green State\")\ndf=df.replace(\"TX Christian\",\"TCU\")\ndf=df.replace(\"Youngs State\",\"Youngstown State\")\ndf=df.replace(\"Eastern Washingtn\",\"Eastern Washington\")\ndf=df.replace(\"TX El Paso\",\"UTEP\")\ndf=df.replace(\"TX-Arlington\",\"UT Arlington\")\ndf=df.replace(\"Northeastrn\",\"Northeastern\")\ndf=df.replace(\"Northern Alabama\",\"North Alabama\")\ndf=df.replace(\"Mt State Marys\",\"Mount St. Mary's\")\ndf=df.replace(\"Wins-Salem\",\"Winston-Salem\")\ndf=df.replace(\"Bowling Green\",\"Bowling Green State\")\ndf=df.replace(\"TX Christian\",\"TCU\")\ndf=df.replace(\"TN State\",\"Tennessee State\")\nfor k in set(df.Team.tolist()):\n    if k not in confs[2023]:\n        print(k)\npwr={}\nkval=20\ndf=df[df.Year>2012]\nfor row in df.itertuples():\n    if float(row.Year) not in pwr:\n        pwr[float(row.Year)]={}\n    if row.Date not in pwr[float(row.Year)]:\n        pwr[float(row.Year)][row.Date]={}\n    if row.Team not in pwr[float(row.Year)][row.Date]:\n        pwr[float(row.Year)][row.Date][row.Team]=float(row.Rating)\nfor t in confy:\n    confy[t]=np.mean(confy[t])*kval\n    confy[t]=confy[t]*(1-rev)\nfor game in df22.itertuples():\n    s=game.Schl\n    o=game.Opp\n    o=o.strip()\n    s=s.strip()\n    season=game.Year\n    if s not in eloLeague.ratingDict.keys():\n        eloLeague.addPlayer(s,rating=1500)\n    if o not in eloLeague.ratingDict.keys():\n        eloLeague.addPlayer(o,rating=1500)\n    while (season)>currSeason: \n        print(season)\n        games=0\n        confz={}\n        for conf in confs[game.Year]:\n            if conf not in eloLeague.ratingDict.keys():\n                eloLeague.addPlayer(conf,rating=1500)\n        if game.Year in pwr:\n            for key in confs[game.Year]:\n                pre=list(pwr[float(game.Year)].keys())[0]\n                num=pwr[game.Year][pre][key]\n                num=num*kval\n                gh=(1500+float(confy[confs[game.Year][key]]))\n                gh=gh+1500\n                gh=gh/2\n                gh=gh+num\n                num=eloLeague.ratingDict[key]+gh\n                num=num/2\n                eloLeague.ratingDict[key]=num\n        for key in confs[game.Year]:\n            conf=confs[game.Year][key]\n            if conf not in confz:\n                confz[conf]=[]\n            confz[conf].append(eloLeague.ratingDict[key])\n        lsdf=df22[df22.Year<game.Year]\n        ls=set(lsdf.Schl.tolist()+lsdf.Opp.tolist())\n        for key in eloLeague.ratingDict.keys():\n            if key  in confs[game.Year] and key in ls:\n                num=np.mean(confz[confs[float(game.Year)][key]])\n                num=num+1500\n                num=num/2\n                eloLeague.ratingDict[key]=(eloLeague.ratingDict[key]*(1-rev))+(num*rev)     \n        currSeason+=1\n    sp=0\n    op=0\n    s=str(game.Schl)\n    o=str(game.Opp)\n    o=o.strip()\n    s=s.strip()\n    if (game.Schl in swac or game.Schl in meac or game.Opp in meac or game.Opp in swac)and(str(o) in confs[2023] and str(s) in confs[2023])and('2023' in str(game.Year)):\n        if 'True' in str(game.neutral):\n            hf=0\n        if game.Venue=='@' and 'True' not in str(game.neutral):\n            hf=hfas[confs[game.Year][game.Opp]]\n            hr=eloLeague.ratingDict[game.Schl]\n            ar=eloLeague.ratingDict[game.Opp]+hf\n        if game.Venue=='vs'  and 'True' not in str(game.neutral):\n            hf=hfas[confs[game.Year][game.Schl]]\n            hr=eloLeague.ratingDict[game.Schl]+hf\n            ar=eloLeague.ratingDict[game.Opp]\n        if hr>ar:\n            spread=round((hr-ar)/21)\n            if spread==0:\n                spread=1\n            name=str(game.Schl)+\" \"+str(game.Venue)+\" \"+str(game.Opp)\n            name=\"On \"+str(game.Date)+\" \"+str(game.Schl)+\" beats \"+str(game.Opp)+\" by \"+str(spread)\n            keys[name]=game.Date   \n        if ar>hr:\n            name=str(game.Schl)+\" \"+str(game.Venue)+\" \"+str(game.Opp)\n            spread=round((ar-hr)/21)\n            if spread==0:\n                spread=1\n            \n            name=\"On \"+str(game.Date)+\" \"+str(game.Opp)+\" beats \"+str(game.Schl)+\" by \"+str(spread)\n            keys[name]=game.Date            \n        \n    if(game.Venue=='@'):\n        if game.Opp not in confs[game.Year]:\n            hf=50\n    else:\n        if game.Schl not in confs[game.Year]:\n            hf=50\n    t1r=0\n    t2r=0\n    k=kval\n    if game.Year in pwr:\n        first=list(pwr[float(game.Year)].keys())[0]\n    if game.Year in pwr and game.Date!=first:\n        key=game.Schl\n        if key in pwr[float(game.Year)][game.Date]:\n            rat=pwr[float(game.Year)][game.Date][key]\n            rat=rat*kval\n            numje=rat\n            numj=(1500)+float(confy[confs[game.Year][key]])\n            numj=numj+1500\n            numj=numj/2\n            numj=numj+numje\n            numj=(numj*(1-rev))+(eloLeague.ratingDict[key]*rev)\n                            \n            avg=eloLeague.ratingDict[key]+numj\n            avg=avg/2\n            eloLeague.ratingDict[key]=avg\n        key=game.Opp\n        if key in pwr[float(game.Year)][game.Date]:\n            rat=pwr[float(game.Year)][game.Date][key]\n            rat=rat*kval\n            numje=rat\n            numj=(1500)+float(confy[confs[game.Year][key]])\n            numj=numj+1500\n            numj=numj/2\n            numj=numj+numje\n            numj=(numj*(1-rev))+(eloLeague.ratingDict[key]*rev)\n                            \n            avg=eloLeague.ratingDict[key]+numj\n            avg=avg/2\n            eloLeague.ratingDict[key]=avg\n    if(game.PTS>game.OPP):\n        homezz=0\n        if(game.Venue!='@'):\n            winnerHomez=True\n            if game.Schl in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Schl]]\n            else:\n                hf=50\n        if(game.Venue=='@'):\n            winnerHomez=False\n            if game.Opp in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Opp]]\n            else:\n                hf=50\n        if 'True'  in str(game.neutral):\n            hf=0\n        if(winnerHomez==True):\n            t1e=eloLeague.ratingDict[game.Schl]+homezz-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]-op+t2r\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp>eloLeague.ratingDict[game.Opp]-op):\n                w+=1\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp<eloLeague.ratingDict[game.Opp]-op):\n                l+=1\n        if(winnerHomez!=True):\n            t1e=eloLeague.ratingDict[game.Schl]-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]+homezz-op+t2r\n            if(eloLeague.ratingDict[game.Schl]-sp>eloLeague.ratingDict[game.Opp]+homezz-op):\n                w+=1\n            if(eloLeague.ratingDict[game.Schl]-sp<eloLeague.ratingDict[game.Opp]+homezz-op):\n                l+=1  \n        df22.at[game.Index,'team1elopre']=t1e\n        df22.at[game.Index,'team2elopre']=t2e\n        eloLeague.gameOver(s,o,winnerHomez,game.neutral,game.PTS,game.OPP,game.Year,game.Date,sp,op,hf,k)\n    if(game.PTS<game.OPP):\n        homezz=0\n        \n        if(game.Venue=='@'):\n            if game.Schl in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Opp]]\n            winnerHomez=True\n        if(game.Venue!='@'):\n            if game.Opp in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Schl]]\n            winnerHomez=False\n        if 'True'  in str(game.neutral):\n            homezz=0\n        if(winnerHomez==True):\n            t1e=eloLeague.ratingDict[game.Schl]-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]+homezz-op+t2r\n            if(eloLeague.ratingDict[game.Schl]-sp>eloLeague.ratingDict[game.Opp]+homezz-op):\n                l+=1\n            if(eloLeague.ratingDict[game.Schl]-sp<eloLeague.ratingDict[game.Opp]+homezz-op):\n                w+=1\n        if(winnerHomez!=True):\n            t1e=eloLeague.ratingDict[game.Schl]+homezz-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]-op+t2r\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp>eloLeague.ratingDict[game.Opp]-op):\n                l+=1\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp<eloLeague.ratingDict[game.Opp]-op):\n                w+=1\n        df22.at[game.Index,'team1elopre']=t1e\n        df22.at[game.Index,'team2elopre']=t2e\n        eloLeague.gameOver(o,s,winnerHomez,game.neutral,game.OPP,game.PTS,game.Year,game.Date,op,sp,hf,k)\n    d1=(s in confs[game.Year] or o in confs[game.Year])\n    for i in range(9,22):\n        spread=abs((t1e-t2e)/float(i))\n        spread=round(spread)\n        if spread==0:\n            spread=1\n        ms=(float(game.PTS)-float(game.OPP))-spread\n        \n        msz = np.square(ms)\n        if d1==True:\n            msqe[str(i)].add(msz)\n    if game.Year in pwr:\n        last=list(pwr[float(game.Year)].keys())[-1]\n    if game.Year in pwr and game.Date==last:\n        for key in confs[game.Year]:\n            row=game\n            if key in pwr[float(game.Year)][row.Date]:\n                am=pwr[float(game.Year)][row.Date+1][key]\n                am=am*kval\n                am=am+1500\n                am=am+eloLeague.ratingDict[key]\n                am=am/2\n                eloLeague.ratingDict[key]=am\n            key=game.Opp\n            if key in pwr[float(game.Year)][row.Date]:\n                am=pwr[float(game.Year)][row.Date+1][key]\n                am=am*kval\n                am=am+1500\n                am=am+eloLeague.ratingDict[key]\n                am=am/2\n                eloLeague.ratingDict[key]=am\n        \nimport numpy as np\nmsqez={}\nfor i in range(9,22):\n    msqez[str(i)]=0\nfor i in range(9,22):\n    msqez[str(i)]=sum(msqe[str(i)])/len(msqe[str(i)])\nmas=min(msqez, key=msqez.get)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(1224-971)/float(mas)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:56:48.684460Z","iopub.execute_input":"2024-10-16T04:56:48.685616Z","iopub.status.idle":"2024-10-16T04:56:48.695029Z","shell.execute_reply.started":"2024-10-16T04:56:48.685558Z","shell.execute_reply":"2024-10-16T04:56:48.693673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df22[df22.Schl=='Mississippi Valley State']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:55:44.884953Z","iopub.execute_input":"2024-10-16T04:55:44.885404Z","iopub.status.idle":"2024-10-16T04:55:45.056832Z","shell.execute_reply.started":"2024-10-16T04:55:44.885369Z","shell.execute_reply":"2024-10-16T04:55:45.055701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url='https://ontheroadtovote.com/ncaaf/prefbs/ys/post.csv'\ndf=pd.read_csv(url)\ndf[df.Year==str(2013)]","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:20:02.735146Z","iopub.execute_input":"2024-10-16T04:20:02.735588Z","iopub.status.idle":"2024-10-16T04:20:02.834772Z","shell.execute_reply.started":"2024-10-16T04:20:02.735551Z","shell.execute_reply":"2024-10-16T04:20:02.833362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"394/float(mas)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:49:14.867199Z","iopub.execute_input":"2024-10-16T04:49:14.868598Z","iopub.status.idle":"2024-10-16T04:49:14.877586Z","shell.execute_reply.started":"2024-10-16T04:49:14.868535Z","shell.execute_reply":"2024-10-16T04:49:14.876089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"124/float(mas)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:50:13.320324Z","iopub.execute_input":"2024-10-16T04:50:13.320779Z","iopub.status.idle":"2024-10-16T04:50:13.328839Z","shell.execute_reply.started":"2024-10-16T04:50:13.320735Z","shell.execute_reply":"2024-10-16T04:50:13.327440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(eloLeague.ratingDict['Texas Southern']+hfas[confs[2023]['Grambling']])-eloLeague.ratingDict['Texas State']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:52:15.866275Z","iopub.execute_input":"2024-10-16T04:52:15.867193Z","iopub.status.idle":"2024-10-16T04:52:15.878228Z","shell.execute_reply.started":"2024-10-16T04:52:15.867138Z","shell.execute_reply":"2024-10-16T04:52:15.876503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"508/18","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:53:20.573910Z","iopub.execute_input":"2024-10-16T04:53:20.575392Z","iopub.status.idle":"2024-10-16T04:53:20.583069Z","shell.execute_reply.started":"2024-10-16T04:53:20.575339Z","shell.execute_reply":"2024-10-16T04:53:20.581635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"633/float(mas)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:54:08.796096Z","iopub.execute_input":"2024-10-16T04:54:08.796552Z","iopub.status.idle":"2024-10-16T04:54:08.804680Z","shell.execute_reply.started":"2024-10-16T04:54:08.796515Z","shell.execute_reply":"2024-10-16T04:54:08.803263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(eloLeague.ratingDict['Utah']+hfas[confs[2023]['Utah']])-eloLeague.ratingDict['Alcorn State']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:54:03.570682Z","iopub.execute_input":"2024-10-16T04:54:03.571333Z","iopub.status.idle":"2024-10-16T04:54:03.581492Z","shell.execute_reply.started":"2024-10-16T04:54:03.571283Z","shell.execute_reply":"2024-10-16T04:54:03.579936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arr=[]\nheaders={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\nyears={}\nimport time\nfor i in range(1949,2025):\n    years[i]=[]\nfor row in df22.itertuples():\n    if float(row.Year)>2005:\n        \n        if float(row.Date) not in years[float(row.Year)]:\n            years[float(row.Year)].append(float(row.Date))\nprint(\"done\")\ny=2012\nfrom fake_useragent import UserAgent\nua = UserAgent()\nfor iz in range(y,y+1):\n    print(iz)\n    iz=str(iz)\n    for date in years[float(iz)]:\n        time.sleep(2)\n        date=str(date)\n        date=date[0]+date[1]+date[2]+date[3]+\"-\"+date[4]+date[5]+\"-\"+date[6]+date[7]\n        date=str(date)\n        url='https://teamrankings.com/ncaa-basketball/ranking/predictive-by-other/?date='+str(date)\n        user_agent = ua.random\n        headers={'User-Agent':user_agent}\n        html=requests.get(url,headers=headers)\n        print(html.status_code)\n        html=html.text\n        soup=BeautifulSoup(html)\n        table=soup.find_all(\"table\")[0]\n        for tr in table.find_all(\"tr\"):\n            if 'Rating' not in str(tr):\n                team=tr.find_all(\"td\")[1]\n                team=team['data-sort']\n                rating=tr.find_all(\"td\")[2].text\n                arr.append([team,rating,iz,date])","metadata":{"execution":{"iopub.status.busy":"2024-10-15T02:27:52.549832Z","iopub.execute_input":"2024-10-15T02:27:52.550353Z","iopub.status.idle":"2024-10-15T02:36:49.898433Z","shell.execute_reply.started":"2024-10-15T02:27:52.550309Z","shell.execute_reply":"2024-10-15T02:36:49.897023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxs={}\narr=[]\nyears={}\nfrom fake_useragent import UserAgent\nua = UserAgent()\nimport time\nfor i in range(1949,2025):\n    years[i]=[]\nfor row in df22.itertuples():\n    if float(row.Year)>2005:\n        \n        if float(row.Date) not in years[float(row.Year)]:\n            years[float(row.Year)].append(float(row.Date))\nfor iz in range(2006,2024):\n    print(iz)\n    iz=float(iz)\n    maxs[iz]=years[iz][-1]\n    maxs[iz]=maxs[iz]+1\n    if 1==1:\n        time.sleep(2)\n        date=maxs[iz]\n        date=str(date)\n        date=date[0]+date[1]+date[2]+date[3]+\"-\"+date[4]+date[5]+\"-\"+date[6]+date[7]\n        date=str(date)\n        url='https://teamrankings.com/ncaa-basketball/ranking/predictive-by-other/?date='+str(date)\n        user_agent = ua.random\n        headers={'User-Agent':user_agent}\n        html=requests.get(url,headers=headers)\n        print(html.status_code)\n        html=html.text\n        soup=BeautifulSoup(html)\n        table=soup.find_all(\"table\")[0]\n        for tr in table.find_all(\"tr\"):\n            if 'Rating' not in str(tr):\n                team=tr.find_all(\"td\")[1]\n                team=team['data-sort']\n                rating=tr.find_all(\"td\")[2].text\n                arr.append([team,rating,iz,date])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:41:01.508723Z","iopub.execute_input":"2024-10-16T04:41:01.509815Z","iopub.status.idle":"2024-10-16T04:42:33.720680Z","shell.execute_reply.started":"2024-10-16T04:41:01.509756Z","shell.execute_reply":"2024-10-16T04:42:33.719394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fake_useragent","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:24:03.456086Z","iopub.execute_input":"2024-10-16T04:24:03.457052Z","iopub.status.idle":"2024-10-16T04:24:21.643126Z","shell.execute_reply.started":"2024-10-16T04:24:03.456993Z","shell.execute_reply":"2024-10-16T04:24:21.641432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for t in confy:\n    confy[t]=np.mean(confy[t])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:21:02.894860Z","iopub.execute_input":"2024-10-16T02:21:02.895744Z","iopub.status.idle":"2024-10-16T02:21:03.042351Z","shell.execute_reply.started":"2024-10-16T02:21:02.895698Z","shell.execute_reply":"2024-10-16T02:21:03.041089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confy[t]","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:21:09.116487Z","iopub.execute_input":"2024-10-16T02:21:09.117101Z","iopub.status.idle":"2024-10-16T02:21:09.127809Z","shell.execute_reply.started":"2024-10-16T02:21:09.117051Z","shell.execute_reply":"2024-10-16T02:21:09.126168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rh={}\nu=[]\nfor team in years[2023]:\n    rh[team]=(eloLeague.ratingDict[team])\n    u.append(eloLeague.ratingDict[team])\nrh=sorted(rh, key=rh.get, reverse=True)\ni=1\nprint(np.mean(u))\nprint(\"Rank||Team||Points Above d1 Average\")\nfor key in rh:\n    print(str(i)+\"  \"+key+\"  \"+str(eloLeague.ratingDict[key]-np.mean(u))+\"\")\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2024-09-19T00:13:27.773459Z","iopub.execute_input":"2024-09-19T00:13:27.773912Z","iopub.status.idle":"2024-09-19T00:13:27.809278Z","shell.execute_reply.started":"2024-09-19T00:13:27.773874Z","shell.execute_reply":"2024-09-19T00:13:27.808156Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"((eloLeague.ratingDict['Creighton']+hfas['Big East'])-(eloLeague.ratingDict['North Dakota State']))/17","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:42:29.780159Z","iopub.execute_input":"2024-09-09T15:42:29.780601Z","iopub.status.idle":"2024-09-09T15:42:29.790001Z","shell.execute_reply.started":"2024-09-09T15:42:29.780565Z","shell.execute_reply":"2024-09-09T15:42:29.788637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['Team','Rating','Year','Date'])\ndf.to_csv(\"posty.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T04:42:46.747207Z","iopub.execute_input":"2024-10-16T04:42:46.748185Z","iopub.status.idle":"2024-10-16T04:42:46.794495Z","shell.execute_reply.started":"2024-10-16T04:42:46.748140Z","shell.execute_reply":"2024-10-16T04:42:46.793091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for row in df22.itertuples():\n    spread=row.team1elopre-row.team2elopre\n    spread=spread/9\n    spread=round(spread)\n    if spread==0:\n        \n        if row.team1elopre>row.team2elopre:\n            spread=1\n        else:\n            spread=-1\n    df22.at[row.Index,'predt1spread']=spread","metadata":{"execution":{"iopub.status.busy":"2024-09-18T23:45:29.638343Z","iopub.execute_input":"2024-09-18T23:45:29.638762Z","iopub.status.idle":"2024-09-18T23:45:36.189593Z","shell.execute_reply.started":"2024-09-18T23:45:29.638729Z","shell.execute_reply":"2024-09-18T23:45:36.188285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t=df[df.Year==2023]\noff=[]\nfor t in list(t.OFF.tolist()):\n    off.append(float(t))\nmax(off)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T22:28:29.931152Z","iopub.execute_input":"2024-09-18T22:28:29.931565Z","iopub.status.idle":"2024-09-18T22:28:29.942871Z","shell.execute_reply.started":"2024-09-18T22:28:29.931533Z","shell.execute_reply":"2024-09-18T22:28:29.941556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"j=np.mean([16,17,20])\n(16*(1-rev))+(rev*j)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T23:54:10.385816Z","iopub.execute_input":"2024-09-18T23:54:10.386278Z","iopub.status.idle":"2024-09-18T23:54:10.395057Z","shell.execute_reply.started":"2024-09-18T23:54:10.386240Z","shell.execute_reply":"2024-09-18T23:54:10.393883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr.find_all(\"td\")[0].text","metadata":{"execution":{"iopub.status.busy":"2024-10-01T04:09:28.454255Z","iopub.execute_input":"2024-10-01T04:09:28.454685Z","iopub.status.idle":"2024-10-01T04:09:28.461873Z","shell.execute_reply.started":"2024-10-01T04:09:28.454647Z","shell.execute_reply":"2024-10-01T04:09:28.460763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport requests\nsep=\"\"\ndef remove_tags(html):\n\n    # parse html content\n    soup = BeautifulSoup(html, \"html.parser\")\n\n    for data in soup(['style', 'script']):\n        # Remove tags\n        data.decompose()\n\n    # return data by retrieving the tag content\n    return ' '.join(soup.stripped_strings)\nyears=[1950,1962,1973,1974]\nimport pandas as pd\nyu=[]\nfrom datetime import datetime,timedelta\nhtml=requests.get(\"https://academics.smcvt.edu/jtrono/BBallArchive.htm\").text\nsoup=BeautifulSoup(html)\ntable=soup.find_all(\"table\")[0]\narr=[]\nfor tr in table.find_all(\"tr\"):\n    print(len(yu),\":\",season)\n    season=tr.find_all(\"td\")[0].text\n    yearz=season[:-1]\n    yearz=yearz[2::]\n    yearz=yearz.replace(\"-\",\"_\")\n    print(season)\n    season=season.split(\"-\")[0]\n    link='https://academics.smcvt.edu/jtrono/'+tr.find_all(\"a\")[0]['href']\n    j=link\n    j=j.split(\"Archive/\")[1]\n    j=j.split(\"_dt\")[0]\n    \n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    \n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    body=body.replace(\"<p>\",\"\")\n    \n    body=body.split(\"<br/>\")\n    \n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        \n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line) and line!='\\xa0\\n</body>' and line!='\\n':\n            \n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            date=line.split(\" \")[0]\n            home=line.split(\" \")[1]\n            pts=line.split(\" \")[2]\n            away=line.split(\" \")[3]\n            opp=line.split(\" \")[4]\n            venue=line.split(\" \")[5]\n            \n            if date[0]=='2':\n                date=season+sep+\"11\"+sep+date[1::]\n            if date[0]=='3':\n                date=season+sep+\"12\"+sep+date[1::]\n            if date[0]=='4':\n                date=str(float(season)+1)+sep+\"01\"+sep+date[1::]\n            if date[0]=='5':\n                date=str(float(season)+1)+sep+\"02\"+sep+date[1::]\n            if date[0]=='6':\n                date=str(float(season)+1)+sep+\"03\"+sep+date[1::]\n            if date[0]=='7':\n                date=str(float(season)+1)+sep+\"04\"+sep+date[1::]\n            date=date.replace(\"F\",\"\")\n            date=date.replace(\"f\",\"\")\n            date=date.replace(\".0\",\"\")\n            date=float(date)\n            notes=''\n            if len(line.split(\" \"))>6:\n                notes=line.split(\" \")[6]\n            \n            arr.append([date,home,away,pts,opp,venue,season,notes])\n    link='https://academics.smcvt.edu/jtrono/'+tr.find_all(\"a\")[1]['href']\n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    \n    body=body.replace(\"<p>\",\"\")\n    body=body.split(\"<br/>\")\n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line) and line!='\\xa0\\n</body>' and season in years:\n            \n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            \n            date=line.split(\" \")[0]\n            home=line.split(\" \")[1]\n            pts=line.split(\" \")[2]\n            away=line.split(\" \")[3]\n            opp=line.split(\" \")[4]\n            venue=line.split(\" \")[5]\n            if date[0]=='2':\n                date=season+sep+\"11\"+sep+date[1::]\n            if date[0]=='3':\n                date=season+sep+\"12\"+sep+date[1::]\n            if date[0]=='4':\n                date=str(float(season)+1)+sep+\"01\"+sep+date[1::]\n            if date[0]=='5':\n                date=str(float(season)+1)+sep+\"02\"+sep+date[1::]\n            if date[0]=='6':\n                date=str(float(season)+1)+sep+\"03\"+sep+date[1::]\n            if date[0]=='7':\n                date=str(float(season)+1)+sep+\"04\"+sep+date[1::]\n            date=date.replace(\"F\",\"\")\n            date=date.replace(\"f\",\"\")\n            date=date.replace(\".0\",\"\")\n            date=float(date)\n            notes=''\n            if len(line.split(\" \"))>6:\n                notes=line.split(\" \")[6]\n            \n            arr.append([date,home,away,pts,opp,venue,season,notes])\n    datez=date\n    j=j.split(\".dts\")[0]\n    jz=str(j)\n    j=jz\n    link='https://academics.smcvt.edu/jtrono/NCAA_Archive/'+j+\"_nit.htm\"\n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    body=body.replace(\"<p>\",\"\")\n    \n    body=body.split(\"<br/>\")\n    \n    datez=date\n   \n    \n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line)  and line!='\\xa0\\n</body>':\n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            home=line.split(\" \")[0]\n            pts=line.split(\" \")[1]\n            away=line.split(\" \")[2]\n            opp=line.split(\" \")[3]\n            venue=line.split(\" \")[4]\n            \n            \n            \n            notes=''\n            if len(line.split(\" \"))>5:\n                notes=line.split(\" \")[5]\n            datez+=1\n            \n            arr.append([datez,home,away,pts,opp,venue,season,notes])\n    link='https://academics.smcvt.edu/jtrono/NCAA_Archive/'+j+\"_ncaa.htm\"\n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    body=body.replace(\"<p>\",\"\")\n    \n    body=body.split(\"<br/>\")\n    datez=date\n    \n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        \n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line)  and line!='\\xa0\\n</body>':\n            \n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            line=line.replace(\"5V\",\"5 V\")\n            home=line.split(\" \")[0]\n            pts=line.split(\" \")[1]\n            away=line.split(\" \")[2]\n            opp=line.split(\" \")[3]\n            venue=line.split(\" \")[4]\n            \n            \n            \n            notes=''\n            if len(line.split(\" \"))>5:\n                notes=line.split(\" \")[5]\n            datez+=1\n            \n            arr.append([datez,home,away,pts,opp,venue,season,notes])\n    \ndf=pd.DataFrame(arr,columns=['date','home','away','homep','awayp','venue','season','notes'])\ndf=df.astype({\"season\":float})","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:23:33.562828Z","iopub.execute_input":"2024-10-14T01:23:33.563513Z","iopub.status.idle":"2024-10-14T01:27:57.534826Z","shell.execute_reply.started":"2024-10-14T01:23:33.563468Z","shell.execute_reply":"2024-10-14T01:27:57.533047Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['date','home','away','homep','awayp','venue','season','notes'])\ndf=df.astype({\"season\":float})\ndf.to_csv(\"allbbz.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:28:49.859797Z","iopub.execute_input":"2024-10-14T01:28:49.860234Z","iopub.status.idle":"2024-10-14T01:28:50.606675Z","shell.execute_reply.started":"2024-10-14T01:28:49.860194Z","shell.execute_reply":"2024-10-14T01:28:50.604751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(yu)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:09:06.981010Z","iopub.execute_input":"2024-10-14T01:09:06.981605Z","iopub.status.idle":"2024-10-14T01:09:06.989066Z","shell.execute_reply.started":"2024-10-14T01:09:06.981554Z","shell.execute_reply":"2024-10-14T01:09:06.987861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"allscores.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:08:06.043673Z","iopub.execute_input":"2024-10-01T12:08:06.044114Z","iopub.status.idle":"2024-10-01T12:08:06.967484Z","shell.execute_reply.started":"2024-10-01T12:08:06.044077Z","shell.execute_reply":"2024-10-01T12:08:06.966140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(line)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:07:55.264014Z","iopub.execute_input":"2024-10-14T01:07:55.264610Z","iopub.status.idle":"2024-10-14T01:07:55.273077Z","shell.execute_reply.started":"2024-10-14T01:07:55.264556Z","shell.execute_reply":"2024-10-14T01:07:55.271576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf13=df13[df13.Year!='Year']\ndf13[df13.Year=='2000-01']\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")\ndf19=df19[df19.Year!='Year']\ndf19[df19.Year=='2000-01']","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:32:33.271160Z","iopub.execute_input":"2024-10-14T03:32:33.271639Z","iopub.status.idle":"2024-10-14T03:32:33.448865Z","shell.execute_reply.started":"2024-10-14T03:32:33.271597Z","shell.execute_reply":"2024-10-14T03:32:33.447675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf2=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1949-1959h.csv\")\ndf3=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1959-1969h.csv\")\ndf4=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1969-1970h.csv\")\ndf5=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1971-1979h.csv\")\nimport re\ndef has_numbers(inputString):\n    return bool(re.search(r'\\d', inputString))\ndf6=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1980-1985h.csv\")\ndf7=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1986-1987h.csv\")\ndf7=df7[df7.Year!=1988]\ndf8=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1988-1989h.csv\")\ndf9=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1990-1992h.csv\")\ndf10=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1993-1994h.csv\")\ndf10=df10[df10.Year<\"1995-96\"]\ndf11=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1995-1996h.csv\")\ndf12=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1997-1999h.csv\")\ndf13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf14=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2005-2011h.csv\")\ndf15=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2012-2020h.csv\")\ndf16=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2021h.csv\")\ndf17=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1949-1988n.csv\")\ndf17=df17[df17.Year!='1971-72']\ndf20=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1971-1972n.csv\")\ndf17=pd.concat([df20,df17])\ndf18=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1989-1999n.csv\")\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T03:43:36.636278Z","iopub.execute_input":"2024-05-10T03:43:36.636693Z","iopub.status.idle":"2024-05-10T03:43:48.225557Z","shell.execute_reply.started":"2024-05-10T03:43:36.636661Z","shell.execute_reply":"2024-05-10T03:43:48.223867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=pd.concat([df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19],ignore_index=True)\narr=[]\ndf100=df1.sort_values(by='Date')\ndf1=df1[['Year','Date','neutral','PTS','OPP','Year','Opp','Schl']]\ndf1=df1.drop_duplicates()\nys=[]\n\nimport sys\nfor Date in df100.Date.unique():\n    times=1\n    teams=[]\n    \n    if '2003' in str(Date):\n        sys.exit(1)\n    if row.Year not in ys:\n        ys.append(row.Year)\n        print(row.Year)\n    df=df1[df1.Date==Date]\n    for row in df.itertuples():\n        if row.Schl in teams or row.Opp in teams:\n            times+=1\n            num=20*times\n            date=row.Date+\" \"+str(num)+\":00:00\"\n        else:\n            date=row.Date+\" 00:00:00\"\n        arr.append([row.Schl,date,row.Opp,row.Year,'vs',row.neutral,row.PTS,row.OPP])\n        teams.append(row.Schl)\n        teams.append(row.Opp)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-10T03:48:13.240018Z","iopub.execute_input":"2024-05-10T03:48:13.240542Z","iopub.status.idle":"2024-05-10T03:50:48.933940Z","shell.execute_reply.started":"2024-05-10T03:48:13.240506Z","shell.execute_reply":"2024-05-10T03:50:48.932281Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# d2 scores from 2007 season","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup, Comment\n\nlinks={}\nimport time\narr=[]\nys={}\nfor i in range(1950,2025):\n    ys[i]=[]\nfor i in range(1950,2025):\n    print(i)\n    links[i]=[]\n    html=requests.get(\"https://www.sports-reference.com/cbb/seasons/men/\"+str(i)+\"-standings.html\")\n    print(html.status_code)\n    html=html.text\n    html=html.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n    soup=BeautifulSoup(html,'lxml')\n    \n    \n    y=i-1\n    for table in soup.find_all(\"table\"):\n        for tr in table.find_all(\"tr\"):\n            if \"Notes\" not in str(tr) and 'Overall' not in str(tr):\n                \n                \n                schl=tr.find_all(\"td\")[0].text\n                conf=tr.find_all(\"td\")[1].text\n                srs=tr.find_all(\"td\")[13].text\n            \n                \n                arr.append([schl,conf,y,srs])\n    time.sleep(5)\n    print(len(arr))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T01:05:44.546210Z","iopub.execute_input":"2024-09-09T01:05:44.547194Z","iopub.status.idle":"2024-09-09T01:12:58.985149Z","shell.execute_reply.started":"2024-09-09T01:05:44.547088Z","shell.execute_reply":"2024-09-09T01:12:58.983818Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['School','Conf','Year','SRS'])\ndf=df[df.SRS.notna()]\ndf.to_csv(\"alld1s.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T01:14:23.576467Z","iopub.execute_input":"2024-09-09T01:14:23.576874Z","iopub.status.idle":"2024-09-09T01:14:23.653978Z","shell.execute_reply.started":"2024-09-09T01:14:23.576838Z","shell.execute_reply":"2024-09-09T01:14:23.652669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30396,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/savageopress12345/mechanical-soup-error?scriptVersionId=118868915\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"ty=df22[df22.Year==2023]\npoints=set(ty.PTS.tolist()+ty.OPP.tolist())\ngames={}\narr=[]\nfor row in ty.itertuples():\n    if row.PTS>row.OPP:\n        name=row.Schl+\"||\"+row.Opp+\"||\"+str(row.PTS)+\"||\"+str(row.OPP)\n        games[name]=row.PTS\n        arr.append([row.Schl,row.Opp,row.PTS,row.OPP,row.Venue,row.Date])\n    if row.PTS<row.OPP:\n        name=row.Opp+\"||\"+row.Schl+\"||\"+str(row.OPP)+\"||\"+str(row.PTS)\n        games[name]=row.OPP\n        arr.append([row.Opp,row.Schl,row.OPP,row.PTS,row.Venue,row.Date])\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.368641Z","iopub.execute_input":"2024-05-10T01:17:40.369141Z","iopub.status.idle":"2024-05-10T01:17:40.692662Z","shell.execute_reply.started":"2024-05-10T01:17:40.369101Z","shell.execute_reply":"2024-05-10T01:17:40.691548Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['Winner','Loser','Winner PTS','Loser PTS','Venue','Date'])\ndf=df.sort_values(by='Loser PTS')\ndf=df.iloc[0:10]\nfor row in df.itertuples():\n    print(row)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.694520Z","iopub.execute_input":"2024-05-10T01:17:40.695127Z","iopub.status.idle":"2024-05-10T01:17:40.735929Z","shell.execute_reply.started":"2024-05-10T01:17:40.695088Z","shell.execute_reply":"2024-05-10T01:17:40.735028Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Pandas(Index=9753, Winner='North Dakota State', Loser='Oak Hills Chr', _3=108.0, _4=14.0, Venue='vs', Date=Timestamp('2023-12-10 00:00:00'))\nPandas(Index=2724, Winner='Faith Bap', Loser='FLBC', _3=65.0, _4=16.0, Venue='@', Date=Timestamp('2023-11-11 00:00:00'))\nPandas(Index=2107, Winner='Emmaus Bib', Loser='FLBC', _3=78.0, _4=23.0, Venue='@', Date=Timestamp('2023-11-10 00:00:00'))\nPandas(Index=8276, Winner='McNeese State', Loser='MS Women', _3=92.0, _4=23.0, Venue='vs', Date=Timestamp('2023-12-05 00:00:00'))\nPandas(Index=9302, Winner='Mercyhurst', Loser='SUNY Fredonia', _3=83.0, _4=24.0, Venue='vs', Date=Timestamp('2023-12-09 00:00:00'))\nPandas(Index=5210, Winner='West Alabama', Loser='Oakwood', _3=93.0, _4=25.0, Venue='vs', Date=Timestamp('2023-11-21 00:00:00'))\nPandas(Index=2718, Winner='Christendom', Loser='Appalachian Bib', _3=98.0, _4=26.0, Venue='vs', Date=Timestamp('2023-11-11 00:00:00'))\nPandas(Index=10473, Winner='Liberty', Loser='St Andrews', _3=99.0, _4=26.0, Venue='vs', Date=Timestamp('2023-12-16 00:00:00'))\nPandas(Index=271, Winner='C Chr Bible', Loser='FLBC', _3=93.0, _4=26.0, Venue='@', Date=Timestamp('2023-10-28 00:00:00'))\nPandas(Index=25218, Winner='Maryville TN', Loser='Warren Wilson', _3=55.0, _4=27.0, Venue='vs', Date=Timestamp('2024-02-17 00:00:00'))\n","output_type":"stream"}]},{"cell_type":"code","source":"[item for item in sorted(games, key=games.get)][0:10]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.737447Z","iopub.execute_input":"2024-05-10T01:17:40.737860Z","iopub.status.idle":"2024-05-10T01:17:40.760119Z","shell.execute_reply.started":"2024-05-10T01:17:40.737823Z","shell.execute_reply":"2024-05-10T01:17:40.759052Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"['IN S Bend||Holy Cross IN||42.0||41.0',\n 'Christendom||Williamson Tr||43.0||33.0',\n 'Loyola (MD)||American||44.0||43.0',\n 'Keuka||Alfred||44.0||41.0',\n 'Weatherford||Tyler JC||45.0||44.0',\n 'Chipola||NW Florida St||45.0||41.0',\n 'Southeastern Bap||Pensacola Chr||46.0||44.0',\n 'Outaouais||Ahuntsic||46.0||44.0',\n 'Cypress||Irvine Valley||46.0||43.0',\n 'Montgomery Co CC||Delaware Co CC||47.0||41.0']"},"metadata":{}}]},{"cell_type":"code","source":"myKeys = list(games.keys())\n{i: games[i] for i in myKeys}[0:5]","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:17:40.762689Z","iopub.execute_input":"2024-05-10T01:17:40.764039Z","iopub.status.idle":"2024-05-10T01:17:40.798949Z","shell.execute_reply.started":"2024-05-10T01:17:40.763977Z","shell.execute_reply":"2024-05-10T01:17:40.791804Z"},"trusted":true},"execution_count":43,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3881209456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmyKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyKeys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"],"ename":"TypeError","evalue":"unhashable type: 'slice'","output_type":"error"}]},{"cell_type":"markdown","source":"**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1949-1959h.csv\")\ndf3=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1959-1969h.csv\")\ndf4=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1969-1970h.csv\")\ndf5=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1971-1979h.csv\")\nimport re\ndef has_numbers(inputString):\n    return bool(re.search(r'\\d', inputString))\ndf6=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1980-1985h.csv\")\ndf7=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1986-1987h.csv\")\ndf7=df7[df7.Year!=1988]\ndf8=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1988-1989h.csv\")\ndf9=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1990-1992h.csv\")\ndf10=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1993-1994h.csv\")\ndf10=df10[df10.Year<\"1995-96\"]\ndf11=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1995-1996h.csv\")\ndf12=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1997-1999h.csv\")\ndf13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf14=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2005-2011h.csv\")\ndf15=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2012-2020h.csv\")\ndf16=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2021h.csv\")\ndf17=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1949-1988n.csv\")\ndf17=df17[df17.Year!='1971-72']\ndf20=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1971-1972n.csv\")\ndf17=pd.concat([df20,df17])\ndf18=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1989-1999n.csv\")\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T01:42:10.261709Z","iopub.execute_input":"2024-05-10T01:42:10.262191Z","iopub.status.idle":"2024-05-10T01:42:10.289584Z","shell.execute_reply.started":"2024-05-10T01:42:10.262151Z","shell.execute_reply":"2024-05-10T01:42:10.288175Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array(['1949-50', '1950-51', '1951-52', '1952-53', '1953-54', '1954-55',\n       '1955-56', '1956-57', '1957-58', '1958-59', '1959-60', '1960-61',\n       '1961-62', '1962-63', '1963-64', '1964-65', '1965-66', '1966-67',\n       '1967-68', '1968-69', '1969-70', '1970-71', '1971-72', '1972-73',\n       '1973-74', '1974-75', '1975-76', '1976-77', '1977-78', '1978-79',\n       '1979-80', '1980-81', '1981-82', '1982-83', '1983-84', '1984-85',\n       '1985-86', '1986-87', '1987-88', '1988-89', '1989-90', '1990-91',\n       '1991-92', '1992-93', '1993-94', '1994-95', '1995-96', '1996-97',\n       '1997-98', '1998-99', '1999-00', '2000-01', '2001-02'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"\nimport time\nstart_time = time.time()\nprint('done files')\nimport numpy as np\nfrom datetime import datetime\nimport random\nimport string\nfrom decimal import Decimal\nclass Elo:\n    \n    \n    \n    \n\n    def __init__(self,k,g=1,homefield = 110): \n        self.ratingDict={}\n        self.k = k\n        self.g = g\n        self.homefield= homefield\n\n    def addPlayer(self,name,rating = 1500):\n        self.ratingDict[name] = rating\n    def gameOver(self, winner, loser, winnerHome,neutral,wp,lp,yr,date,wpe,lpe,hfa,k):\n        wpe=wpe\n        lpe=lpe\n        \n        \n        homef=hfa\n        if('True' in str(neutral)):\n            \n        \n            homef=0\n        \n        \n        if(winnerHome==True):\n            \n            elod=(eloLeague.ratingDict[winner]+homef)-(eloLeague.ratingDict[loser])\n        if(winnerHome!=True):\n            \n            elod=(eloLeague.ratingDict[winner])-(homef+eloLeague.ratingDict[loser])\n        \n        elo=float(elod)\n        wp=float(wp)\n        lp=float(lp)\n        \n        o=abs(wp-lp)\n        y=float(((o)+3))\n        \n        mov=((o+3)**0.8)/(7.5+0.006*elod)\n        if winnerHome==True:\n            \n            result = self.expectResult(self.ratingDict[winner]+homef, self.ratingDict[loser])\n        else:\n            result = self.expectResult(self.ratingDict[winner], self.ratingDict[loser]+homef)\n        shift=(self.k*mov)*(1 - result) \n        self.ratingDict[winner]+=shift\n        self.ratingDict[loser]-=shift\n        \n        \n\n    def expectResult(self, p1, p2):\n    \n        global exp\n        exp = (Decimal(p2)-Decimal(p1))/Decimal(400.0)\n        n2=Decimal(10.0)\n        j=Decimal(exp)\n        o=Decimal(1)/((n2**(j))+Decimal(1))\n        return float(o)\nimport requests\nfrom bs4 import BeautifulSoup,Comment\nimport re, csv\nfrom bs4 import BeautifulSoup as bs\nuteams=requests.get(\"https://ontheroadtovote.com/ncaaf/caabteams.json\").json() \nd2urls={}\nd2urls[2001]='https://ontheroadtovote.com/ncaaf/prefbs/2001.html'\nfor i in range(2002,2024):\n    url='https://ontheroadtovote.com/ncaaf/prefbs/masseyratings.com'+str(i)+\".webarchive\"\n    d2urls[str(i)]=url\n\nthearr=[]\nabbreviations = [\n    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#States.\n    \"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"IA\",\n    \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\", \"MI\", \"MN\", \"MO\",\n    \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\",\n    \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\",\n    \"WV\", \"WY\",\n    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Federal_district.\n    \"DC\",\n    # https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States#Inhabited_territories.\n    \"AS\", \"GU\", \"MP\", \"PR\", \"VI\",\n]\nimport re\nimport pandas as pd\n\nstandings=pd.read_csv(\"https://ontheroadtovote.com/ncaab/d1vsnond1/teams/d1standings.txt\")\nfrom datetime import date\ntoday=str(date.today())\nfrom datetime import timedelta\nstandings=pd.read_csv(\"https://ontheroadtovote.com/ncaab/updatedstandings.csv\")\nw=0\nl=0\nnames=[]\ndef replace(n):\n    string=n\n    for letter in letters:\n        string=string.replace(letter+\" Stateate\",letter+\" State\")\n    return string\nnames=set()\nfrom datetime import date\ntoday=date.today()\noldconfs=pd.read_csv(\"https://ontheroadtovote.com/ncaab/old.csv\")\nimport json\nhbcus=['Texas Southern','Coppin State','Morgan State','North Carolina Central','Morgan State','Howard','Norfolk State','South Carolina State','Delaware State','Grambling','Southern','Alcorn State','North Carolina A&T','Tennessee State','Chicago State','Hampton','Bethune-Cookman','Alabama A&M','Prairie View A&M','Mississippi Valley State','Alabama State','Arkansas-Pine Bluff','Florida A&M','Jackson State','Maryland-Eastern Shore']\nw=0\nl=0\nfrom datetime import datetime\ndf2 = {'Unnamed: 0':'t','Rk':4,'School':'Hiram','Conf':'Independent','Year':1893,'W':1,'L':0}\noldconfs.append(df2,ignore_index=True)\nmsqe={}\ncurrSeason=1949\nfor i in range(9,22):\n    msqe[str(i)]=set()\ndf=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/smallschoolscores/teams/cbbstandings.csv\")\nconfs={}\nfor i in range(1949,2025):\n    confs[i]={}\ndf=df.replace(\"PCC (North)\",\"PCC\")\ndf=df.replace(\"PCC (South)\",\"PCC\")\ndf=df.replace(\"Mid-Atl (Eastern)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (Western)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (East)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (West)\",\"Mid-Atl\")\ndf=df.replace(\"ECC (West)\",\"ECC\")\ndf=df.replace(\"ECC (East)\",\"ECC\")\ndf=df.replace(\"ECBL (East)\",\"ECBL\")\ndf=df.replace(\"ECBL (West)\",\"ECBL\")\ndf=df.replace(\"EAA (West)\",\"EAA\")\ndf=df.replace(\"EAA (East)\",\"EAA\")\ndf=df.replace(\"ECACM (North)\",\"ECACM\")\ndf=df.replace(\"ECACM (South)\",\"ECACM\")\ndf=df.replace(\"A-10 (East)\",\"A-10\")\ndf=df.replace(\"A-10 (West)\",\"A-10\")\ndf=df.replace(\"MAAC (South)\",\"MAAC\")\ndf=df.replace(\"MAAC (North)\",\"MAAC\")\ndf=df.replace(\"CUSA (Blue)\",\"CUSA\")\ndf=df.replace(\"CUSA (Red)\",\"CUSA\")\ndf=df.replace(\"CUSA (White)\",\"CUSA\")\ndf=df.replace(\"Big East (East)\",\"Big East\")\ndf=df.replace(\"MAC (East)\",\"MAC\")\ndf=df.replace(\"SEC (East)\",\"SEC\")\ndf=df.replace(\"Southern (North)\",'Southern')\ndf=df.replace(\"Southern (South)\",\"Southern\")\ndf=df.replace(\"WAC (Pacific)\",\"WAC\")\ndf=df.replace(\"CUSA (National)\",\"CUSA\")\ndf=df.replace(\"TAAC (East)\",\"TAAC\")\ndf=df.replace(\"Sun Belt (West)\",\"Sun Belt\")\ndf=df.replace(\"TAAC (West)\",\"TAAC\")\ndf=df.replace(\"A-Sun (North)\",\"A-Sun\")\ndf=df.replace(\"MAC (West)\",\"MAC\")\ndf=df.replace(\"Big East (West)\",\"Big East\")\ndf=df.replace(\"SEC (West)\",\"SEC\")\ndf=df.replace(\"Southland (West)\",\"Southland\")\ndf=df.replace(\"Southland (East)\",\"Southland\")\ndf=df.replace(\"OVC (East)\",\"OVC\")\ndf=df.replace(\"OVC (West)\",\"OVC\")\ndf=df.replace(\"Big South (North)\",\"Big South\")\ndf=df.replace(\"Big South (South)\",\"Big South\")\ndf=df.replace(\"A-Sun (East)\",\"A-Sun\")\ndf=df.replace(\"Patriot (Central)\",\"Patriot\")\ndf=df.replace(\"WAC (Mountain)\",\"WAC\")\ndf=df.replace(\"CUSA (American)\",\"CUSA\")\ndf=df.replace(\"Big West (West)\",\"Big West\")\ndf=df.replace(\"CUSA (East)\",\"CUSA\")\ndf=df.replace(\"Patriot (North)\",\"Patriot\")\ndf=df.replace(\"CUSA (West)\",\"CUSA\")\ndf=df.replace(\"A-Sun (West)\",\"A-Sun\")\ndf=df.replace(\"Patriot (South)\",\"Patriot\")\ndf=df.replace(\"A-Sun (South)\",\"A-Sun\")\ndf=df.replace(\"MEAC (Southern)\",\"MEAC\")\ndf=df.replace(\"MEAC (Northern)\",\"MEAC\")\ndf=df.replace(\"Sun Belt (East)\",\"Sun Belt\")\ndf=df.replace(\"Big West (West)\",\"Big West\")\ndf=df.replace(\"Big West (East)\",\"Big West\")\ndf=df.replace(\"Big East (Big East 6)\",\"Big East\")\ndf=df.replace(\"Big East (Big East 7)\",\"Big East\")\nstandings=pd.read_csv(\"https://ontheroadtovote.com/ncaab/d1vsnond1/teams/d1standings.txt\")\nfor row in standings.itertuples():\n    if float(row.Year)>1948:\n        confs[float(row.Year)][str(row.Schl)]=str(row.Conference)\nfor row in df.itertuples():\n    s=row.School\n    s=s.replace(\"FDU\",'Fairleigh Dickinson')\n    s=s.replace(\"UCF\",\"Central Florida\")\n    confs[float(row.Year)][str(s)]=row.Conf\npreds={}\nswac=['Grambling','Alcorn State',\"Jackson State\",'Prairie View','Texas Southern','Arkansas-Pine Bluff','Southern','Bethune-Cookman','Alabama State','Florida A&M','Alabama A&M','Mississippi Valley State']\nmeac=['North Carolina Central','Coppin State','Maryland-Eastern Shore','Norfolk State','Howard','South Carolina State','Morgan State','Delaware State']\nconfy={}\nfor conf in set(df.Conf.tolist()):\n    confy[conf]={}\nfor row in df.itertuples():\n    confy[row.Conf][float(row.Year)]=[]\nfor row in df.itertuples():\n    confy[row.Conf]=[]\n\n\nkval=20\neloLeague = Elo(k = kval)\nprint(\"go through games\")\ndid=[]\nrev=0.73\nwe=pd.read_csv(\"https://ontheroadtovote.com/ncaaf/prefbs/allbbz.csv\")\ntz={}\nh=requests.get(\"https://ontheroadtovote.com/ncaaf/prefbs/alltz.txt\").text\nh=str(h)\nh=h.split(\"\\n\")\nwe['homep']=we['homep'].fillna(\"35\")\nwe=we.astype({\"homep\":float,\"awayp\":float})\n\nfor line in h:\n    tz[line.split(\"|\")[0]]=line.split(\"|\")[1]\nfor row in we.itertuples():\n    s=str(row.home)\n    o=str(row.away)\n    if s in tz:\n        s=tz[s]\n    if o in tz:\n        o=tz[o]\n    sz=row.season\n    o=o.strip()\n    s=s.strip()\n    if o=='Bowling Green':\n        o='Bowling Green State'\n    if s=='Bowling Green':\n        s='Bowling Green State'\n    row=[row.date,s,o,row.homep,row.awayp,row.venue,row.season,row.notes,False]\n    if s in confs[float(sz)] and o in confs[float(sz)]:\n        thearr.append(row)\nprint(\"did old\")\nprint(len(thearr))\ndf13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf13=df13[df13.Year!='Year']\ndf13[df13.Year=='2000-01']\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")\ndf19=df19[df19.Year!='Year']\ndf19[df19.Year=='2000-01']\ndf2=pd.concat([df19,df13])\ndf2=df2.sort_values(by='Date')\nuteams['Bowling Green']='Bowling Green State'\nfor row in df2.itertuples():\n    o=row.Opp\n    s=row.Schl\n    if o in uteams:\n        o=uteams[o]\n    if s in uteams:\n        s=uteams[s]\n    if o in confs[2000] and s in confs[2000]:\n        thearr.append([row.Date,s,o,row.PTS,row.OPP,'vs',2000,'notes',row.neutral])\nfor key in d2urls:\n    print(key)\n    r = requests.get(d2urls[key])\n    soup = BeautifulSoup(r.text, 'lxml')\n    p = re.compile(r'([^0-9-]+)\\s{3,}')\n    p2 = re.compile(r'\\s(\\d+)\\s')\n    aa=str(BeautifulSoup(r.text, 'lxml'))\n    aa=str(aa)\n    aa=(aa.split(\"<hr/><pre>\")[1])\n    aa=aa.replace(\"               \",\",\")\n    aa=aa.replace(\"  \",\",\")\n    for i in range(0,10):\n        aa=aa.replace(str(i)+\" \",str(i)+\",\") \n    aa=aa.replace(\",,,,,,\",\",\")\n    \n    q=aa\n    q=q.split(\"\\n\")\n    for line in q:\n        line=str(line)\n        \n        \n        \n        \n        if 'Games' not in str(line) and str(line)!='' and '<' not in str(line):\n            j=line[1]\n            n=False\n            line = list(line.split(','))\n            v=\"vs\"\n            if \"@\" not in str(line):\n                n=True\n            if \"@\" in str(line[1]):\n                v=\"vs\"\n            else:\n                v='@'\n            date=str(line[0])\n            \n            line=str(line)\n            line=line.replace(\"[\",\"\")\n            line=line.replace(\"]\",\"\")\n            line=line.replace(\"'\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\",@\",\",\")\n            line=line.replace(\"@\",\"\")\n            line = list(line.split(','))\n            lines=[]\n            for l in line:\n                if l==' ' :\n                    m=1\n                else:\n                    \n                    lines.append(l)\n                \n            \n            line=lines\n            s=line[1]\n            s=s.lstrip()\n            s=s.rstrip()\n            o=line[3]\n            o=o.lstrip()\n            o=o.rstrip()\n            o=o.replace(\"amp;\",\"\")\n            s=s.replace(\"amp;\",\"\")\n            if s in uteams:\n                s=uteams[s]\n            if o in uteams:\n                o=uteams[o]\n            if len(line)>7:\n                notes=line[7]\n                notes=notes.strip()\n                if notes in abbreviations:\n                    n=True\n            if s  not in confs[float(key)] or o not in confs[float(key)]:\n                m=1\n            else:\n                row=[date,s,o,line[2],line[4],v,float(key),'notes',n]\n            thearr.append(row)\n\nfrom bs4 import BeautifulSoup,Comment\ndf22=pd.DataFrame(thearr,columns=['Date','Schl',\"Opp\",'PTS','OPP','Venue','Year','Notes','neutral'])\ndf22=df22.astype({\"Venue\":\"string\"})\ndf22=df22.astype({\"neutral\":\"string\"})\nprint(\"created df22\")\nprint(set(df22.Year.tolist()))\ndf22['Venue']=df22['Venue'].replace(\"NA?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"A?\",\"@\")\ndf22['Venue']=df22['Venue'].replace(\"AH?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"AN?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"HA?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"HN?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"NA?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"NN\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"NH?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"N\\xa0\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"N?\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"H?\",\"H\")\ndf22['Venue']=df22['Venue'].replace(\"A?\",\"A\")\ndf22['Venue']=df22['Venue'].replace(\"n\",\"N\")\ndf22['Venue']=df22['Venue'].replace(\"?\",\"N\")\ndf22=df22.astype({\"PTS\":float,\"OPP\":float})\nfor row in df22.itertuples():\n    if row.Venue=='A':\n        df22.at[row.Index,'Venue']='@'\n    if row.Venue=='H' or row.Venue=='N':\n        df22.at[row.Index,'Venue']='vs'\n    if row.Venue=='N':\n        df22.at[row.Index,'neutral']='True'\n    else:\n        df22.at[row.Index,'neutral']='False'\ndf22['Date']=df22['Date'].str.replace(\"-\",\"\")\nfrom datetime import date\ndf22=df22.astype({\"Date\":float})\ntoday=str(date.today())\ntoday=today.replace(\"-\",\"\")\ndf22=df22[df22.Date<float(today)]\ndf22=df22[df22.PTS!=1]\ndf22=df22[df22.PTS!=2]\ndf22=df22.replace(\"Texas Christian\",'TCU')\n\nhfas={}\nfor game in df22.itertuples():\n    if game.Schl in confs[game.Year] and game.Opp in confs[game.Year]:\n        \n        if confs[float(game.Year)][game.Schl]!=confs[float(game.Year)][game.Opp]:\n            sconf=confs[float(game.Year)][game.Schl]\n            confy[sconf].append(game.PTS-game.OPP)\n            oconf=confs[float(game.Year)][game.Opp]\n            confy[oconf].append(game.OPP-game.PTS)\nfor game in df22.itertuples():\n    \n    if game.Schl in confs[game.Year] and game.Opp in confs[game.Year]:\n        if game.neutral==True or game.neutral=='True':\n            m=1\n        else:\n            \n            sc=confs[game.Year][game.Schl]\n            oc=confs[game.Year][game.Opp]\n            if sc not in hfas:\n                hfas[sc]=[]\n            if oc not in hfas:\n                hfas[oc]=[]\n            if game.Venue!='@':\n                hfas[sc].append(game.PTS-game.OPP)\n            else:\n                hfas[oc].append(game.OPP-game.PTS)\nkval=20\nfor key in hfas:\n    \n    hfas[key]=(np.mean(hfas[key]))\n    hfas[key]=round(hfas[key])*kval\n    hfas[key]=round(hfas[key])\nmean=np.mean(list(hfas.values()))\nmean=round(mean,-1)\nrev=0.70\nfor key in hfas:\n    num=((1-rev)*hfas[key])+(rev*mean)\n    num=hfas[key]\n    hfas[key]=num\nl=0\nw=0\nfor row in df22.itertuples():\n    if row.Schl not in did:\n        num=round(np.mean(confy[confs[row.Year][row.Schl]]))\n        num=num*kval\n        num=num*(1-rev)\n        eloLeague.addPlayer(row.Schl,rating=1500+num)\n        did.append(row.Schl)\n    if row.Opp not in did:\n        num=round(np.mean(confy[confs[row.Year][row.Opp]]))\n        num=num*kval\n        num=num*(1-rev)\n        eloLeague.addPlayer(row.Opp,rating=1500+num)\n        did.append(row.Opp)\nkeys={}\narr=[]\nfor i in range(2011,2015):\n    url='https://ontheroadtovote.com/ncaaf/prefbs/ys/'+str(i)+\"rat.txt\"\n    df=pd.read_csv(url)\n    for row in df.itertuples():\n        date=str(row.Date)\n        date=date.replace(\"-\",\"\")\n        rating=str(row.Rating)\n        if \"--\" in str(rating) and float(row.Year)==2019:\n            rating=-0.1\n        rat=float(rating)\n        arr.append([row.Team,rat,float(row.Year),float(date)])\n\nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/2015-2016rat.txt'\ndf=pd.read_csv(url)\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    arr.append([row.Team,float(row.Rating),float(row.Year),float(date)])\nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/2017-2018rat.txt'\ndf=pd.read_csv(url)\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    arr.append([row.Team,float(row.Rating),float(row.Year),float(date)]) \nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/2019-2023rat.txt'\ndf=pd.read_csv(url)\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    rating=str(row.Rating)\n    if \"--\" in str(rating) and float(row.Year)==2019:\n        rating=-0.1\n    rat=float(rating)\n    arr.append([row.Team,rat,float(row.Year),float(date)])\nurl='https://ontheroadtovote.com/ncaaf/prefbs/ys/post.csv'\ndf=pd.read_csv(url)\nfor row in df.itertuples():\n    date=str(row.Date)\n    date=date.replace(\"-\",\"\")\n    arr.append([row.Team,float(row.Rating),float(row.Year),float(date)])\ndf=pd.DataFrame(arr,columns=['Team','Rating','Year','Date'])\ndf=pd.DataFrame(arr,columns=['Team','Rating','Year','Date'])\ndf=df.replace(\"Abl Christian\",\"Abilene Christian\")\ndf=df.replace(\"AR Lit Rock\",\"Little Rock\")\ndf=df.replace(\"Alab A&M\",\"Alabama A&M\")\ndf=df.replace(\"IPFW\",\"Purdue Fort Wayne\")\ndf=df.replace(\"N Carolina\",\"North Carolina\")\ndf=df.replace(\"Hsn Christian\",\"Houston Christian\")\ndf=df.replace(\"LIU\",\"Long Island University\")\ndf['Team']=df['Team'].str.replace(\" St\",\" State\")\ndf['Team']=df['Team'].str.replace(\" Stateate\",\" State\")\ndf['Team']=df['Team'].str.replace(\" Stateate\",\" State\")\ndf=df.replace(\"Ark Pine Bl\",\"Arkansas-Pine Bluff\")\ndf=df.replace(\"Albany\",\"Albany (NY)\")\ndf=df.replace(\"Boston U\",\"Boston University\")\ndf=df.replace(\"S Carolina\",\"South Carolina\")\ndf=df.replace(\"Boston Col\",\"Boston College\")\ndf=df.replace(\"Beth-Cook\",\"Bethune-Cookman\")\ndf=df.replace(\"Bowling Grn\",\"Bowling Green\")\ndf=df.replace(\"Cal Baptist\",\"California Baptist\")\ndf['Team']=df['Team'].str.replace(\"CS \",\"Cal State \")\ndf['Team']=df['Team'].str.replace(\" Mich\",\" Michigan\")\ndf=df.replace(\"Central Ark\",\"Central Arkansas\")\ndf=df.replace(\"Central Conn\",\"Central Connecticut\")\ndf=df.replace(\"Cal State Nrdge\",\"Cal State Northridge\")\ndf=df.replace(\"Charl South\",\"Charleston Southern\")\ndf=df.replace(\"Coastal Car\",\"Coastal Carolina\")\ndf=df.replace(\"Col Charlestn\",\"College of Charleston\")\ndf['Team']=df['Team'].str.replace(\"E \",\"Eastern \")\ndf=df.replace(\"Eastern Tenn State\",\"East Tennessee State\")\ndf=df.replace(\"Eastern Michiganigan\",\"Eastern Michigan\")\ndf=df.replace(\"Eastern Carolina\",\"East Carolina\")\ndf=df.replace(\"USC\",\"Southern California\")\ndf=df.replace(\"LSU\",\"Louisiana State\")\ndf=df.replace(\"Florida Intl\",\"Florida International\")\ndf=df.replace(\"Fla Atlantic\",\"Florida Atlantic\")\ndf=df.replace(\"Fla Gulf Cst\",\"Florida Gulf Coast\")\ndf['Team']=df['Team'].str.replace(\"GA \",\"Georgia \")\ndf['Team']=df['Team'].str.replace(\"Geo \",\"George \")\ndf=df.replace(\"Grd Canyon\",\"Grand Canyon\")\ndf=df.replace(\"Loyola-Chi\",\"Loyola (IL)\")\ndf=df.replace(\"Lg Beach State\",\"Long Beach State\")\ndf=df.replace(\"Incar Word\",\"Incarnate Word\")\ndf=df.replace(\"IL-Chicago\",\"Illinois-Chicago\")\ndf=df.replace(\"Gard-Webb\",\"Gardner-Webb\")\ndf=df.replace(\"Grambling State\",\"Grambling\")\ndf=df.replace(\"Jksnville State\",\"Jacksonville State\")\ndf=df.replace(\"James Mad\",\"James Madison\")\ndf=df.replace(\"LIU-Brooklyn\",\"Long Island University\")\ndf=df.replace(\"LA Tech\",\"Louisiana Tech\")\ndf=df.replace(\"F Dickinson\",\"Fairleigh Dickinson\")\ndf=df.replace(\"Loyola-MD\",\"Loyola (MD)\")\ndf=df.replace(\"Loyola Mym\",\"Loyola Marymount\")\ndf=df.replace(\"Mass Lowell\",\"Massachusetts-Lowell\")\ndf=df.replace(\"Middle Tenn\",\"Middle Tennessee\")\ndf=df.replace(\"Miss State\",\"Mississippi State\")\ndf=df.replace(\"Miss Val State\",\"Mississippi Valley State\")\ndf=df.replace(\"Centenary\",\"Centenary (LA)\")\ndf=df.replace(\"Maryland BC\",\"Maryland-Baltimore County\")\ndf=df.replace(\"Maryland ES\",\"Maryland-Eastern Shore\")\ndf['Team']=df['Team'].str.replace(\"NC-\",\"UNC \")\ndf['Team']=df['Team'].str.replace(\"N \",\"Northern \")\ndf['Team']=df['Team'].str.replace(\"Northern Dakota State\",\"North Dakota State\")\ndf['Team']=df['Team'].str.replace(\"Northern Florida\",\"North Florida\")\ndf['Team']=df['Team'].str.replace(\"Northern Hampshire\",\"New Hampshire\")\ndf=df.replace(\"Nicholls\",\"Nicholls State\")\ndf=df.replace(\"NW State\",\"Northwestern State\")\ndf=df.replace(\"NC A&T\",\"North Carolina A&T\")\ndf=df.replace(\"Neb-Omaha\",\"Omaha\")\ndf=df.replace(\"App State\",\"Appalachian State\")\ndf=df.replace(\"Miami\",\"Miami (FL)\")\ndf=df.replace(\"Queens\",\"Queens (NY)\")\ndf=df.replace(\"NorthernMex State\",\"New Mexico State\")\ndf=df.replace(\"S Indiana\",\"Southern Indiana\")\ndf=df.replace(\"S Illinois\",\"Southern Illinois\")\ndf=df.replace(\"S Alabama\",\"South Alabama\")\ndf=df.replace(\"S Carolina\",\"South Carolina\")\ndf=df.replace(\"S Florida\",\"South Florida\")\ndf=df.replace(\"S Mississippi\",\"Southern Mississippi\")\ndf=df.replace(\"S Methodist\",\"Southern Methodist\")\ndf=df.replace(\"S Dakota St\",\"South Dakota State\")\ndf=df.replace(\"S Car State\",\"South Carolina State\")\ndf=df.replace(\"Wm & Mary\",\"William & Mary\")\ndf=df.replace(\"S Utah\",\"Southern Utah\")\ndf=df.replace(\"SC Upstate\",\"South Carolina Upstate\")\ndf=df.replace(\"Rob Morris\",\"Robert Morris\")\ndf=df.replace(\"SEastern Louisiana\",\"Southeastern Louisiana\")\ndf=df.replace(\"SEastern Missouri\",\"Southeast Missouri State\")\ndf=df.replace(\"SIU Edward\",\"Southern Illinois-Edwardsville\")\ndf=df.replace(\"Sac State\",\"Sacramento State\")\ndf=df.replace(\"Sacred Hrt\",\"Sacred Heart\")\ndf=df.replace(\"Sam Hous State\",\"Sam Houston\")\ndf=df.replace(\"UNC Grnsboro\",\"UNC Greensboro\")\ndf=df.replace(\"S Dakota State\",\"South Dakota State\")\ndf=df.replace(\"Citadel\",\"The Citadel\")\ndf=df.replace(\"VA Tech\",\"Virginia Tech\")\ndf=df.replace(\"BYU\",\"Brigham Young\")\ndf=df.replace(\"VCU\",\"Virginia Commonwealth\")\ndf=df.replace(\"U Mass\",\"Massachusetts\")\ndf=df.replace(\"NC Central\",\"North Carolina Central\")\ndf=df.replace(\"W Kentucky\",\"Western Kentucky\")\ndf=df.replace(\"UCSB\",\"UC Santa Barbara\")\ndf=df.replace(\"St Peters\",\"Saint Peter's\")\ndf=df.replace(\"Neb Omaha\",\"Omaha\")\ndf=df.replace(\"St Fran (NY)\",\"St. Francis (NY)\")\ndf=df.replace(\"St Fran (PA)\",\"Saint Francis (PA)\")\ndf=df.replace(\"TNorthern State\",\"Tennessee-Martin\")\ndf=df.replace(\"UCSB\",\"UC Santa Barbara\")\ndf=df.replace(\"TX A&M-CC\",\"Texas A&M-Corpus Christi\")\ndf=df.replace(\"Central Connecticut\",\"Central Connecticut State\")\ndf=df.replace(\"VMI\",\"Virginia Military Institute\")\ndf=df.replace(\"U Penn\",\"Pennsylvania\")\ndf=df.replace(\"Wash State\",\"Washington State\")\ndf=df.replace(\"TX Southern\",\"Texas Southern\")\ndf=df.replace(\"TX A&M-Com\",\"Texas A&M-Commerce\")\ndf=df.replace(\"W Illinois\",\"Western Illinois\")\ndf=df.replace(\"Loyola Mymt\",\"Loyola Marymount\")\ndf=df.replace(\"UCF\",\"Central Florida\")\ndf=df.replace(\"W Virginia\",\"West Virginia\")\ndf=df.replace(\"TNorthern Tech\",\"Tennessee Tech\")\ndf=df.replace(\"WI-Milwkee\",\"Milwaukee\")\ndf=df.replace(\"St Marys\",\"Saint Mary's (CA)\")\ndf=df.replace(\"George Wshgtn\",\"George Washington\")\ndf=df.replace(\"St Johns\",\"St. John's (NY)\")\ndf=df.replace(\"W Carolina\",\"Western Carolina\")\ndf=df.replace(\"Cal State Bakersfld\",\"Cal State Bakersfield\")\ndf=df.replace(\"UL Monroe\",\"Louisiana-Monroe\")\ndf=df.replace(\"Northern Mex State\",\"New Mexico State\")\ndf=df.replace(\"UCSD\",\"UC San Diego\")\ndf=df.replace(\"W Michiganigan\",\"Western Michigan\")\ndf=df.replace(\"TNorthern Martin\",\"Tennessee-Martin\")\ndf=df.replace(\"WI-Grn Bay\",\"Green Bay\")\ndf=df.replace(\"TX-Pan Am\",\"Texas-Rio Grande Valley\")\ndf=df.replace(\"Detroit\",\"Detroit Mercy\")\ndf=df.replace(\"Queens (NY)\",\"Queens (NC)\")\ndf=df.replace(\"St Josephs\",\"Saint Joseph's\")\ndf=df.replace(\"St Bonavent\",\"St. Bonaventure\")\ndf=df.replace(\"Ste F Austin\",\"Stephen F. Austin\")\ndf=df.replace(\"UNC Wilmgton\",\"UNC Wilmington\")\ndf=df.replace(\"UNLV\",\"Nevada-Las Vegas\")\ndf=df.replace(\"TX El Paso\",\"UTEP\")\ndf=df.replace(\"Bowling Green\",\"Bowling Green State\")\ndf=df.replace(\"TX Christian\",\"TCU\")\ndf=df.replace(\"Youngs State\",\"Youngstown State\")\ndf=df.replace(\"Eastern Washingtn\",\"Eastern Washington\")\ndf=df.replace(\"TX El Paso\",\"UTEP\")\ndf=df.replace(\"TX-Arlington\",\"UT Arlington\")\ndf=df.replace(\"Northeastrn\",\"Northeastern\")\ndf=df.replace(\"Northern Alabama\",\"North Alabama\")\ndf=df.replace(\"Mt State Marys\",\"Mount St. Mary's\")\ndf=df.replace(\"Wins-Salem\",\"Winston-Salem\")\ndf=df.replace(\"Bowling Green\",\"Bowling Green State\")\ndf=df.replace(\"TX Christian\",\"TCU\")\nfor k in set(df.Team.tolist()):\n    if k not in confs[2023]:\n        print(k)\npwr={}\nfor row in df.itertuples():\n    if float(row.Year) not in pwr:\n        pwr[float(row.Year)]={}\n    if row.Date not in pwr[float(row.Year)]:\n        pwr[float(row.Year)][row.Date]={}\n    if row.Team not in pwr[float(row.Year)][row.Date]:\n        pwr[float(row.Year)][row.Date][row.Team]=float(row.Rating)\n\nfor game in df22.itertuples():\n    s=game.Schl\n    o=game.Opp\n    o=o.strip()\n    s=s.strip()\n    season=game.Year\n    if s not in eloLeague.ratingDict.keys():\n        eloLeague.addPlayer(s,rating=1500)\n    if o not in eloLeague.ratingDict.keys():\n        eloLeague.addPlayer(o,rating=1500)\n    while (season)>currSeason: \n        games=0\n        confz={}\n        for conf in confs[game.Year]:\n            if conf not in eloLeague.ratingDict.keys():\n                eloLeague.addPlayer(conf,rating=1500)\n        if game.Year in pwr:\n            for key in confs[game.Year]:\n                pre=list(pwr[float(game.Year)].keys())[0]\n                pre=pre[key]\n                pre=pre*kval\n                pre=1500+pre\n                num=pre+eloLeague.ratingDict[key]\n                num=num/2\n                eloLeague.ratingDict[key]=num\n        for key in confs[game.Year]:\n            conf=confs[game.Year][key]\n            if conf not in confz:\n                confz[conf]=[]\n            confz[conf].append(eloLeague.ratingDict[key])\n        lsdf=df22[df22.Year<game.Year]\n        ls=set(lsdf.Schl.tolist()+lsdf.Opp.tolist())\n        \n        for key in eloLeague.ratingDict.keys():\n            \n            if key  in confs[game.Year] and key in ls:\n                num=np.mean(confz[confs[float(game.Year)][key]])\n                \n                num=num+1500\n                numz=round(np.mean(confy[confs[game.Year][game.Opp]]))\n                numz=numz*kval\n                numz=numz*(1-rev)\n                num=num/2\n               \n                eloLeague.ratingDict[key]=(eloLeague.ratingDict[key]*(1-rev))+(num*rev)\n                \n                \n                \n            \n                \n                 \n                    \n        currSeason+=1\n    \n    sp=0\n    op=0\n    s=str(game.Schl)\n    o=str(game.Opp)\n    o=o.strip()\n    s=s.strip()\n    \n    if (game.Schl in swac or game.Schl in meac or game.Opp in meac or game.Opp in swac)and(str(o) in confs[2023] and str(s) in confs[2023])and('2023' in str(game.Year)):\n        if 'True' in str(game.neutral):\n            hf=0\n            \n        \n        if game.Venue=='@' and 'True' not in str(game.neutral):\n            hf=hfas[confs[game.Year][game.Opp]]\n            hr=eloLeague.ratingDict[game.Schl]\n            ar=eloLeague.ratingDict[game.Opp]+hf\n        if game.Venue=='vs'  and 'True' not in str(game.neutral):\n            hf=hfas[confs[game.Year][game.Schl]]\n            hr=eloLeague.ratingDict[game.Schl]+hf\n            ar=eloLeague.ratingDict[game.Opp]\n        if hr>ar:\n            spread=round((hr-ar)/21)\n            if spread==0:\n                spread=1\n            name=str(game.Schl)+\" \"+str(game.Venue)+\" \"+str(game.Opp)\n            name=\"On \"+str(game.Date)+\" \"+str(game.Schl)+\" beats \"+str(game.Opp)+\" by \"+str(spread)\n            keys[name]=game.Date   \n        if ar>hr:\n            name=str(game.Schl)+\" \"+str(game.Venue)+\" \"+str(game.Opp)\n            spread=round((ar-hr)/21)\n            if spread==0:\n                spread=1\n            \n            name=\"On \"+str(game.Date)+\" \"+str(game.Opp)+\" beats \"+str(game.Schl)+\" by \"+str(spread)\n            keys[name]=game.Date            \n        \n    if(game.Venue=='@'):\n        if game.Opp not in confs[game.Year]:\n            hf=50\n    else:\n        if game.Schl not in confs[game.Year]:\n            hf=50\n    t1r=0\n    t2r=0\n    games+=1\n    k=25-(games*0.0035)\n    k=round(25)\n    first=list(pwr[float(game.Year)].keys())[0]\n    for key in eloLeague.ratingDict.keys():\n        if game.Year in pwr:\n            if key in pwr[float(game.Year)][row.Date]:\n                am=pwr[float(game.Year)][row.Date][key]\n                am=am*kval\n                am=am+1500\n                am=am+eloLeague.ratingDict[key]\n                am=am/2\n                eloLeague.ratingDict[key]=am\n    if(game.PTS>game.OPP):\n        \n        homezz=0\n        \n        if(game.Venue!='@'):\n            winnerHomez=True\n            if game.Schl in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Schl]]\n            else:\n                hf=50\n        if(game.Venue=='@'):\n            winnerHomez=False\n            if game.Opp in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Opp]]\n            else:\n                hf=50\n        if 'True'  in str(game.neutral):\n            hf=0\n        \n        if(winnerHomez==True):\n            t1e=eloLeague.ratingDict[game.Schl]+homezz-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]-op+t2r\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp>eloLeague.ratingDict[game.Opp]-op):\n                w+=1\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp<eloLeague.ratingDict[game.Opp]-op):\n                l+=1\n        if(winnerHomez!=True):\n            t1e=eloLeague.ratingDict[game.Schl]-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]+homezz-op+t2r\n            if(eloLeague.ratingDict[game.Schl]-sp>eloLeague.ratingDict[game.Opp]+homezz-op):\n                w+=1\n            if(eloLeague.ratingDict[game.Schl]-sp<eloLeague.ratingDict[game.Opp]+homezz-op):\n                l+=1  \n        df22.at[game.Index,'team1elopre']=t1e\n        df22.at[game.Index,'team2elopre']=t2e\n        eloLeague.gameOver(s,o,winnerHomez,game.neutral,game.PTS,game.OPP,game.Year,game.Date,sp,op,hf,k)\n    if(game.PTS<game.OPP):\n        homezz=0\n        \n        if(game.Venue=='@'):\n            if game.Schl in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Opp]]\n            winnerHomez=True\n        if(game.Venue!='@'):\n            if game.Opp in confs[game.Year]:\n                hf=hfas[confs[game.Year][game.Schl]]\n            winnerHomez=False\n        if 'True'  in str(game.neutral):\n            homezz=0\n        if(winnerHomez==True):\n            t1e=eloLeague.ratingDict[game.Schl]-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]+homezz-op+t2r\n            if(eloLeague.ratingDict[game.Schl]-sp>eloLeague.ratingDict[game.Opp]+homezz-op):\n                l+=1\n            if(eloLeague.ratingDict[game.Schl]-sp<eloLeague.ratingDict[game.Opp]+homezz-op):\n                w+=1\n            \n        \n        if(winnerHomez!=True):\n            t1e=eloLeague.ratingDict[game.Schl]+homezz-sp+t1r\n            t2e=eloLeague.ratingDict[game.Opp]-op+t2r\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp>eloLeague.ratingDict[game.Opp]-op):\n                l+=1\n            if(eloLeague.ratingDict[game.Schl]+homezz-sp<eloLeague.ratingDict[game.Opp]-op):\n                w+=1\n        df22.at[game.Index,'team1elopre']=t1e\n        df22.at[game.Index,'team2elopre']=t2e\n        eloLeague.gameOver(o,s,winnerHomez,game.neutral,game.OPP,game.PTS,game.Year,game.Date,op,sp,hf,k)\n    d1=(s in confs[game.Year] or o in confs[game.Year])\n    for i in range(9,22):\n        spread=abs((t1e-t2e)/float(i))\n        spread=round(spread)\n        if spread==0:\n            spread=1\n        ms=(float(game.PTS)-float(game.OPP))-spread\n        \n        msz = np.square(ms)\n        if d1==True:\n            msqe[str(i)].add(msz)\n        \nimport numpy as np\nmsqez={}\nfor i in range(9,22):\n    msqez[str(i)]=0\nfor i in range(9,22):\n    msqez[str(i)]=sum(msqe[str(i)])/len(msqe[str(i)])\nmas=min(msqez, key=msqez.get)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T23:38:32.933969Z","iopub.execute_input":"2024-10-15T23:38:32.934620Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"done files\ngo through games\ndid old\n140506\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n","output_type":"stream"}]},{"cell_type":"code","source":"df22.sort_values(by='Date')","metadata":{"execution":{"iopub.status.busy":"2024-10-15T23:33:53.642734Z","iopub.execute_input":"2024-10-15T23:33:53.643197Z","iopub.status.idle":"2024-10-15T23:33:53.713421Z","shell.execute_reply.started":"2024-10-15T23:33:53.643159Z","shell.execute_reply":"2024-10-15T23:33:53.711508Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"              Date             Schl            Opp    PTS   OPP Venue    Year  \\\n140506  20001109.0           Kansas           UCLA   99.0  98.0    vs  2000.0   \n140507  20001109.0  St. John's (NY)       Kentucky   62.0  61.0    vs  2000.0   \n140509  20001110.0            Tulsa  Arizona State   69.0  67.0    vs  2000.0   \n140510  20001110.0             UCLA       Kentucky   97.0  92.0    vs  2000.0   \n140511  20001110.0  St. John's (NY)         Kansas   74.0  82.0    vs  2000.0   \n...            ...              ...            ...    ...   ...   ...     ...   \n777333  20240402.0    Indiana State           Utah  100.0  90.0     @  2023.0   \n777335  20240404.0       Seton Hall  Indiana State   79.0  77.0     @  2023.0   \n777337  20240406.0      Connecticut        Alabama   86.0  72.0     @  2023.0   \n777336  20240406.0           Purdue       NC State   63.0  50.0     @  2023.0   \n777338  20240408.0      Connecticut         Purdue   75.0  60.0     @  2023.0   \n\n        Notes neutral  \n140506  notes   False  \n140507  notes   False  \n140509  notes   False  \n140510  notes   False  \n140511  notes   False  \n...       ...     ...  \n777333  notes   False  \n777335  notes   False  \n777337  notes   False  \n777336  notes   False  \n777338  notes   False  \n\n[151871 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Schl</th>\n      <th>Opp</th>\n      <th>PTS</th>\n      <th>OPP</th>\n      <th>Venue</th>\n      <th>Year</th>\n      <th>Notes</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>140506</th>\n      <td>20001109.0</td>\n      <td>Kansas</td>\n      <td>UCLA</td>\n      <td>99.0</td>\n      <td>98.0</td>\n      <td>vs</td>\n      <td>2000.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>140507</th>\n      <td>20001109.0</td>\n      <td>St. John's (NY)</td>\n      <td>Kentucky</td>\n      <td>62.0</td>\n      <td>61.0</td>\n      <td>vs</td>\n      <td>2000.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>140509</th>\n      <td>20001110.0</td>\n      <td>Tulsa</td>\n      <td>Arizona State</td>\n      <td>69.0</td>\n      <td>67.0</td>\n      <td>vs</td>\n      <td>2000.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>140510</th>\n      <td>20001110.0</td>\n      <td>UCLA</td>\n      <td>Kentucky</td>\n      <td>97.0</td>\n      <td>92.0</td>\n      <td>vs</td>\n      <td>2000.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>140511</th>\n      <td>20001110.0</td>\n      <td>St. John's (NY)</td>\n      <td>Kansas</td>\n      <td>74.0</td>\n      <td>82.0</td>\n      <td>vs</td>\n      <td>2000.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>777333</th>\n      <td>20240402.0</td>\n      <td>Indiana State</td>\n      <td>Utah</td>\n      <td>100.0</td>\n      <td>90.0</td>\n      <td>@</td>\n      <td>2023.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>777335</th>\n      <td>20240404.0</td>\n      <td>Seton Hall</td>\n      <td>Indiana State</td>\n      <td>79.0</td>\n      <td>77.0</td>\n      <td>@</td>\n      <td>2023.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>777337</th>\n      <td>20240406.0</td>\n      <td>Connecticut</td>\n      <td>Alabama</td>\n      <td>86.0</td>\n      <td>72.0</td>\n      <td>@</td>\n      <td>2023.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>777336</th>\n      <td>20240406.0</td>\n      <td>Purdue</td>\n      <td>NC State</td>\n      <td>63.0</td>\n      <td>50.0</td>\n      <td>@</td>\n      <td>2023.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>777338</th>\n      <td>20240408.0</td>\n      <td>Connecticut</td>\n      <td>Purdue</td>\n      <td>75.0</td>\n      <td>60.0</td>\n      <td>@</td>\n      <td>2023.0</td>\n      <td>notes</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>151871 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'Iowa State' in confs[1961]","metadata":{"execution":{"iopub.status.busy":"2024-10-15T23:16:39.433817Z","iopub.execute_input":"2024-10-15T23:16:39.434334Z","iopub.status.idle":"2024-10-15T23:16:39.443272Z","shell.execute_reply.started":"2024-10-15T23:16:39.434295Z","shell.execute_reply":"2024-10-15T23:16:39.441817Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"dfe=pd.DataFrame(thearr)\nset(dfe[6].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-10-15T23:34:11.182949Z","iopub.execute_input":"2024-10-15T23:34:11.183582Z","iopub.status.idle":"2024-10-15T23:34:12.086543Z","shell.execute_reply.started":"2024-10-15T23:34:11.183533Z","shell.execute_reply":"2024-10-15T23:34:12.084570Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"{1949.0,\n 1950.0,\n 1951.0,\n 1952.0,\n 1953.0,\n 1954.0,\n 1955.0,\n 1956.0,\n 1957.0,\n 1958.0,\n 1959.0,\n 1960.0,\n 1961.0,\n 1962.0,\n 1963.0,\n 1964.0,\n 1965.0,\n 1966.0,\n 1967.0,\n 1968.0,\n 1969.0,\n 1970.0,\n 1971.0,\n 1972.0,\n 1973.0,\n 1974.0,\n 1975.0,\n 1976.0,\n 1977.0,\n 1978.0,\n 1979.0,\n 1980.0,\n 1981.0,\n 1982.0,\n 1983.0,\n 1984.0,\n 1985.0,\n 1986.0,\n 1987.0,\n 1988.0,\n 1989.0,\n 1990.0,\n 1991.0,\n 1992.0,\n 1993.0,\n 1994.0,\n 1995.0,\n 1996.0,\n 1997.0,\n 1998.0,\n 1999.0,\n 2000.0,\n 2001.0,\n 2002.0,\n 2003.0,\n 2004.0,\n 2005.0,\n 2006.0,\n 2007.0,\n 2008.0,\n 2009.0,\n 2010.0,\n 2011.0,\n 2012.0,\n 2013.0,\n 2014.0,\n 2015.0,\n 2016.0,\n 2017.0,\n 2018.0,\n 2019.0,\n 2020.0,\n 2021.0,\n 2022.0,\n 2023.0}"},"metadata":{}}]},{"cell_type":"code","source":"(eloLeague.ratingDict['Indiana']+hfas[confs[2023]['Purdue']])-eloLeague.ratingDict['Sam Houston']","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:56:18.473173Z","iopub.execute_input":"2024-10-14T03:56:18.473638Z","iopub.status.idle":"2024-10-14T03:56:18.482983Z","shell.execute_reply.started":"2024-10-14T03:56:18.473599Z","shell.execute_reply":"2024-10-14T03:56:18.481812Z"},"trusted":true},"execution_count":228,"outputs":[{"execution_count":228,"output_type":"execute_result","data":{"text/plain":"87.56460700877369"},"metadata":{}}]},{"cell_type":"code","source":"arr=[]\nheaders={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\nyears={}\nimport time\nfor i in range(1949,2025):\n    years[i]=[]\nfor row in df22.itertuples():\n    if float(row.Year)>2005:\n        \n        if float(row.Date) not in years[float(row.Year)]:\n            years[float(row.Year)].append(float(row.Date))\nprint(\"done\")\ny=2012\nfrom fake_useragent import UserAgent\nua = UserAgent()\nfor iz in range(y,y+1):\n    print(iz)\n    iz=str(iz)\n    for date in years[float(iz)]:\n        time.sleep(2)\n        date=str(date)\n        date=date[0]+date[1]+date[2]+date[3]+\"-\"+date[4]+date[5]+\"-\"+date[6]+date[7]\n        date=str(date)\n        url='https://teamrankings.com/ncaa-basketball/ranking/predictive-by-other/?date='+str(date)\n        user_agent = ua.random\n        headers={'User-Agent':user_agent}\n        html=requests.get(url,headers=headers)\n        print(html.status_code)\n        html=html.text\n        soup=BeautifulSoup(html)\n        table=soup.find_all(\"table\")[0]\n        for tr in table.find_all(\"tr\"):\n            if 'Rating' not in str(tr):\n                team=tr.find_all(\"td\")[1]\n                team=team['data-sort']\n                rating=tr.find_all(\"td\")[2].text\n                arr.append([team,rating,iz,date])","metadata":{"execution":{"iopub.status.busy":"2024-10-15T02:27:52.549832Z","iopub.execute_input":"2024-10-15T02:27:52.550353Z","iopub.status.idle":"2024-10-15T02:36:49.898433Z","shell.execute_reply.started":"2024-10-15T02:27:52.550309Z","shell.execute_reply":"2024-10-15T02:36:49.897023Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"done\n2012\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n200\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['Team','Rating','Year','Date'])\ndf.to_csv(\"2011rat.txt\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-15T01:46:02.435276Z","iopub.execute_input":"2024-10-15T01:46:02.435817Z","iopub.status.idle":"2024-10-15T01:46:02.687263Z","shell.execute_reply.started":"2024-10-15T01:46:02.435775Z","shell.execute_reply":"2024-10-15T01:46:02.685842Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"               Team Rating  Year        Date\n0           Ohio St   26.5  2011  2011-11-07\n1        N Carolina   23.6  2011  2011-11-07\n2          Kentucky   23.5  2011  2011-11-07\n3              Duke   22.2  2011  2011-11-07\n4          Syracuse   21.0  2011  2011-11-07\n...             ...    ...   ...         ...\n47941      Longwood  -14.1  2011  2012-04-02\n47942    Binghamton  -14.2  2011  2012-04-02\n47943    Chicago St  -14.2  2011  2012-04-02\n47944   S Car State  -14.3  2011  2012-04-02\n47945  Grambling St  -20.3  2011  2012-04-02\n\n[47946 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Team</th>\n      <th>Rating</th>\n      <th>Year</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ohio St</td>\n      <td>26.5</td>\n      <td>2011</td>\n      <td>2011-11-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>N Carolina</td>\n      <td>23.6</td>\n      <td>2011</td>\n      <td>2011-11-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kentucky</td>\n      <td>23.5</td>\n      <td>2011</td>\n      <td>2011-11-07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Duke</td>\n      <td>22.2</td>\n      <td>2011</td>\n      <td>2011-11-07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Syracuse</td>\n      <td>21.0</td>\n      <td>2011</td>\n      <td>2011-11-07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47941</th>\n      <td>Longwood</td>\n      <td>-14.1</td>\n      <td>2011</td>\n      <td>2012-04-02</td>\n    </tr>\n    <tr>\n      <th>47942</th>\n      <td>Binghamton</td>\n      <td>-14.2</td>\n      <td>2011</td>\n      <td>2012-04-02</td>\n    </tr>\n    <tr>\n      <th>47943</th>\n      <td>Chicago St</td>\n      <td>-14.2</td>\n      <td>2011</td>\n      <td>2012-04-02</td>\n    </tr>\n    <tr>\n      <th>47944</th>\n      <td>S Car State</td>\n      <td>-14.3</td>\n      <td>2011</td>\n      <td>2012-04-02</td>\n    </tr>\n    <tr>\n      <th>47945</th>\n      <td>Grambling St</td>\n      <td>-20.3</td>\n      <td>2011</td>\n      <td>2012-04-02</td>\n    </tr>\n  </tbody>\n</table>\n<p>47946 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install fake_useragent","metadata":{"execution":{"iopub.status.busy":"2024-10-15T02:04:12.274667Z","iopub.execute_input":"2024-10-15T02:04:12.275116Z","iopub.status.idle":"2024-10-15T02:04:27.651079Z","shell.execute_reply.started":"2024-10-15T02:04:12.275079Z","shell.execute_reply":"2024-10-15T02:04:27.649237Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nCollecting fake_useragent\n  Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\nCollecting importlib-metadata~=4.0\n  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\nRequirement already satisfied: importlib-resources>=5.0 in /opt/conda/lib/python3.7/site-packages (from fake_useragent) (5.10.2)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata~=4.0->fake_useragent) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata~=4.0->fake_useragent) (3.8.1)\nInstalling collected packages: importlib-metadata, fake_useragent\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 6.0.0\n    Uninstalling importlib-metadata-6.0.0:\n      Successfully uninstalled importlib-metadata-6.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nflake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 4.13.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fake_useragent-1.5.1 importlib-metadata-4.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(arr)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T15:59:30.940917Z","iopub.execute_input":"2024-10-14T15:59:30.941340Z","iopub.status.idle":"2024-10-14T15:59:30.958599Z","shell.execute_reply.started":"2024-10-14T15:59:30.941297Z","shell.execute_reply":"2024-10-14T15:59:30.957439Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                0     1     2           3\n0          Kansas  28.5  2008  2008-11-10\n1      N Carolina  28.4  2008  2008-11-10\n2            Duke  28.1  2008  2008-11-10\n3         Memphis  27.0  2008  2008-11-10\n4      Louisville  26.2  2008  2008-11-10\n..            ...   ...   ...         ...\n641      Hartford  -0.8  2008  2008-11-10\n642   N Hampshire  -0.9  2008  2008-11-10\n643        Mercer  -0.9  2008  2008-11-10\n644      Idaho St  -1.2  2008  2008-11-10\n645  UC Riverside  -1.3  2008  2008-11-10\n\n[646 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kansas</td>\n      <td>28.5</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>N Carolina</td>\n      <td>28.4</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Duke</td>\n      <td>28.1</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Memphis</td>\n      <td>27.0</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Louisville</td>\n      <td>26.2</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>641</th>\n      <td>Hartford</td>\n      <td>-0.8</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>642</th>\n      <td>N Hampshire</td>\n      <td>-0.9</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>Mercer</td>\n      <td>-0.9</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>Idaho St</td>\n      <td>-1.2</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n    <tr>\n      <th>645</th>\n      <td>UC Riverside</td>\n      <td>-1.3</td>\n      <td>2008</td>\n      <td>2008-11-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>646 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'<table' in str(html)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T15:56:25.783376Z","iopub.execute_input":"2024-10-14T15:56:25.783847Z","iopub.status.idle":"2024-10-14T15:56:25.791132Z","shell.execute_reply.started":"2024-10-14T15:56:25.783808Z","shell.execute_reply":"2024-10-14T15:56:25.789865Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"rh={}\nu=[]\nfor team in years[2023]:\n    rh[team]=(eloLeague.ratingDict[team])\n    u.append(eloLeague.ratingDict[team])\nrh=sorted(rh, key=rh.get, reverse=True)\ni=1\nprint(np.mean(u))\nprint(\"Rank||Team||Points Above d1 Average\")\nfor key in rh:\n    print(str(i)+\"  \"+key+\"  \"+str(eloLeague.ratingDict[key]-np.mean(u))+\"\")\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2024-09-19T00:13:27.773459Z","iopub.execute_input":"2024-09-19T00:13:27.773912Z","iopub.status.idle":"2024-09-19T00:13:27.809278Z","shell.execute_reply.started":"2024-09-19T00:13:27.773874Z","shell.execute_reply":"2024-09-19T00:13:27.808156Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"1526.5169673225107\nRank||Team||Points Above d1 Average\n1  Connecticut  461.4182344304886\n2  Purdue  385.85410002334606\n3  Houston  358.0079270256358\n4  Iowa State  338.8530030025802\n5  Auburn  311.8145424292777\n6  Illinois  311.1588165809478\n7  Gonzaga  295.26343448093075\n8  North Carolina  291.2620456855291\n9  Creighton  290.09364132557516\n10  Duke  288.5691983274023\n11  Tennessee  284.7641858594668\n12  Marquette  268.519083091674\n13  Arizona  258.7513934848755\n14  Alabama  251.68511344890044\n15  Saint Mary's (CA)  246.64438580392152\n16  Baylor  235.30123016498374\n17  San Diego State  232.09485091815782\n18  Texas  228.9578246127112\n19  Indiana State  223.41284668784078\n20  Grand Canyon  219.29207430281986\n21  Kansas  215.5905831027644\n22  Nevada  213.41069485124603\n23  Kentucky  212.60346889531297\n24  Texas Tech  211.76938680785406\n25  Brigham Young  211.16771750973066\n26  Drake  209.22143588340555\n27  St. John's (NY)  205.90518235135664\n28  Texas A&M  203.3392827560367\n29  James Madison  201.25395293857696\n30  Clemson  200.6531007908568\n31  Florida  200.19548507672857\n32  Nebraska  198.31472662011652\n33  Florida Atlantic  197.72540716105823\n34  Utah State  197.6112967754268\n35  Wisconsin  196.60188184929166\n36  Michigan State  195.5610272762642\n37  NC State  194.88274992784318\n38  New Mexico  194.52468323620656\n39  Seton Hall  194.3699088264559\n40  Northwestern  194.04909933752788\n41  Dayton  192.20307209204134\n42  Colorado  179.86650482326377\n43  Pittsburgh  179.80326749693245\n44  Mississippi State  179.46175946938752\n45  Ohio State  177.26388038601795\n46  Cincinnati  175.03146188897404\n47  TCU  172.94914611455124\n48  Memphis  171.40062388168508\n49  Colorado State  169.5101349606482\n50  Samford  167.3040483321697\n51  South Carolina  165.73763310159893\n52  Oklahoma  163.4597171877308\n53  Vermont  160.81075552786274\n54  Boise State  160.7266181949774\n55  Princeton  159.9310532251077\n56  College of Charleston  158.94835508489382\n57  Washington State  157.35447976974683\n58  Bradley  152.997404450148\n59  Iowa  152.03243042997428\n60  UC Irvine  150.14288659500266\n61  San Francisco  148.95824154137927\n62  Villanova  147.7986100642056\n63  Oregon  147.68068441495006\n64  Appalachian State  144.8090520683511\n65  South Florida  143.57680130428707\n66  Yale  143.2012474604212\n67  Virginia Commonwealth  142.49864678133372\n68  Duquesne  138.22636928052748\n69  Kansas State  134.4290404356077\n70  Providence  133.33964895319764\n71  Cornell  129.9582293720448\n72  Wake Forest  128.78940533075365\n73  North Texas  122.85299148135618\n74  Loyola (IL)  120.86257950011031\n75  Xavier  120.49106849256691\n76  Richmond  119.27501228527967\n77  Nevada-Las Vegas  117.0579436299563\n78  Maryland  113.94805570179437\n79  UT Arlington  113.4246956829727\n80  McNeese State  110.29691612484908\n81  Penn State  109.99041048321624\n82  Central Florida  109.46808560483532\n83  UAB  107.48293002761693\n84  Louisiana Tech  105.81646556041028\n85  Tarleton State  105.56497227452041\n86  Belmont  104.00627925520735\n87  Indiana  102.61611959952165\n88  Massachusetts  101.8073894132026\n89  Akron  101.37079216520738\n90  Boston College  100.9270644197652\n91  Sam Houston  98.74407234992782\n92  Virginia  98.3179696498571\n93  Southern Methodist  98.04671736093565\n94  Western Carolina  96.64498173530956\n95  Virginia Tech  96.27544148988909\n96  Colgate  94.25387896184156\n97  Utah  94.23311582221186\n98  Seattle  94.20182950683761\n99  Santa Clara  89.55747387711949\n100  Morehead State  89.30977506836302\n101  Toledo  87.67356734482632\n102  South Dakota State  86.545827967891\n103  Saint Joseph's  85.06503452782817\n104  Ohio  84.10443450438788\n105  George Mason  83.53495775808051\n106  Butler  81.59396764528356\n107  Minnesota  80.72686556099802\n108  High Point  80.62573183944573\n109  Hofstra  79.8114399027088\n110  Eastern Washington  79.5909233697214\n111  Arkansas State  78.59180565529073\n112  Western Kentucky  77.07258950584242\n113  Syracuse  75.8411794844285\n114  Northern Iowa  74.09619853264712\n115  Massachusetts-Lowell  72.1366325291483\n116  Charlotte  70.38825222183118\n117  Oakland  68.8390957224783\n118  Chattanooga  65.93054055627817\n119  St. Bonaventure  65.63454621396545\n120  Quinnipiac  64.48082712356131\n121  UC San Diego  62.69646492744846\n122  Troy  62.48673687940868\n123  Youngstown State  60.21977918454627\n124  UNC Wilmington  56.56485608336334\n125  Fairfield  55.308753183133604\n126  Drexel  54.61993405733756\n127  Washington  53.32176919288986\n128  Georgia  51.788892571503084\n129  Furman  50.825110487972324\n130  UNC Greensboro  50.59101107365086\n131  UCLA  50.070042537862946\n132  Florida State  49.321878627268916\n133  Southern Illinois  47.61380518578221\n134  Southern California  47.50421524585113\n135  Rutgers  40.92930180721737\n136  Mississippi  38.38106924856538\n137  Montana  37.11734108001656\n138  Bryant  36.51683440269426\n139  St. Thomas  36.02366582142872\n140  Louisiana State  32.83259561138789\n141  Wright State  32.50917503900837\n142  Hawaii  31.10900730180083\n143  Long Beach State  30.170527590660868\n144  Purdue Fort Wayne  28.864603055409134\n145  UC Davis  28.243232065110988\n146  Kent State  28.214555016890927\n147  East Tennessee State  27.04625740624101\n148  Towson  26.802654508897376\n149  Lipscomb  23.76117014820079\n150  Utah Valley  22.64872133497761\n151  Weber State  21.80285561902565\n152  Oklahoma State  21.4983265704916\n153  Arkansas  19.625610474154428\n154  UNC Asheville  18.634508782994317\n155  Wyoming  17.19241641830854\n156  Louisiana  16.06992530343109\n157  Little Rock  13.270054643279764\n158  Missouri State  12.81544144399345\n159  Brown  9.937772989412451\n160  Davidson  9.26446287166118\n161  Saint Peter's  8.747510468361497\n162  Stephen F. Austin  7.622685535546452\n163  Texas State  7.302466288666437\n164  Wofford  6.614733287321997\n165  Merrimack  6.198235966189259\n166  Rider  5.496864662369262\n167  Stony Brook  4.028909125123619\n168  UTEP  3.4640607339906637\n169  Wichita State  2.5578384734499195\n170  Kansas City  2.1926195079411173\n171  Longwood  0.3702067386136605\n172  Tennessee-Martin  -3.6533167663262702\n173  Miami (FL)  -4.329690508579006\n174  Stetson  -4.523571582931027\n175  North Dakota  -6.219597129497743\n176  Northern Kentucky  -6.834419727986642\n177  Liberty  -7.133313023890423\n178  Notre Dame  -8.060710287414167\n179  Marist  -8.261634565333225\n180  Tulane  -9.66737183698956\n181  Mercer  -11.073844535228773\n182  Montana State  -13.270613172264348\n183  Abilene Christian  -13.452182782809132\n184  Stanford  -13.713602532720415\n185  South Alabama  -14.109669116550776\n186  Milwaukee  -14.720585109987269\n187  Temple  -15.281486841774267\n188  Murray State  -15.42566484615918\n189  Cleveland State  -15.456159550547454\n190  Delaware  -16.83364200118467\n191  UC Riverside  -18.95432777883184\n192  Northern Colorado  -19.619220427108758\n193  Bowling Green State  -19.907108119425857\n194  Harvard  -20.488201913044122\n195  Texas A&M-Corpus Christi  -21.448048451210752\n196  Monmouth  -21.95754906108209\n197  Eastern Kentucky  -22.784462067249706\n198  Illinois State  -24.658167110854265\n199  California  -24.877392957723032\n200  Michigan  -29.176582878926183\n201  Iona  -29.833676684232387\n202  Arizona State  -30.120280414816307\n203  UC Santa Barbara  -30.715916782571185\n204  Central Michigan  -31.53554452737808\n205  La Salle  -32.555477945401435\n206  Central Connecticut State  -32.72957004762475\n207  Norfolk State  -33.824558337327744\n208  Lehigh  -35.036593942527816\n209  Georgia Tech  -35.75704270727306\n210  Loyola Marymount  -36.40152581883103\n211  Mount St. Mary's  -37.48691572203302\n212  Pepperdine  -38.82223072923534\n213  Maine  -38.935138966733575\n214  Ball State  -38.96461318914339\n215  Western Illinois  -39.25543804339941\n216  West Virginia  -39.421534125126755\n217  Tulsa  -39.723215842570426\n218  California Baptist  -42.8544712830419\n219  Saint Louis  -43.42540580434297\n220  Nicholls State  -44.75459692565505\n221  San Diego  -45.675351397559325\n222  Pennsylvania  -48.481644602240976\n223  Niagara  -49.40017369430939\n224  East Carolina  -49.49148924981819\n225  Jacksonville State  -51.49616186183721\n226  Florida Gulf Coast  -51.89978768661467\n227  Bucknell  -53.774239745085424\n228  Fordham  -53.83291779673891\n229  Winthrop  -54.193370960274706\n230  North Florida  -54.34213054053794\n231  Columbia  -56.78941045732381\n232  Miami (OH)  -58.9413632300907\n233  Cal State Fullerton  -59.84239531156504\n234  Boston University  -60.15418316211776\n235  Gardner-Webb  -60.46476070515587\n236  Austin Peay  -61.51065268850607\n237  Georgia State  -61.536039611730075\n238  Cal State Northridge  -62.018397620682435\n239  New Hampshire  -62.9236028141338\n240  Idaho State  -63.29512893664037\n241  Cal State Bakersfield  -64.3381417353969\n242  Lamar  -65.85263033990009\n243  Canisius  -66.13302729709926\n244  Oregon State  -66.52676965242631\n245  Evansville  -67.50005106499611\n246  Southern Mississippi  -68.61501860692806\n247  Radford  -68.64440396086866\n248  North Dakota State  -69.55212365957868\n249  Omaha  -70.20231513032104\n250  North Alabama  -71.2343425569477\n251  Portland State  -71.96382608857039\n252  Wagner  -73.15518637029254\n253  George Washington  -73.91484694024666\n254  Jacksonville  -73.97616720377005\n255  Marshall  -74.3194222875411\n256  Binghamton  -74.77745572058348\n257  Green Bay  -76.18400475934936\n258  Le Moyne  -76.30689266804711\n259  Maryland-Baltimore County  -76.31344864992798\n260  Queens (NC)  -78.23564506756338\n261  Illinois-Chicago  -78.68222670928844\n262  Rhode Island  -79.49701296723424\n263  Albany (NY)  -79.94616815984386\n264  Grambling  -80.20864059746009\n265  Kennesaw State  -80.75723137318914\n266  Sacred Heart  -81.67894916079922\n267  Portland  -81.73788957087095\n268  American  -82.58006785124576\n269  Middle Tennessee  -83.60027572822878\n270  Southern Utah  -85.2212242816704\n271  Fresno State  -88.12245924806552\n272  Oral Roberts  -88.40285673561016\n273  Missouri  -90.7837099122496\n274  Rice  -91.20372304747798\n275  Denver  -91.22575379682212\n276  Georgia Southern  -92.55895207561753\n277  Northeastern  -92.89668128774451\n278  Tennessee State  -93.65691066374666\n279  Vanderbilt  -94.45115748019452\n280  North Carolina Central  -99.53272038841305\n281  Howard  -99.63099756227507\n282  Southern Illinois-Edwardsville  -100.01920590678128\n283  Western Michigan  -102.08515462512105\n284  Georgetown  -105.66233504901925\n285  UTSA  -106.82214012128225\n286  New Mexico State  -107.0018345352546\n287  Air Force  -107.85889555694621\n288  Navy  -108.50299090052931\n289  Presbyterian  -110.970193560074\n290  Utah Tech  -111.74181220850778\n291  The Citadel  -112.5990330126915\n292  Florida International  -114.35162716168156\n293  San Jose State  -116.19763614766157\n294  Louisiana-Monroe  -118.23159822235766\n295  Northern Arizona  -120.86499217811638\n296  Campbell  -122.74395723347129\n297  Northern Illinois  -124.93198974173924\n298  Texas Southern  -126.93426204022103\n299  Fairleigh Dickinson  -129.97536499111652\n300  Eastern Michigan  -138.04549527322092\n301  Alcorn State  -142.3828755642187\n302  Old Dominion  -144.27915253791798\n303  South Carolina Upstate  -144.31841640043058\n304  Southern  -149.9306219670409\n305  Lafayette  -150.07428069742173\n306  Elon  -153.03583388207608\n307  South Dakota  -155.08678575270255\n308  Delaware State  -155.90584552781115\n309  Robert Morris  -156.74290715590314\n310  Eastern Illinois  -161.25614029499388\n311  South Carolina State  -161.4993626358946\n312  Louisville  -161.64639438109293\n313  Southeastern Louisiana  -162.1164839510518\n314  Bellarmine  -162.61580026247884\n315  Chicago State  -162.69108055029938\n316  Sacramento State  -164.53701491997435\n317  Bethune-Cookman  -167.91996073872383\n318  Jackson State  -170.1318741192531\n319  Dartmouth  -171.84851205501127\n320  Idaho  -171.89676847183796\n321  Coastal Carolina  -173.1076033670263\n322  Valparaiso  -174.83582951131757\n323  Charleston Southern  -175.0615008954942\n324  William & Mary  -179.69796988005328\n325  Tennessee Tech  -180.08663235899462\n326  Holy Cross  -184.11532968686242\n327  Northwestern State  -185.87823836883763\n328  Manhattan  -192.74399768214857\n329  Alabama A&M  -196.54672446317431\n330  Texas A&M-Commerce  -197.7693289673441\n331  Army  -201.89929065265255\n332  NJIT  -202.0400871893446\n333  Southern Indiana  -203.3653679069398\n334  DePaul  -206.02144255286657\n335  Long Island University  -210.50299083595428\n336  Central Arkansas  -212.23952023703146\n337  Morgan State  -218.90565039089574\n338  Hampton  -219.5693133349548\n339  Loyola (MD)  -222.72231426310145\n340  Texas-Rio Grande Valley  -224.3403154227883\n341  Southeast Missouri State  -230.93907999344606\n342  Alabama State  -240.5956417647917\n343  Maryland-Eastern Shore  -242.92479965000462\n344  Pacific  -242.9369005601975\n345  North Carolina A&T  -242.99830661180476\n346  Buffalo  -243.2754912540022\n347  New Orleans  -246.19034735575042\n348  Arkansas-Pine Bluff  -246.60496731623607\n349  Saint Francis (PA)  -250.56025092493473\n350  Lindenwood  -252.41234045016927\n351  Cal Poly  -256.954404927631\n352  Siena  -260.66035930841076\n353  Virginia Military Institute  -267.3381705965985\n354  Prairie View  -268.9615008150545\n355  Stonehill  -271.7747763450998\n356  Detroit Mercy  -271.97073069692624\n357  Incarnate Word  -288.0303423708524\n358  Florida A&M  -289.78808065704084\n359  IUPUI  -298.82943623841925\n360  Houston Christian  -304.81394688168916\n361  Coppin State  -332.30369054579796\n362  Mississippi Valley State  -398.61106723409716\n","output_type":"stream"}]},{"cell_type":"code","source":"((eloLeague.ratingDict['Creighton']+hfas['Big East'])-(eloLeague.ratingDict['North Dakota State']))/17","metadata":{"execution":{"iopub.status.busy":"2024-09-09T15:42:29.780159Z","iopub.execute_input":"2024-09-09T15:42:29.780601Z","iopub.status.idle":"2024-09-09T15:42:29.790001Z","shell.execute_reply.started":"2024-09-09T15:42:29.780565Z","shell.execute_reply":"2024-09-09T15:42:29.788637Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"38.620751581108685"},"metadata":{}}]},{"cell_type":"code","source":"(1443-1266)/9","metadata":{"execution":{"iopub.status.busy":"2024-09-18T20:50:33.480114Z","iopub.execute_input":"2024-09-18T20:50:33.480552Z","iopub.status.idle":"2024-09-18T20:50:33.489223Z","shell.execute_reply.started":"2024-09-18T20:50:33.480515Z","shell.execute_reply":"2024-09-18T20:50:33.487874Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"19.666666666666668"},"metadata":{}}]},{"cell_type":"code","source":"for row in df22.itertuples():\n    spread=row.team1elopre-row.team2elopre\n    spread=spread/9\n    spread=round(spread)\n    if spread==0:\n        \n        if row.team1elopre>row.team2elopre:\n            spread=1\n        else:\n            spread=-1\n    df22.at[row.Index,'predt1spread']=spread","metadata":{"execution":{"iopub.status.busy":"2024-09-18T23:45:29.638343Z","iopub.execute_input":"2024-09-18T23:45:29.638762Z","iopub.status.idle":"2024-09-18T23:45:36.189593Z","shell.execute_reply.started":"2024-09-18T23:45:29.638729Z","shell.execute_reply":"2024-09-18T23:45:36.188285Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"t=df[df.Year==2023]\noff=[]\nfor t in list(t.OFF.tolist()):\n    off.append(float(t))\nmax(off)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T22:28:29.931152Z","iopub.execute_input":"2024-09-18T22:28:29.931565Z","iopub.status.idle":"2024-09-18T22:28:29.942871Z","shell.execute_reply.started":"2024-09-18T22:28:29.931533Z","shell.execute_reply":"2024-09-18T22:28:29.941556Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"115.5"},"metadata":{}}]},{"cell_type":"code","source":"j=np.mean([16,17,20])\n(16*(1-rev))+(rev*j)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T23:54:10.385816Z","iopub.execute_input":"2024-09-18T23:54:10.386278Z","iopub.status.idle":"2024-09-18T23:54:10.395057Z","shell.execute_reply.started":"2024-09-18T23:54:10.386240Z","shell.execute_reply":"2024-09-18T23:54:10.393883Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"17.21666666666667"},"metadata":{}}]},{"cell_type":"code","source":"tr.find_all(\"td\")[0].text","metadata":{"execution":{"iopub.status.busy":"2024-10-01T04:09:28.454255Z","iopub.execute_input":"2024-10-01T04:09:28.454685Z","iopub.status.idle":"2024-10-01T04:09:28.461873Z","shell.execute_reply.started":"2024-10-01T04:09:28.454647Z","shell.execute_reply":"2024-10-01T04:09:28.460763Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'1949-502'"},"metadata":{}}]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport requests\nsep=\"\"\ndef remove_tags(html):\n\n    # parse html content\n    soup = BeautifulSoup(html, \"html.parser\")\n\n    for data in soup(['style', 'script']):\n        # Remove tags\n        data.decompose()\n\n    # return data by retrieving the tag content\n    return ' '.join(soup.stripped_strings)\nyears=[1950,1962,1973,1974]\nimport pandas as pd\nyu=[]\nfrom datetime import datetime,timedelta\nhtml=requests.get(\"https://academics.smcvt.edu/jtrono/BBallArchive.htm\").text\nsoup=BeautifulSoup(html)\ntable=soup.find_all(\"table\")[0]\narr=[]\nfor tr in table.find_all(\"tr\"):\n    print(len(yu),\":\",season)\n    season=tr.find_all(\"td\")[0].text\n    yearz=season[:-1]\n    yearz=yearz[2::]\n    yearz=yearz.replace(\"-\",\"_\")\n    print(season)\n    season=season.split(\"-\")[0]\n    link='https://academics.smcvt.edu/jtrono/'+tr.find_all(\"a\")[0]['href']\n    j=link\n    j=j.split(\"Archive/\")[1]\n    j=j.split(\"_dt\")[0]\n    \n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    \n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    body=body.replace(\"<p>\",\"\")\n    \n    body=body.split(\"<br/>\")\n    \n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        \n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line) and line!='\\xa0\\n</body>' and line!='\\n':\n            \n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            date=line.split(\" \")[0]\n            home=line.split(\" \")[1]\n            pts=line.split(\" \")[2]\n            away=line.split(\" \")[3]\n            opp=line.split(\" \")[4]\n            venue=line.split(\" \")[5]\n            \n            if date[0]=='2':\n                date=season+sep+\"11\"+sep+date[1::]\n            if date[0]=='3':\n                date=season+sep+\"12\"+sep+date[1::]\n            if date[0]=='4':\n                date=str(float(season)+1)+sep+\"01\"+sep+date[1::]\n            if date[0]=='5':\n                date=str(float(season)+1)+sep+\"02\"+sep+date[1::]\n            if date[0]=='6':\n                date=str(float(season)+1)+sep+\"03\"+sep+date[1::]\n            if date[0]=='7':\n                date=str(float(season)+1)+sep+\"04\"+sep+date[1::]\n            date=date.replace(\"F\",\"\")\n            date=date.replace(\"f\",\"\")\n            date=date.replace(\".0\",\"\")\n            date=float(date)\n            notes=''\n            if len(line.split(\" \"))>6:\n                notes=line.split(\" \")[6]\n            \n            arr.append([date,home,away,pts,opp,venue,season,notes])\n    link='https://academics.smcvt.edu/jtrono/'+tr.find_all(\"a\")[1]['href']\n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    \n    body=body.replace(\"<p>\",\"\")\n    body=body.split(\"<br/>\")\n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line) and line!='\\xa0\\n</body>' and season in years:\n            \n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            \n            date=line.split(\" \")[0]\n            home=line.split(\" \")[1]\n            pts=line.split(\" \")[2]\n            away=line.split(\" \")[3]\n            opp=line.split(\" \")[4]\n            venue=line.split(\" \")[5]\n            if date[0]=='2':\n                date=season+sep+\"11\"+sep+date[1::]\n            if date[0]=='3':\n                date=season+sep+\"12\"+sep+date[1::]\n            if date[0]=='4':\n                date=str(float(season)+1)+sep+\"01\"+sep+date[1::]\n            if date[0]=='5':\n                date=str(float(season)+1)+sep+\"02\"+sep+date[1::]\n            if date[0]=='6':\n                date=str(float(season)+1)+sep+\"03\"+sep+date[1::]\n            if date[0]=='7':\n                date=str(float(season)+1)+sep+\"04\"+sep+date[1::]\n            date=date.replace(\"F\",\"\")\n            date=date.replace(\"f\",\"\")\n            date=date.replace(\".0\",\"\")\n            date=float(date)\n            notes=''\n            if len(line.split(\" \"))>6:\n                notes=line.split(\" \")[6]\n            \n            arr.append([date,home,away,pts,opp,venue,season,notes])\n    datez=date\n    j=j.split(\".dts\")[0]\n    jz=str(j)\n    j=jz\n    link='https://academics.smcvt.edu/jtrono/NCAA_Archive/'+j+\"_nit.htm\"\n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    body=body.replace(\"<p>\",\"\")\n    \n    body=body.split(\"<br/>\")\n    \n    datez=date\n   \n    \n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line)  and line!='\\xa0\\n</body>':\n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            home=line.split(\" \")[0]\n            pts=line.split(\" \")[1]\n            away=line.split(\" \")[2]\n            opp=line.split(\" \")[3]\n            venue=line.split(\" \")[4]\n            \n            \n            \n            notes=''\n            if len(line.split(\" \"))>5:\n                notes=line.split(\" \")[5]\n            datez+=1\n            \n            arr.append([datez,home,away,pts,opp,venue,season,notes])\n    link='https://academics.smcvt.edu/jtrono/NCAA_Archive/'+j+\"_ncaa.htm\"\n    ht=requests.get(link).text\n\n   \n    soupz=BeautifulSoup(ht)\n    \n    body=soupz.find_all(\"body\")[0]\n    body=str(body)\n    body=body.replace(\"<br>\",\"<br/>\")\n    body=body.replace(\"<p>\",\"\")\n    \n    body=body.split(\"<br/>\")\n    datez=date\n    \n    for line in body:\n        line=remove_tags(line)\n        line=line.replace(\"\\r\\n\",\"\")\n        \n        if 'html' not in str(line) and line!='' and line!='\\xa0' and '<body>' not in str(line)  and line!='\\xa0\\n</body>':\n            \n            line=line.replace(\"leftmargin\",\"\")\n            line=line.replace(\"35\",\"\")\n            line=line.replace('\"',\"\")\n            line=line.replace(\"<body\",\"\")\n            line=line.replace(\"topmargin\",\"\")\n            line=line.replace(\" = \",\"\")\n            line=line.replace(\">\\n\",\"\")\n            line=line.replace(\"=\",\"\")\n            line=line.replace(\"5V\",\"5 V\")\n            home=line.split(\" \")[0]\n            pts=line.split(\" \")[1]\n            away=line.split(\" \")[2]\n            opp=line.split(\" \")[3]\n            venue=line.split(\" \")[4]\n            \n            \n            \n            notes=''\n            if len(line.split(\" \"))>5:\n                notes=line.split(\" \")[5]\n            datez+=1\n            \n            arr.append([datez,home,away,pts,opp,venue,season,notes])\n    \ndf=pd.DataFrame(arr,columns=['date','home','away','homep','awayp','venue','season','notes'])\ndf=df.astype({\"season\":float})","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:23:33.562828Z","iopub.execute_input":"2024-10-14T01:23:33.563513Z","iopub.status.idle":"2024-10-14T01:27:57.534826Z","shell.execute_reply.started":"2024-10-14T01:23:33.563468Z","shell.execute_reply":"2024-10-14T01:27:57.533047Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"0 : 1999\n1999-20001\n0 : 1999\n1998-991\n0 : 1998\n1997-981\n0 : 1997\n1996-971\n0 : 1996\n1995-961\n0 : 1995\n1994-953\n0 : 1994\n1993-943\n0 : 1993\n1992-933\n0 : 1992\n1991-923\n0 : 1991\n1990-913\n0 : 1990\n1989-903\n0 : 1989\n1988-893\n0 : 1988\n1987-883\n0 : 1987\n1986-873\n0 : 1986\n1985-863\n0 : 1985\n1984-853\n0 : 1984\n1983-844\n0 : 1983\n1982-834\n0 : 1982\n1981-824\n0 : 1981\n1980-814\n0 : 1980\n1979-804\n0 : 1979\n1978-794\n0 : 1978\n1977-784\n0 : 1977\n1976-774\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/bs4/__init__.py:439: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  MarkupResemblesLocatorWarning\n","output_type":"stream"},{"name":"stdout","text":"0 : 1976\n1975-764\n0 : 1975\n1974-754\n0 : 1974\n1973-744\n0 : 1973\n1972-734\n0 : 1972\n1971-724\n0 : 1971\n1970-714\n0 : 1970\n1969-702\n0 : 1969\n1968-692\n0 : 1968\n1967-682\n0 : 1967\n1966-67\n0 : 1966\n1965-662\n0 : 1965\n1964-652\n0 : 1964\n1963-642\n0 : 1963\n1962-632\n0 : 1962\n1961-622\n0 : 1961\n1960-612\n0 : 1960\n1959-602\n0 : 1959\n1958-592\n0 : 1958\n1957-582\n0 : 1957\n1956-572\n0 : 1956\n1955-562\n0 : 1955\n1954-552\n0 : 1954\n1953-542\n0 : 1953\n1952-532\n0 : 1952\n1951-522\n0 : 1951\n1950-512\n0 : 1950\n1949-502\n","output_type":"stream"}]},{"cell_type":"code","source":"u=we[we.season==1979]\nht=requests.get(\"https://academics.smcvt.edu/jtrono/NCAA_Archive/79_80_dts.htm\").text\nsoupz=BeautifulSoup(ht)\n    \nbody=soupz.find_all(\"body\")[0]\nbody=str(body)\nbody=body.replace(\"<br>\",\"<br/>\")\nbody=body.replace(\"<p>\",\"\")\n    \nbody=body.split(\"<br/>\")\nbody[2000]","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:15:53.520782Z","iopub.execute_input":"2024-10-14T01:15:53.521259Z","iopub.status.idle":"2024-10-14T01:15:54.792667Z","shell.execute_reply.started":"2024-10-14T01:15:53.521218Z","shell.execute_reply":"2024-10-14T01:15:54.791314Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"'430 MER 75 STE 56 H'"},"metadata":{}}]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['date','home','away','homep','awayp','venue','season','notes'])\ndf=df.astype({\"season\":float})\ndf.to_csv(\"allbbz.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:28:49.859797Z","iopub.execute_input":"2024-10-14T01:28:49.860234Z","iopub.status.idle":"2024-10-14T01:28:50.606675Z","shell.execute_reply.started":"2024-10-14T01:28:49.860194Z","shell.execute_reply":"2024-10-14T01:28:50.604751Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"df[df.homep=='WMI']","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:21:46.584159Z","iopub.execute_input":"2024-10-14T01:21:46.584614Z","iopub.status.idle":"2024-10-14T01:21:46.612577Z","shell.execute_reply.started":"2024-10-14T01:21:46.584576Z","shell.execute_reply":"2024-10-14T01:21:46.611198Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"             date home away homep awayp venue  season notes\n85192  19781129.0        72   WMI   VAL    66  1978.0     H","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>home</th>\n      <th>away</th>\n      <th>homep</th>\n      <th>awayp</th>\n      <th>venue</th>\n      <th>season</th>\n      <th>notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>85192</th>\n      <td>19781129.0</td>\n      <td></td>\n      <td>72</td>\n      <td>WMI</td>\n      <td>VAL</td>\n      <td>66</td>\n      <td>1978.0</td>\n      <td>H</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(yu)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:09:06.981010Z","iopub.execute_input":"2024-10-14T01:09:06.981605Z","iopub.status.idle":"2024-10-14T01:09:06.989066Z","shell.execute_reply.started":"2024-10-14T01:09:06.981554Z","shell.execute_reply":"2024-10-14T01:09:06.987861Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"2939"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv(\"allscores.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T12:08:06.043673Z","iopub.execute_input":"2024-10-01T12:08:06.044114Z","iopub.status.idle":"2024-10-01T12:08:06.967484Z","shell.execute_reply.started":"2024-10-01T12:08:06.044077Z","shell.execute_reply":"2024-10-01T12:08:06.966140Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"len(line)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T01:07:55.264014Z","iopub.execute_input":"2024-10-14T01:07:55.264610Z","iopub.status.idle":"2024-10-14T01:07:55.273077Z","shell.execute_reply.started":"2024-10-14T01:07:55.264556Z","shell.execute_reply":"2024-10-14T01:07:55.271576Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"'\\r\\nDUQ 94 GEW 89 A'"},"metadata":{}}]},{"cell_type":"code","source":"df13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf13=df13[df13.Year!='Year']\ndf13[df13.Year=='2000-01']\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")\ndf19=df19[df19.Year!='Year']\ndf19[df19.Year=='2000-01']","metadata":{"execution":{"iopub.status.busy":"2024-10-14T03:32:33.271160Z","iopub.execute_input":"2024-10-14T03:32:33.271639Z","iopub.status.idle":"2024-10-14T03:32:33.448865Z","shell.execute_reply.started":"2024-10-14T03:32:33.271597Z","shell.execute_reply":"2024-10-14T03:32:33.447675Z"},"trusted":true},"execution_count":171,"outputs":[{"execution_count":171,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0     Year        Date    ?               Schl  Rk.  ?.1  \\\n173           33  2000-01  2000-11-09  NaN    St. John's (NY)  NaN  NaN   \n174           34  2000-01  2000-11-10  NaN     North Carolina    6  NaN   \n175           35  2000-01  2000-11-10  NaN    St. John's (NY)  NaN  NaN   \n176           36  2000-01  2000-11-11  NaN     North Carolina    6  NaN   \n177           37  2000-01  2000-11-13  NaN         California  NaN  NaN   \n...          ...      ...         ...  ...                ...  ...  ...   \n4730          14  2000-01  2001-03-20  NaN             Purdue  NaN  NaN   \n4731          15  2000-01  2001-03-21  NaN             Dayton  NaN  NaN   \n4732          16  2000-01  2001-03-21  NaN  Mississippi State  NaN  NaN   \n4733          17  2000-01  2001-03-22  NaN            Memphis  NaN  NaN   \n4734          18  2000-01  2001-03-23  NaN             Purdue  NaN  NaN   \n\n                    Opp Rk..1 ?.2  ?.3 PTS OPP  MOV  ?.4   OT  neutral  \n173            Kentucky    12   W  NaN  62  61    1  NaN  NaN    False  \n174            Winthrop   NaN   W  NaN  66  61    5  NaN  NaN    False  \n175              Kansas     7   L  NaN  74  82   -8  NaN  NaN    False  \n176               Tulsa   NaN   W  NaN  91  81   10  NaN  NaN    False  \n177   Mississippi State   NaN   W  NaN  83  76    7  NaN    1    False  \n...                 ...   ...  ..  ...  ..  ..  ...  ...  ...      ...  \n4730             Auburn   NaN   W  NaN  79  61   18  NaN  NaN    False  \n4731      Detroit Mercy   NaN   L  NaN  42  59  -17  NaN  NaN    False  \n4732              Tulsa   NaN   L  NaN  75  77   -2  NaN  NaN    False  \n4733         New Mexico   NaN   W  NaN  81  63   18  NaN  NaN    False  \n4734            Alabama   NaN   L  NaN  77  85   -8  NaN    2    False  \n\n[4387 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Year</th>\n      <th>Date</th>\n      <th>?</th>\n      <th>Schl</th>\n      <th>Rk.</th>\n      <th>?.1</th>\n      <th>Opp</th>\n      <th>Rk..1</th>\n      <th>?.2</th>\n      <th>?.3</th>\n      <th>PTS</th>\n      <th>OPP</th>\n      <th>MOV</th>\n      <th>?.4</th>\n      <th>OT</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>173</th>\n      <td>33</td>\n      <td>2000-01</td>\n      <td>2000-11-09</td>\n      <td>NaN</td>\n      <td>St. John's (NY)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kentucky</td>\n      <td>12</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>62</td>\n      <td>61</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>34</td>\n      <td>2000-01</td>\n      <td>2000-11-10</td>\n      <td>NaN</td>\n      <td>North Carolina</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>Winthrop</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>66</td>\n      <td>61</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>35</td>\n      <td>2000-01</td>\n      <td>2000-11-10</td>\n      <td>NaN</td>\n      <td>St. John's (NY)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kansas</td>\n      <td>7</td>\n      <td>L</td>\n      <td>NaN</td>\n      <td>74</td>\n      <td>82</td>\n      <td>-8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>36</td>\n      <td>2000-01</td>\n      <td>2000-11-11</td>\n      <td>NaN</td>\n      <td>North Carolina</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>Tulsa</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>91</td>\n      <td>81</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>37</td>\n      <td>2000-01</td>\n      <td>2000-11-13</td>\n      <td>NaN</td>\n      <td>California</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Mississippi State</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>83</td>\n      <td>76</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4730</th>\n      <td>14</td>\n      <td>2000-01</td>\n      <td>2001-03-20</td>\n      <td>NaN</td>\n      <td>Purdue</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Auburn</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>79</td>\n      <td>61</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4731</th>\n      <td>15</td>\n      <td>2000-01</td>\n      <td>2001-03-21</td>\n      <td>NaN</td>\n      <td>Dayton</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Detroit Mercy</td>\n      <td>NaN</td>\n      <td>L</td>\n      <td>NaN</td>\n      <td>42</td>\n      <td>59</td>\n      <td>-17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4732</th>\n      <td>16</td>\n      <td>2000-01</td>\n      <td>2001-03-21</td>\n      <td>NaN</td>\n      <td>Mississippi State</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tulsa</td>\n      <td>NaN</td>\n      <td>L</td>\n      <td>NaN</td>\n      <td>75</td>\n      <td>77</td>\n      <td>-2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4733</th>\n      <td>17</td>\n      <td>2000-01</td>\n      <td>2001-03-22</td>\n      <td>NaN</td>\n      <td>Memphis</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>New Mexico</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>81</td>\n      <td>63</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4734</th>\n      <td>18</td>\n      <td>2000-01</td>\n      <td>2001-03-23</td>\n      <td>NaN</td>\n      <td>Purdue</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Alabama</td>\n      <td>NaN</td>\n      <td>L</td>\n      <td>NaN</td>\n      <td>77</td>\n      <td>85</td>\n      <td>-8</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>4387 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf2=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1949-1959h.csv\")\ndf3=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1959-1969h.csv\")\ndf4=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1969-1970h.csv\")\ndf5=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1971-1979h.csv\")\nimport re\ndef has_numbers(inputString):\n    return bool(re.search(r'\\d', inputString))\ndf6=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1980-1985h.csv\")\ndf7=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1986-1987h.csv\")\ndf7=df7[df7.Year!=1988]\ndf8=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1988-1989h.csv\")\ndf9=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1990-1992h.csv\")\ndf10=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1993-1994h.csv\")\ndf10=df10[df10.Year<\"1995-96\"]\ndf11=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1995-1996h.csv\")\ndf12=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/1997-1999h.csv\")\ndf13=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2000-2004h.csv\")\ndf14=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2005-2011h.csv\")\ndf15=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2012-2020h.csv\")\ndf16=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/notneutral/home/2021h.csv\")\ndf17=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1949-1988n.csv\")\ndf17=df17[df17.Year!='1971-72']\ndf20=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1971-1972n.csv\")\ndf17=pd.concat([df20,df17])\ndf18=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/1989-1999n.csv\")\ndf19=pd.read_csv(\"https://ontheroadtovote.com/ncaab/scores/neutral/2000-2021n.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-10T03:43:36.636278Z","iopub.execute_input":"2024-05-10T03:43:36.636693Z","iopub.status.idle":"2024-05-10T03:43:48.225557Z","shell.execute_reply.started":"2024-05-10T03:43:36.636661Z","shell.execute_reply":"2024-05-10T03:43:48.223867Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"df1=pd.concat([df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19],ignore_index=True)\narr=[]\ndf100=df1.sort_values(by='Date')\ndf1=df1[['Year','Date','neutral','PTS','OPP','Year','Opp','Schl']]\ndf1=df1.drop_duplicates()\nys=[]\n\nimport sys\nfor Date in df100.Date.unique():\n    times=1\n    teams=[]\n    \n    if '2003' in str(Date):\n        sys.exit(1)\n    if row.Year not in ys:\n        ys.append(row.Year)\n        print(row.Year)\n    df=df1[df1.Date==Date]\n    for row in df.itertuples():\n        if row.Schl in teams or row.Opp in teams:\n            times+=1\n            num=20*times\n            date=row.Date+\" \"+str(num)+\":00:00\"\n        else:\n            date=row.Date+\" 00:00:00\"\n        arr.append([row.Schl,date,row.Opp,row.Year,'vs',row.neutral,row.PTS,row.OPP])\n        teams.append(row.Schl)\n        teams.append(row.Opp)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-10T03:48:13.240018Z","iopub.execute_input":"2024-05-10T03:48:13.240542Z","iopub.status.idle":"2024-05-10T03:50:48.933940Z","shell.execute_reply.started":"2024-05-10T03:48:13.240506Z","shell.execute_reply":"2024-05-10T03:50:48.932281Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"2002-03\n1949-50\n1950-51\n1951-52\n1952-53\n1953-54\n1954-55\n1955-56\n1956-57\n1957-58\n1958-59\n1959-60\n1960-61\n1961-62\n1962-63\n1963-64\n1964-65\n1965-66\n1966-67\n1967-68\n1968-69\n1969-70\n1970-71\n1971-72\n1972-73\n1973-74\n1974-75\n1975-76\n1976-77\n1977-78\n1978-79\n1979-80\n1980-81\n1981-82\n1982-83\n1983-84\n1984-85\n1985-86\n1986-87\n1987-88\n1988-89\n1989-90\n1990-91\n1991-92\n1992-93\n1993-94\n1994-95\n1995-96\n1996-97\n1997-98\n1998-99\n1999-00\n2000-01\n2001-02\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"],"ename":"SystemExit","evalue":"1","output_type":"error"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3560: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# d2 scores from 2007 season","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup, Comment\n\nlinks={}\nimport time\narr=[]\nys={}\nfor i in range(1950,2025):\n    ys[i]=[]\nfor i in range(1950,2025):\n    print(i)\n    links[i]=[]\n    html=requests.get(\"https://www.sports-reference.com/cbb/seasons/men/\"+str(i)+\"-standings.html\")\n    print(html.status_code)\n    html=html.text\n    html=html.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n    soup=BeautifulSoup(html,'lxml')\n    \n    \n    y=i-1\n    for table in soup.find_all(\"table\"):\n        for tr in table.find_all(\"tr\"):\n            if \"Notes\" not in str(tr) and 'Overall' not in str(tr):\n                \n                \n                schl=tr.find_all(\"td\")[0].text\n                conf=tr.find_all(\"td\")[1].text\n                srs=tr.find_all(\"td\")[13].text\n            \n                \n                arr.append([schl,conf,y,srs])\n    time.sleep(5)\n    print(len(arr))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T01:05:44.546210Z","iopub.execute_input":"2024-09-09T01:05:44.547194Z","iopub.status.idle":"2024-09-09T01:12:58.985149Z","shell.execute_reply.started":"2024-09-09T01:05:44.547088Z","shell.execute_reply":"2024-09-09T01:12:58.983818Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"1950\n200\n170\n1951\n200\n342\n1952\n200\n513\n1953\n200\n687\n1954\n200\n861\n1955\n200\n1037\n1956\n200\n1212\n1957\n200\n1388\n1958\n200\n1571\n1959\n200\n1752\n1960\n200\n1933\n1961\n200\n2112\n1962\n200\n2292\n1963\n200\n2472\n1964\n200\n2652\n1965\n200\n2834\n1966\n200\n3021\n1967\n200\n3213\n1968\n200\n3405\n1969\n200\n3604\n1970\n200\n3808\n1971\n200\n4016\n1972\n200\n4238\n1973\n200\n4469\n1974\n200\n4707\n1975\n200\n4946\n1976\n200\n5185\n1977\n200\n5436\n1978\n200\n5697\n1979\n200\n5960\n1980\n200\n6226\n1981\n200\n6491\n1982\n200\n6766\n1983\n200\n7043\n1984\n200\n7318\n1985\n200\n7602\n1986\n200\n7891\n1987\n200\n8181\n1988\n200\n8471\n1989\n200\n8764\n1990\n200\n9057\n1991\n200\n9352\n1992\n200\n9651\n1993\n200\n9950\n1994\n200\n10252\n1995\n200\n10556\n1996\n200\n10868\n1997\n200\n11183\n1998\n200\n11500\n1999\n200\n11818\n2000\n200\n12142\n2001\n200\n12466\n2002\n200\n12794\n2003\n200\n13129\n2004\n200\n13460\n2005\n200\n13795\n2006\n200\n14134\n2007\n200\n14476\n2008\n200\n14822\n2009\n200\n15171\n2010\n200\n15523\n2011\n200\n15874\n2012\n200\n16222\n2013\n200\n16574\n2014\n200\n16928\n2015\n200\n17281\n2016\n200\n17634\n2017\n200\n17987\n2018\n200\n18339\n2019\n200\n18693\n2020\n200\n19047\n2021\n200\n19399\n2022\n200\n19760\n2023\n200\n20123\n2024\n200\n20485\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['School','Conf','Year','SRS'])\ndf=df[df.SRS.notna()]\ndf.to_csv(\"alld1s.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T01:14:23.576467Z","iopub.execute_input":"2024-09-09T01:14:23.576874Z","iopub.status.idle":"2024-09-09T01:14:23.653978Z","shell.execute_reply.started":"2024-09-09T01:14:23.576838Z","shell.execute_reply":"2024-09-09T01:14:23.652669Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## ","metadata":{}}]}
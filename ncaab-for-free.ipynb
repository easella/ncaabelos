{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30396,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/savageopress12345/mechanical-soup-error?scriptVersionId=118868915\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"import pandas as pda\narr=[]\ndfz=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/barttvk.csv\")\ndff=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/barttvk2.csv\")\nfor row in dff.itertuples():\n    arr.append([row.date,row.home,row.away,row.predw,row.line,row.final,row.neutral,row.season])\nfor row in dfz.itertuples():\n    arr.append([row.date,row.home,row.away,row.predw,row.line,row.final,row.neutral,row.season])  \ndf=pd.DataFrame(arr,columns=['date','home','away','predw','line','final','neutral','season'])\ndf=df.astype({\"final\":\"string\"})\ndf=df.replace(\"Ohio St.\",\"Ohio State\")\ndf['final']=df['final'].str.replace(\" St.\",\" State\")\ndf['home']=df['home'].str.replace(\" St.\",\" State\")\ndf['away']=df['away'].str.replace(\" St.\",\" State\")\ndf['predw']=df['predw'].str.replace(\" St.\",\" State\")\ndf=df.replace(\"Penn\",\"Pennsylvania\")\ndf['final']=df['final'].str.replace(\"Penn\",\"Pennsylvania\")\ndf['home']=df['home'].str.replace(\"Penn\",\"Pennsylvania\")\ndf['away']=df['away'].str.replace(\"Penn\",\"Pennsylvania\")\ndf['predw']=df['predw'].str.replace(\"Penn\",\"Pennsylvania\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T01:55:06.053669Z","iopub.execute_input":"2025-10-28T01:55:06.054832Z","iopub.status.idle":"2025-10-28T01:55:08.479138Z","shell.execute_reply.started":"2025-10-28T01:55:06.054772Z","shell.execute_reply":"2025-10-28T01:55:08.477982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"k=[]\nk.append([\"Albany\",\"Albany (NY)\"])\nk.append(['Arkansas Pine Bluff','Arkansas-Pine Bluff'])\nk.append(['Bethune Cookman','Bethune-Cookman'])\nk.append(['Cal Baptist','California Baptist'])\nk.append(['East Texas A&M','Texas A&M-Commerce'])\nk.append(['FIU','Florida International'])\nk.append(['Fairleigh Dickinson','FDU'])\nk.append(['Gardner Webb','Gardner-Webb'])\nk.append(['Grambling State','Grambling'])\nk.append(['Illinois Chicago','Illinois-Chicago'])\nk.append(['IU Indy','IUPUI'])\nk.append(['Loyola MD','Loyola (MD)'])\nk.append(['Louisiana Monroe','Louisiana-Monroe'])\nk.append(['LIU','Long Island University'])\nk.append(['Loyola Chicago','Loyola (IL)'])\nk.append(['LSU','Louisiana State'])\nk.append(['Maryland Eastern Shore','Maryland-Eastern Shore'])\nk.append([\"Mount State Mary's\",\"Mount St. Mary's\"])\nk.append(['Miami FL','Miami (FL)'])\nk.append(['Miami OH','Miami (OH)'])\nk.append(['N.C. Statete','NC State'])\nk.append(['Nebraska Omaha','Omaha'])\nk.append(['Ohio Statete','Ohio State'])\nk.append(['Prairie View A&M','Prairie View'])\nk.append(['Southern Miss','Southern Mississippi'])\nk.append([\"Saint Peter's\",\"Saint Peter's\"])\nk.append(['Saint Francis','Saint Francis (PA)'])\nk.append(['SMU','Southern Methodist'])\nk.append([\"St. John's\",\"St. John's (NY)\"])\nk.append(['St. Francis NY',\"St. Francis (NY)\"])\nk.append(['SIU Edwardsville','Southern Illinois-Edwardsville'])\nk.append([\"Saint Mary's\",\"Saint Mary's (CA)\"])\nk.append(['Sam Houston State','Sam Houston'])\nk.append(['Texas A&M Corpus Chris','Texas A&M-Corpus Christi'])\nk.append(['Tennessee Martin','Tennessee-Martin'])\nk.append(['UMBC','Maryland-Baltimore County'])\nk.append(['UNLV','Nevada-Las Vegas'])\nk.append(['UMKC','Kansas City'])\nk.append(['UT Rio Grande Valley','Texas-Rio Grande Valley'])\nk.append(['USC Upstate','South Carolina Upstate'])\nk.append(['USC','Southern California'])\nk.append(['UMass Lowell','Massachusetts-Lowell'])\nk.append(['VCU','Virginia Commonwealth'])\nk.append(['VMI','Virginia Military Institute'])\nk=pd.DataFrame(k,columns=['t','tr'])\nfor row in k.itertuples():\n    df['final']=df['final'].str.replace(row.t,row.tr)\n    df['home']=df['home'].str.replace(row.t,row.tr)\n    df['away']=df['away'].str.replace(row.t,row.tr)\n    df['predw']=df['predw'].str.replace(row.t,row.tr)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:11:11.650022Z","iopub.execute_input":"2025-10-28T02:11:11.650416Z","iopub.status.idle":"2025-10-28T02:11:18.007874Z","shell.execute_reply.started":"2025-10-28T02:11:11.650384Z","shell.execute_reply":"2025-10-28T02:11:18.006817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:21:23.672207Z","iopub.execute_input":"2025-10-28T02:21:23.672641Z","iopub.status.idle":"2025-10-28T02:21:23.681592Z","shell.execute_reply.started":"2025-10-28T02:21:23.672588Z","shell.execute_reply":"2025-10-28T02:21:23.680490Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts=set(df.home.tolist())\nfor t in ts:\n    if t[0]=='U':\n        print(t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:11:28.746983Z","iopub.execute_input":"2025-10-28T02:11:28.747778Z","iopub.status.idle":"2025-10-28T02:11:28.757108Z","shell.execute_reply.started":"2025-10-28T02:11:28.747743Z","shell.execute_reply":"2025-10-28T02:11:28.755809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv(\"finalbart.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:12:05.373129Z","iopub.execute_input":"2025-10-28T02:12:05.373533Z","iopub.status.idle":"2025-10-28T02:12:05.647648Z","shell.execute_reply.started":"2025-10-28T02:12:05.373497Z","shell.execute_reply":"2025-10-28T02:12:05.646412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport numpy as np\nstart_time = time.time()\nprint('done files')\nimport random\nimport string\nfrom decimal import Decimal\nclass Elo:\n    def __init__(self,k,g=1,homefield = 110): \n        self.ratingDict={}\n        self.k = k\n        self.g = g\n        self.homefield= homefield\n    def addPlayer(self,name,rating = 1500):\n        self.ratingDict[name] = rating\n    def gameOver(self,winner,loser,wp,lp,diffz):\n        o=abs(wp-lp)\n        y=float(((o)+3))\n        mov=((o+3)**0.8)/(7.5+0.006*(diffz))\n        result = self.expectResult(diffz)\n        shift=(self.k*mov)*(1 - result) \n        self.ratingDict[winner]+=shift\n        self.ratingDict[loser]-=shift\n    def expectResult(self,gtz):\n        pq=(Decimal(10)**(Decimal(-gtz)/Decimal(400)))+Decimal(1)\n        o=Decimal(1)/Decimal(pq)\n        return float(o)\nimport requests\nfrom bs4 import BeautifulSoup,Comment\nimport re, csv\nimport pandas as pd\ndf=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/standings.csv\")\nfrom datetime import timedelta,date,datetime\nimport json\nmsqe={}\ncurrSeason=1949\nfor i in range(9,50):\n    msqe[str(i)]=set()\nconfs={}\nfor i in range(1949,2026):\n    confs[i]={}\ndf=df.replace(\"PCC (North)\",\"PCC\")\ndf=df.replace(\"PCC (South)\",\"PCC\")\ndf=df.replace(\"Mid-Atl (Eastern)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (Western)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (East)\",\"Mid-Atl\")\ndf=df.replace(\"Mid-Atl (West)\",\"Mid-Atl\")\ndf=df.replace(\"ECC (West)\",\"ECC\")\ndf=df.replace(\"ECC (East)\",\"ECC\")\ndf=df.replace(\"ECBL (East)\",\"ECBL\")\ndf=df.replace(\"ECBL (West)\",\"ECBL\")\ndf=df.replace(\"EAA (West)\",\"EAA\")\ndf=df.replace(\"EAA (East)\",\"EAA\")\ndf=df.replace(\"ECACM (North)\",\"ECACM\")\ndf=df.replace(\"ECACM (South)\",\"ECACM\")\ndf=df.replace(\"A-10 (East)\",\"A-10\")\ndf=df.replace(\"A-10 (West)\",\"A-10\")\ndf=df.replace(\"MAAC (South)\",\"MAAC\")\ndf=df.replace(\"MAAC (North)\",\"MAAC\")\ndf=df.replace(\"CUSA (Blue)\",\"CUSA\")\ndf=df.replace(\"CUSA (Red)\",\"CUSA\")\ndf=df.replace(\"CUSA (White)\",\"CUSA\")\ndf=df.replace(\"Big East (East)\",\"Big East\")\ndf=df.replace(\"MAC (East)\",\"MAC\")\ndf=df.replace(\"SEC (East)\",\"SEC\")\ndf=df.replace(\"Southern (North)\",'Southern')\ndf=df.replace(\"Southern (South)\",\"Southern\")\ndf=df.replace(\"WAC (Pacific)\",\"WAC\")\ndf=df.replace(\"CUSA (National)\",\"CUSA\")\ndf=df.replace(\"TAAC (East)\",\"TAAC\")\ndf=df.replace(\"Sun Belt (West)\",\"Sun Belt\")\ndf=df.replace(\"TAAC (West)\",\"TAAC\")\ndf=df.replace(\"A-Sun (North)\",\"A-Sun\")\ndf=df.replace(\"MAC (West)\",\"MAC\")\ndf=df.replace(\"Big East (West)\",\"Big East\")\ndf=df.replace(\"SEC (West)\",\"SEC\")\ndf=df.replace(\"Southland (West)\",\"Southland\")\ndf=df.replace(\"Southland (East)\",\"Southland\")\ndf=df.replace(\"OVC (East)\",\"OVC\")\ndf=df.replace(\"OVC (West)\",\"OVC\")\ndf=df.replace(\"Big South (North)\",\"Big South\")\ndf=df.replace(\"Big South (South)\",\"Big South\")\ndf=df.replace(\"A-Sun (East)\",\"A-Sun\")\ndf=df.replace(\"Patriot (Central)\",\"Patriot\")\ndf=df.replace(\"WAC (Mountain)\",\"WAC\")\ndf=df.replace(\"CUSA (American)\",\"CUSA\")\ndf=df.replace(\"Big West (West)\",\"Big West\")\ndf=df.replace(\"CUSA (East)\",\"CUSA\")\ndf=df.replace(\"Patriot (North)\",\"Patriot\")\ndf=df.replace(\"CUSA (West)\",\"CUSA\")\ndf=df.replace(\"A-Sun (West)\",\"A-Sun\")\ndf=df.replace(\"Patriot (South)\",\"Patriot\")\ndf=df.replace(\"A-Sun (South)\",\"A-Sun\")\ndf=df.replace(\"MEAC (Southern)\",\"MEAC\")\ndf=df.replace(\"MEAC (Northern)\",\"MEAC\")\ndf=df.replace(\"Sun Belt (East)\",\"Sun Belt\")\ndf=df.replace(\"Big West (West)\",\"Big West\")\ndf=df.replace(\"Big West (East)\",\"Big West\")\ndf=df.replace(\"Big East (Big East 6)\",\"Big East\")\ndf=df.replace(\"Big East (Big East 7)\",\"Big East\")\ndf['conf']=df['conf'].replace(\"American\",\"AAC\")\ndf=df[df.conf.isna()==False]\nstandings=pd.read_csv(\"https://cfbzzz.alwaysdata.net/ncaab/d1vsnond1/teams/d1standings.txt\")\nstandings=standings.replace(\"Florida Gulf Cost\",\"Florida Gulf Coast\")\na=df[df.season==2025]\nfor row in a.itertuples():\n    if float(row.season)>1948:\n        confs[float(row.season)][str(row.team)]=str(row.conf)\ndf=df[df.num.isna()==False]\nfor row in df.itertuples():\n    if float(row.season)>1948:\n        confs[float(row.season)][str(row.team)]=str(row.conf)\nfor row in standings.itertuples():\n    if float(row.Year)>1948:\n        confs[float(row.Year)][str(row.Schl)]=str(row.Conference)\nfrom bs4 import BeautifulSoup, Comment\narr=[]\nconfy={}\nfor row in df.itertuples():\n    if float(row.season)>1948:\n        confy[row.conf]=[]\nkval=20\neloLeague = Elo(k = kval)\nprint(\"go through games\")\nrev=0.70\nsep=\"\"\ndef remove_tags(html):\n\n    # parse html content\n    soup = BeautifulSoup(html, \"html.parser\")\n\n    for data in soup(['style', 'script']):\n        # Remove tags\n        data.decompose()\n\n    # return data by retrieving the tag content\n    return ' '.join(soup.stripped_strings)\nfrom time import sleep\nhfas={}\nconfs[2024][\"Texas A&M-Commerce\"]=\"Southland\"\narr=[]\nyears={}\nyears[2024]=[]\ntoday=datetime.today().strftime('%Y%m%d')\nconfs[2024]['IUPUI']='Horizon'\nconfs[2024]['Texas A&M-Commerce']='Southland'\ndel confs[2024]['East Texas A&M']\ndel confs[2024]['IU Indy']\ngames=[]\nh='g'\narrz=[]\nty={}\nfor i in range(2014,2025):\n    ty[i]=[]\n    for t in confs[i]:\n        ty[i].append(t)\n\nimport requests\nfrom bs4 import BeautifulSoup\nhtml=requests.get(\"https://academics.smcvt.edu/jtrono/BBallArchive.htm\").text\nsoup=BeautifulSoup(html)\nlinks={}\ntable=soup.find_all(\"table\")[0]\nfor tr in table.find_all(\"tr\"):\n    year=tr.find_all(\"td\")[0].text\n    year=str(year).split(\"-\")[0]\n    year=float(year)\n    links[year]=[]\n    link=tr.find_all(\"td\")[1]\n    link=link.find(\"a\")\n    link=link['href']\n    link='https://academics.smcvt.edu/jtrono/'+link\n    links[year].append(link)\n    link=tr.find_all(\"td\")[3]\n    link=link.find(\"a\")\n    link=link['href']\n    link='https://academics.smcvt.edu/jtrono/'+link\n    links[year].append(link)\n    link=tr.find_all(\"td\")[4]\n    link=link.find(\"a\")\n    link=link['href']\n    link='https://academics.smcvt.edu/jtrono/'+link\n    links[year].append(link)\ne=0\nfrom datetime import date as datey\nfrom datetime import timedelta\nfrom bs4 import BeautifulSoup\nimport requests\n# Define the given date\ng={}\ng['date']=0\narrz=[]\nui=0\n\nlinks[1974].append(\"https://academics.smcvt.edu/jtrono/NCAA_Archive/74_75_NCIT.htm\")\nlinks[1973].append(\"https://academics.smcvt.edu/jtrono/NCAA_Archive/73_74_CCA.htm\")\nfor year in links:\n    print(year)\n    for link in links[year]:\n        html=requests.get(link).text\n        soup=BeautifulSoup(html,'html.parser')\n        if float(year)!=1951:\n            soup=str(soup.find(\"p\"))\n        else:\n            soup=str(soup.find(\"body\"))\n        if '<br>' in str(soup):\n            print(\"yes!!!!\")\n            soup=soup.replace(\"<p>\",\"\")\n     \n            soup=soup.replace(\"\\r\",\"\")\n            lines=soup.split(\"<br>\")\n        elif '<br/>' in str(soup):\n            print(\"no!!!!\")\n            soup=soup.replace(\"<p>\",\"\")\n            soup=soup.replace(\"\\r\",\"\")\n            \n            lines=soup.split(\"<br/>\")\n        else:\n            print(\"what!!!!!!\")\n            soup=soup.replace(\"<p>\",\"\")\n            soup=soup.replace('<p class=\"MsoPlainText\">',\"\")\n            soup=soup.replace(\"\\r\", \"\")\n            \n            lines=soup.split(\"</p>\")\n        for line in lines:\n            \n            if len(line)>0 and 'TOURNAMENT' not in str(line) and \"<\" not in str(line):\n                line=line.replace(\"F405\",\"405\")\n                line=line.replace(\"75\\nVIL\",\"75 VIL\")\n                line=line.lstrip()\n                line=line.replace(\"\\xa0\",\"\")\n                line=line.replace(\"f304\",\"304\")\n                line=line.split(\" \")\n                year=str(year)\n                if \"dts\" in str(link) or \"NCIT\" in str(link) or \"CCA\" in str(link):\n                    date=str(line[0])\n                    date=date.replace(\"\\n\",\"\")\n                    year=year.replace(\".0\",\"\")\n                    if float(date[0])==2:\n                        date=year+str(11)+str(line[0])[1]+str(line[0])[2]\n                    if float(date[0])==3:\n                        date=year+str(12)+str(line[0])[1]+str(line[0])[2]\n                    if float(date[0])==4:\n                        date=str(int(year)+1)+str(\"01\")+str(line[0])[1]+str(line[0])[2]\n                    if float(date[0])==5:\n                        date=str(int(year)+1)+str(\"02\")+str(line[0])[1]+str(line[0])[2]\n                    if float(date[0])==6:\n                        date=str(int(year)+1)+str(\"03\")+str(line[0])[1]+str(line[0])[2]\n                    if float(year)==1951:\n                        if ui<10:\n                            ui+=1\n                            print(line)\n                    arrz.append([date,line[1],line[2],line[3],line[4],line[5],float(year),\"no\"])\n                    g['date']=date\n                \n                else:\n                    lk=g['date']\n                    \n                    given_date = datey(int(lk[:4]),int(lk[4]+lk[5]),int(lk[6]+lk[7]))\n                    lk=given_date+timedelta(days=1)\n                    lk=str(lk)\n                    lk=lk.replace(\"-\",\"\")\n                    g['date']=lk\n                    thing=\"\"\n                    if \"ncaa\" in str(link):\n                        thing='ncaa'\n                    if 'nit' in str(link):\n                        thing='nit'\n                    arrz.append([lk,line[0],line[1],line[2],line[3],line[4],float(year),thing])\n                \n                \narrz.append([19620308,'REG',75,'STB',76,'N',1962,\"\"])\narrz.append([19620308,'XAV',80,'CRE',67,'N',1962,\"\"])\narrz.append([19620309,'REG',61,'CRE',76,'N',1962,\"\"])\narrz.append([19620309,'XAV',89,'STB',75,'N',1962,\"\"])\narrz.append([19500327,\"WYO\",78,\"DUQ\",61,\"N\",1950,\"no\"])\narrz.append([19500327,\"BRA\",75,\"WKE\",71,\"H\",1950,\"no\"])\narrz.append([19500328,\"UTA\",67,\"VIL\",65,\"N\",1950,\"no\"])\narrz.append([19500328,\"SYR\",69,\"TOL\",52,\"N\",1950,\"no\"])\narrz.append([19500330,\"BRA\",77,\"WYO\",63,\"H\",1950,\"no\"])\narrz.append([19500330,\"SYR\",74,\"UTA\",57,\"N\",1950,\"no\"])\narrz.append([19500331,\"SYR\",76,\"BRA\",75,\"A\",1950,\"no\"])\narrz.append([19500331,\"UTA\",55,\"WYO\",52,\"N\",1950,\"no\"])\nhtml=requests.get(\"https://academics.smcvt.edu/jtrono/NCAA_Archive/Translation.htm\").text\nsoup=BeautifulSoup(html)\nsoup=soup.find(\"p\").text\nsoup=str(soup).replace(\"\\r\",\"\")\ntz={}\nfor line in soup.split(\"\\n\"):\n    \n    line=line.split(\" \")\n    tz[line[0]]=line[1]\nimport pandas as pd\ndf=pd.DataFrame(arrz,columns=['date','t1','t1p','t2','t2p','venue','season','fake'])\ndf=df.astype({\"t1\":\"string\",\"t2\":\"string\"})\ndf['t1']=df['t1'].str.replace(\"&amp;\",\"&\")\ndf['t2']=df['t2'].str.replace(\"&amp;\",\"&\")\ndf['t1']=df['t1'].str.replace(\"\\n\",\"\")\ndf['t2']=df['t2'].str.replace(\"\\n\",\"\")\nfor t in tz:\n    print(t)\n    df=df.replace(t,tz[t])\nfor row in df.itertuples():\n    if \"St\"==str(row.t1)[-2]+str(row.t1)[-1]:\n        df.at[row.Index,'t1']=str(row.t1).replace(\"St\",\" State\")\n    if \"St\"==str(row.t2)[-2]+str(row.t2)[-1]:\n        df.at[row.Index,'t2']=str(row.t2).replace(\"St\",\" State\")\n    if \"A&M\"==str(row.t1)[-3]+str(row.t1)[-2]+str(row.t1)[-1]:\n        df.at[row.Index,'t1']=str(row.t1).replace(\"A&M\",\" A&M\")\n    if \"A&M\"==str(row.t2)[-3]+str(row.t2)[-2]+str(row.t2)[-1]:\n        df.at[row.Index,'t2']=str(row.t2).replace(\"A&M\",\" A&M\")\ndf=df.astype({\"t1\":\"string\",\"t2\":\"string\"})\ndf=df.replace(\"AirForce\",\"Air Force\")\ndf=df.replace(\"AlcornSt\",\"Alcorn State\")\ndf=df.replace(\"AmericanUniv\",\"American\")\ndf=df.replace(\"AbileneChristian\",\"Abilene Christian\")\ndf=df.replace(\"AlbanyNY\",\"Albany\")\ndf=df.replace(\"ArkPineBluff\",\"Arkansas-Pine Bluff\")\ndf=df.replace(\"ArkLittleRock\",\"Little Rock\")\ndf=df.replace(\"BostonCollege\",\"Boston College\")\ndf=df.replace(\"AustinPeay\",\"Austin Peay\")\ndf=df.replace(\"BowlingGreen\",\"Bowling Green\")\ndf=df.replace(\"BostonUniv\",\"Boston University\")\ndf=df.replace(\"CSSacramento\",\"Sacramento State\")\ndf=df.replace(\"CSNorthridge\",\"Cal State Northridge\")\ndf=df.replace(\"CityCollegeNewYork\",\"City College of New York\")\ndf=df.replace(\"CharlestonSo\",\"Charleston Southern\")\ndf=df.replace(\"CoastalCar\",\"Coastal Carolina\")\ndf=df.replace(\"CalStateLosAngeles\",\"Cal State Los Angeles\")\ndf=df.replace(\"CSFullerton\",\"Cal State Fullerton\")\ndf=df.replace(\"ColCharleston\",\"College of Charleston\")\ndf=df.replace(\"CalPolySLO\",\"Cal Poly\")\ndf=df.replace(\"CMichigan\",\"Central Michigan\")\ndf=df.replace(\"CentralConn\",\"Central Connecticut State\")\ndf=df.replace(\"Detroit\",\"Detroit Mercy\")\ndf=df.replace(\"EWashington\",\"Eastern Washington\")\ndf=df.replace(\"EKentucky\",\"Eastern Kentucky\")\ndf=df.replace(\"EMichigan\",\"Eastern Michigan\")\ndf=df.replace(\"EIllinois\",\"Eastern Illinois\")\ndf=df.replace(\"EastCarolina\",\"East Carolina\")\ndf=df.replace(\"ETennessee State\",\"East Tennessee State\")\ndf=df.replace(\"FLAtlantic\",\"Florida Atlantic\")\ndf=df.replace(\"FloridaIntl\",\"Florida International\")\ndf=df.replace(\"TexasTech\",\"Texas Tech\")\ndf=df.replace(\"OldDominion\",\"Old Dominion\")\ndf=df.replace(\"JamesMadison\",\"James Madison\")\ndf=df.replace(\"GeorgeMason\",\"George Mason\")\ndf=df.replace(\"GeorgiaTech\",\"Georgia Tech\")\ndf=df.replace(\"GaSouthern\",\"Georgia Southern\")\ndf=df.replace(\"GWashington\",\"George Washington\")\ndf=df.replace(\"FDickinson\",\"FDU\")\ndf=df.replace(\"HolyCross\",\"Holy Cross\")\ndf=df.replace(\"HighPoint\",\"High Point\")\ndf=df.replace(\"HoustonBaptist\",\"Houston Christian\")\ndf=df.replace(\"ILChicago\",\"Illinois-Chicago\")\ndf=df.replace(\"JohnCarroll\",\"John Carroll\")\ndf=df.replace(\"Kent\",\"Kent State\")\ndf=df.replace(\"LALafayette\",\"Louisiana\")\ndf=df.replace(\"LongIsland\",\"Long Island University\")\ndf=df.replace(\"LoyolaNewOrleans\",\"Loyola (LA)\")\ndf=df.replace(\"LoyMarymount\",\"Loyola Marymount\")\ndf=df.replace(\"LaSalle\",\"La Salle\")\ndf=df.replace(\"LouisianaTech\",\"Louisiana Tech\")\ndf=df.replace(\"LoyolaMD\",\"Loyola (MD)\")\ndf=df.replace(\"Loyola-Chicago\",\"Loyola (IL)\")\ndf=df.replace(\"LAMonroe\",\"Louisiana-Monroe\")\ndf=df.replace(\"MissouriKC\",\"Kansas City\")\ndf=df.replace(\"MonmouthNJ\",\"Monmouth\")\ndf=df.replace(\"LongBeach State\",\"Long Beach State\")\ndf=df.replace(\"MtStMary's\",\"Mount St. Mary's\")\ndf=df.replace(\"MiamiFL\",\"Miami (FL)\")\ndf=df.replace(\"MiamiOH\",\"Miami (OH)\")\ndf=df.replace(\"NewHampshire\",\"New Hampshire\")\ndf=df.replace(\"MDBaltimoreCo\",\"Maryland-Baltimore County\")\ndf=df.replace(\"MSValley State\",\"Mississippi Valley State\")\ndf=df.replace(\"TexasSouthern\",\"Texas Southern\")\ndf=df.replace(\"MDEShore\",\"Maryland-Eastern Shore\")\ndf=df.replace(\"MiddleTenn State\",\"Middle Tennessee\")\ndf=df.replace(\"NorthTexas\",\"North Texas\")\ndf=df.replace(\"NorthwesternLA\",\"Northwestern State\")\ndf=df.replace(\"NorthernIowa\",\"Northern Iowa\")\ndf=df.replace(\"SanJose State\",\"San Jose State\")\ndf=df.replace(\"NCState\",\"NC State\")\ndf=df.replace(\"OklahomaCity\",\"Oklahoma City\")\ndf=df.replace(\"OralRoberts\",\"Oral Roberts\")\ndf=df.replace(\"WKentucky\",\"Western Kentucky\")\ndf=df.replace(\"SIllinois\",\"Southern Illinois\")\ndf=df.replace(\"SanDiego State\",\"San Diego State\")\ndf=df.replace(\"SanDiego\",\"San Diego\")\ndf=df.replace(\"NewMexico State\",\"New Mexico State\")\ndf=df.replace(\"NewMexico\",\"New Mexico\")\ndf=df.replace(\"NewYorkUniv\",\"New York University\")\ndf=df.replace(\"NewOrleans\",\"New Orleans\")\ndf=df.replace(\"NorthCarolina\",\"North Carolina\")\ndf=df.replace(\"NCA&T\",\"North Carolina A&T\")\ndf=df.replace(\"NArizona\",\"Northern Arizona\")\ndf=df.replace(\"WMichigan\",\"Western Michigan\")\ndf=df.replace(\"NortheastIllinois\",\"Northeastern Illinois\")\ndf=df.replace(\"WIllinois\",\"Western Illinois\")\ndf=df.replace(\"NIllinois\",\"Northern Illinois\")\ndf=df.replace(\"NorthernColorado\",\"Northern Colorado\")\ndf=df.replace(\"NortheastLouisiana\",\"Louisiana-Monroe\")\ndf=df.replace(\"Penn\",\"Pennsylvania\")\ndf=df.replace(\"PrairieView\",\"Prairie View\")\ndf=df.replace(\"Regis\",\"Regis (CO)\")\ndf=df.replace(\"RhodeIsland\",\"Rhode Island\")\ndf=df.replace(\"RobertMorris\",\"Robert Morris\")\ndf=df.replace(\"SantaClara\",\"Santa Clara\")\ndf=df.replace(\"SouthernMiss\",\"Southern Mississippi\")\ndf=df.replace(\"SouthCarolina\",\"South Carolina\")\ndf=df.replace(\"SCarolina State\",\"South Carolina State\")\ndf=df.replace(\"SELouisiana\",\"Southeastern Louisiana\")\ndf=df.replace(\"SMU\",\"Southern Methodist\")\ndf=df.replace(\"StLouis\",\"Saint Louis\")\ndf=df.replace(\"StonyBrook\",\"Stony Brook\")\ndf=df.replace(\"SFAustin\",\"Stephen F. Austin\")\ndf=df.replace(\"StBonaventure\",\"St. Bonaventure\")\ndf=df.replace(\"SAlabama\",\"South Alabama\")\ndf=df.replace(\"StJoseph'sPA\",\"Saint Joseph's\")\ndf=df.replace(\"StMary's\",\"Saint Mary's (CA)\")\ndf=df.replace(\"SamHouston State\",\"Sam Houston\")\ndf=df.replace(\"SanFrancisco\",\"San Francisco\")\ndf=df.replace(\"SacredHt\",\"Sacred Heart\")\ndf=df.replace(\"StFrancisPA\",\"Saint Francis (PA)\")\ndf=df.replace(\"StJohn's\",\"St. John's (NY)\")\ndf=df.replace(\"StPeter's\",\"Saint Peter's\")\ndf=df.replace(\"StFrancisNY\",\"St. Francis (NY)\")\ndf=df.replace(\"SantaBarbara\",\"UC Santa Barbara\")\ndf=df.replace(\"SEMissouri State\",\"Southeast Missouri State\")\ndf=df.replace(\"SouthernUtah\",\"Southern Utah\")\ndf=df.replace(\"SouthFlorida\",\"South Florida\")\ndf=df.replace(\"SetonHall\",\"Seton Hall\")\ndf=df.replace(\"SouthernUniv\",\"Southern\")\ndf=df.replace(\"SouthwestLouisiana\",\"Louisiana\")\ndf=df.replace(\"TXArlington\",\"UT Arlington\")\ndf=df.replace(\"TennesseeTech\",\"Tennessee Tech\")\ndf=df.replace(\"TXPanAmerican\",\"Texas-Rio Grande Valley\")\ndf=df.replace(\"TXSouthern\",\"Texas Southern\")\ndf=df.replace(\"TNMartin\",\"Tennessee-Martin\")\ndf=df.replace(\"Trinity(Texas)\",\"Trinity (TX)\")\ndf=df.replace(\"TXSanAntonio\",\"UTSA\")\ndf=df.replace(\"TAMC.Christi\",\"Texas A&M-Corpus Christi\")\ndf=df.replace(\"UCIrvine\",\"UC Irvine\")\ndf=df.replace(\"UNCWilmington\",\"UNC Wilmington\")\ndf=df.replace(\"UNCGreensboro\",\"UNC Greensboro\")\ndf=df.replace(\"UNLV\",\"Nevada-Las Vegas\")\ndf=df.replace('USInternational',\"U.S. International\")\ndf=df.replace(\"UNCAsheville\",\"UNC Asheville\")\ndf=df.replace(\"USC\",\"Southern California\")\ndf=df.replace(\"VirginiaTech\",\"Virginia Tech\")\ndf=df.replace(\"VACommonwealth\",\"Virginia Commonwealth\")\ndf=df.replace(\"VMI\",\"Virginia Military Institute\")\ndf=df.replace(\"WestChester State\",\"West Chester\")\ndf=df.replace(\"WestTexas State\",\"West Texas A&M\")\ndf=df.replace(\"Washington(StLouis)\",\"Washington (MO)\")\ndf=df.replace(\"WIGreenBay\",\"Green Bay\")\ndf=df.replace(\"WakeForest\",\"Wake Forest\")\ndf=df.replace(\"William&Mary\",\"William & Mary\")\ndf=df.replace(\"WIMilwaukee\",\"Milwaukee\")\ndf=df.replace(\"WestVirginia\",\"West Virginia\")\ndf=df.replace(\"Washington&Lee\",\"Washington & Lee\")\ndf=df.replace(\"WCarolina\",\"Western Carolina\")\ndfz=df\ndf=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/masseyz.csv\")\ndfz=dfz.replace(\"CaseWesternReserve\",\"Case Western Reserve\")\ndfz=dfz.replace(\"Albany\",\"Albany (NY)\")\ndfz=dfz[dfz.season!=1998]\ndfz=dfz[dfz.season!=1999]\ndfz=dfz[dfz.season!=2000]\narr=[]\nery=df\nfor row in df.itertuples():\n    n=False\n    if 'vs' in str(row.venue):\n        n=True\n    if float(row.season)<2014:\n        arr.append([row.date,row.t1,row.t2,row.t1p,row.t2p,row.venue,row.season,n,False])\n    else:\n        arr.append([row.date,row.t1,row.t2,row.t1p,row.t2p,row.venue,row.season,n,True])\nfor row in dfz.itertuples():\n    n=False\n    if 'N' in str(row.venue):\n        n=True\n    arr.append([row.date,row.t1,row.t2,row.t1p,row.t2p,row.venue,row.season,n,False])\nh='g'\ndf=pd.read_csv(\"https://cfbzzz.alwaysdata.net/ncaaf/espnz.txt\")\nqw=[]\ndef scores(date,season):\n    print(date)\n    date=str(date)\n    url=\"https://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=\"+date+\"&groups=50&limit=360\"\n    html=requests.get(url)\n    print(url)\n    html=html.json()\n    leagues=html['events']\n    y=200\n    print(len(leagues))\n    for game in leagues:\n        \n        h=game\n        if 'competitions' in str(game):\n            t1=game['competitions'][0]['competitors'][0]['team']['shortDisplayName']\n            t2=game['competitions'][0]['competitors'][1]['team']['shortDisplayName']\n            neutral=game['competitions'][0]['neutralSite']\n            att=game['competitions'][0]['attendance']\n            time=game['competitions'][0]['date']\n            t1s=game['competitions'][0]['competitors'][0]['score']\n            t2s=game['competitions'][0]['competitors'][1]['score']\n            neutral=str(neutral)\n            location='?'\n            stime=game['competitions'][0]['startDate']\n            if 'address'  in str(game['competitions'][0]):\n                if 'state' in str(game['competitions'][0]['venue']['address']):\n\n\n                    location=game['competitions'][0]['venue']['address']['city']+\", \"+game['competitions'][0]['venue']['address']['state']\n                    venue=game['competitions'][0]['venue']['fullName']\n                else:\n                    location=game['competitions'][0]['venue']['address']['city']\n                    venue=game['competitions'][0]['venue']['fullName']\n            else:\n                venue='?'\n            location=location.replace('\"',\"\")\n            location=location.replace(',',\"\")\n            if \"True\" in str(neutral):\n                notes=\"@\"+location\n            else:\n                notes=\"\"\n            name=str(date)+t1\n            namez=str(date)+t2\n            if name not in games and namez not in games:\n                if float(t1s)==0 and float(t2s)==0:\n                    m=1\n                else:\n                    qw.append([date,t1,t2,\"vs\",t1s,t2s,season,str(location),str(neutral),notes,venue])\nfrom datetime import date\ntoday=date.today()\ntoday=str(today)\nfor date in pd.date_range(start=\"2025-11-03\",end=today):\n    date=str(date)\n    date=date.replace(\" 00:00:00\",\"\")\n    date=date.replace(\"-\",\"\")\n    date=date.replace(\".0\",\"\")\n    scores(date,2025)\nert=[]\nfor gh in qw:\n    ert.append(gh)\nfor row in df.itertuples():\n    ert.append([row.date,row.t1,row.t2,row.venue,row.t1p,row.t2p,row.season,row.city,row.neutral,row.notes,row.stadium])\ndf=pd.DataFrame(ert,columns=['date','t1','t2','venue','t1p','t2p','season','city','neutral','notes','stadium'])\ndf=df.replace(\"Abilene Chrstn\",\"Abilene Christian\")\ndf=df.replace(\"Bethune\",\"Bethune-Cookman\")\ndf=df.replace(\"NC Central\",\"North Carolina Central\")\ndf=df.replace(\"Charleston\",\"College of Charleston\")\ndf=df.replace(\"Central Florida\",\"UCF\")\ndf=df.replace(\"G Washington\",\"George Washington\")\ndf=df.replace(\"Hawai’i\",\"Hawaii\")\ndf=df.replace(\"MTSU\",\"Middle Tennessee\")\ndf=df.replace(\"CSU Northridge\",\"Cal State Northridge\")\ndf=df.replace(\"Loyola MD\",\"Loyola (MD)\")\ndf=df.replace(\"Hawai'i\",\"Hawaii\")\ndf=df.replace(\"Saint Mary's\",\"Saint Mary's (CA)\")\ndf=df.replace(\"Pitt\",\"Pittsburgh\")\ndf=df.replace(\"UAlbany\",\"Albany (NY)\")\ndf=df.replace(\"UIC\",\"Illinois-Chicago\")\ndf=df.replace(\"UT Martin\",\"Tennessee-Martin\")\ndf=df.replace(\"Texas A&M-CC\",\"Texas A&M-Corpus Christi\")\ndf=df.replace(\"San José State\",\"San Jose State\")\ndf=df.replace(\"San Diego St\",\"San Diego State\")\ndf=df.replace(\"TX A&M-CC\",\"Texas A&M-Corpus Christi\")\ndf=df.replace(\"NC State\",\"NC State\")\ndf=df.replace(\"Western KY\",\"Western Kentucky\")\ndf=df.replace(\"SE Louisiana\",\"Southeastern Louisiana\")\ndf=df.replace(\"SE Missouri\",\"Southeast Missouri State\")\ndf=df.replace(\"MD Eastern\",\"Maryland-Eastern Shore\")\ndf=df.replace(\"UMass\",\"Massachusetts\")\ndf=df.replace(\"SMU\",\"Southern Methodist\")\ndf=df.replace(\"SC State\",\"South Carolina State\")\ndf=df.replace(\"Boston U\",\"Boston University\")\ndf=df.replace(\"MD E Shore\",\"Maryland-Eastern Shore\")\ndf=df.replace(\"C Michigan\",\"Central Michigan\")\ndf=df.replace(\"LSU\",\"Louisiana State\")\ndf=df.replace(\"App State\",\"Appalachian State\")\ndf=df.replace(\"AR-Pine Bluff\",\"Arkansas-Pine Bluff\")\ndf=df.replace(\"N Illinois\",\"Northern Illinois\") \ndf=df.replace(\"W Illinois\",\"Western Illinois\")\ndf=df.replace(\"E Illinois\",\"Eastern Illinois\")\ndf=df.replace(\"C Connecticut\",\"Central Connecticut State\")\ndf=df.replace(\"Coastal Car\",\"Coastal Carolina\")\ndf=df.replace(\"G Washington\",\"George Washington\")\ndf=df.replace(\"GA Southern\",\"Georgia Southern\")\ndf=df.replace(\"FIU\",\"Florida International\")\ndf=df.replace(\"FAU\",\"Florida Atlantic\")\ndf=df.replace(\"E Michigan\",\"Eastern Michigan\")\ndf=df.replace(\"W Michigan\",\"Western Michigan\")\ndf=df.replace(\"Charleston So\",\"Charleston Southern\")\ndf=df.replace(\"CSU Northridge\",\"Cal State Northridge\")\ndf=df.replace(\"UMBC\",\"Maryland-Baltimore County\")\ndf=df.replace(\"N'Western State\",'Northwestern State')\ndf=df.replace(\"NC A&T\",\"North Carolina A&T\")\ndf=df.replace(\"Nicholls\",\"Nicholls State\")\ndf=df.replace(\"McNeese\",\"McNeese State\")\ndf=df.replace(\"E Washington\",\"Eastern Washington\")\ndf=df.replace(\"E Kentucky\",\"Eastern Kentucky\")\ndf=df.replace(\"ETSU\",\"East Tennessee State\")\ndf=df.replace(\"Southern Miss\",\"Southern Mississippi\")\ndf=df.replace(\"St Francis PA\",\"Saint Francis (PA)\")\ndf=df.replace(\"St Francis BK\",\"St. Francis (NY)\")\ndf=df.replace(\"N Illinois\",\"Northern Illinois\")\ndf=df.replace(\"Brooklyn NY\",\"New York NY\")\ndf=df.replace(\"Manhattan NY\",\"New York NY\")\ndf=df.replace(\"Staten Island NY\",\"New York NY\")\ndf=df.replace(\"VMI\",\"Virginia Military Institute\")\ndf=df.replace(\"UL Monroe\",\"Louisiana-Monroe\")\ndf=df.replace(\"W Carolina\",\"Western Carolina\")\ndf=df.replace(\"Utah Stateate\",\"Utah State\")\ndf=df.replace(\"VCU\",\"Virginia Commonwealth\")\ndf=df.replace(\"UConn\",\"Connecticut\")\ndf=df.replace(\"N Arizona\",\"Northern Arizona\")\ndf=df.replace(\"Hou Christian\",\"Houston Christian\")\ndf=df.replace(\"IU Indy\",\"IUPUI\")\ndf=df.replace('Illinois St',\"Illinois State\")\ndf=df.replace(\"Florida St\",\"Florida State\")\ndf=df.replace(\"Texas St\",\"Texas State\")\ndf=df.replace(\"Indiana St\",\"Indiana State\")\ndf=df.replace(\"Michigan St\",\"Michigan State\")\ndf=df.replace(\"Iowa St\",\"Iowa State\")\ndf=df.replace(\"Alabama St\",\"Alabama State\")\ndf=df.replace(\"Alcorn St\",\"Alcorn State\")\ndf=df.replace(\"Jackson St\",\"Jackson State\")\ndf=df.replace(\"Greenwood MS\",\"Itta Benna MS\")\ndf=df.replace(\"Georgia St\",\"Georgia State\")\ndf=df.replace(\"Oregon St\",\"Oregon State\")\ndf=df.replace(\"Arizona St\",\"Arizona State\")\ndf=df.replace(\"Washington St\",\"Washington State\")\ndf=df.replace(\"Penn\",\"Pennsylvania\")\ndf=df.replace(\"Arkansas St\",\"Arkansas State\")\ndf=df.replace(\"Jax State\",\"Jacksonville State\")\ndf=df.replace(\"Long Island\",\"Long Island University\")\ndf=df.replace(\"N Kentucky\",\"Northern Kentucky\")\ndf=df.replace(\"Liu Brooklyn\",\"Long Island University\")\ndf=df.replace(\"Utah St\",\"Utah State\")\ndf=df.replace(\"New Mexico St\",\"New Mexico State\")\ndf=df.replace(\"Kansas St\",\"Kansas State\")\ndf=df.replace(\"Missouri St\",\"Missouri State\")\ndf=df.replace(\"Idaho St\",\"Idaho State\")\ndf=df.replace(\"Montana St\",\"Montana State\")\ndf=df.replace(\"Oklahoma St\",\"Oklahoma State\")\ndf=df.replace(\"Murray St\",\"Murray State\")\ndf=df.replace(\"Mississippi St\",\"Mississippi State\")\ndf=df.replace(\"Penn St\",\"Penn State\")\ndf=df.replace(\"Portland St\",\"Portland State\")\ndf=df.replace(\"LMU\",\"Loyola Marymount\")\ndf=df.replace(\"Long Beach St\",\"Long Beach State\")\ndf=df.replace(\"Loyola Chicago\",\"Loyola (IL)\")\ndf=df.replace(\"N Dakota St\",\"North Dakota State\")\ndf=df.replace(\"Loyola MD\",\"Loyola (MD)\")\ndf=df.replace(\"Queens NY\",\"New York NY\")\ndf=df.replace(\"Norfolk St\",\"Norfolk State\")\ndf=df.replace(\"Purdue FW\",\"Purdue Fort Wayne\")\ndf=df.replace(\"N Colorado\",\"Northern Colorado\")\ndf=df.replace(\"St John's\",\"St. John's (NY)\")\ndf=df.replace(\"Queens\",\"Queens (NC)\")\ndf=df.replace(\"S Dakota St\",\"South Dakota State\")\ndf=df.replace(\"Santa Barbara\",\"UC Santa Barbara\")\ndf=df.replace(\"SFA\",\"Stephen F. Austin\")\ndf=df.replace(\"San José St\",\"San Jose State\")\ndf=df.replace(\"SC Upstate\",\"South Carolina Upstate\")\ndf=df.replace(\"St Bonaventure\",\"St. Bonaventure\")\ndf=df.replace(\"SIUE\",\"Southern Illinois-Edwardsville\")\ndf=df.replace(\"Seattle U\",\"Seattle\")\ndf=df.replace(\"San Diego St\",\"San Diego State\")\ndf=df.replace(\"Saint Francis\",\"Saint Francis (PA)\")\ndf=df.replace(\"Sacramento St\",\"Sacramento State\")\ndf=df.replace(\"UMass Lowell\",\"Massachusetts-Lowell\")\ndf=df.replace(\"So Indiana\",\"Southern Indiana\")\ndf=df.replace(\"St Thomas (MN)\",\"St. Thomas\")\ndf=df.replace(\"Savannah St\",\"Savannah State\")\ndf=df.replace(\"S Illinois\",\"Southern Illinois\")\ndf=df.replace(\"SC Upstate\",\"South Carolina Upstate\")\ndf=df.replace(\"SF Austin\",\"Stephen F. Austin\")\ndf=df.replace(\"UT Rio Grande\",\"Texas-Rio Grande Valley\")\ndf=df.replace(\"UNLV\",\"Nevada-Las Vegas\")\ndf=df.replace(\"USC\",\"Southern California\")\ndf=df.replace(\"Wichita St\",\"Wichita State\")\ndf=df.replace(\"Wright St\",\"Wright State\")\ndf=df.replace(\"Weber St\",\"Weber State\")\ndf=df.replace(\"Cleveland St\",\"Cleveland State\")\ndf=df.replace(\"Youngstown St\",\"Youngstown State\")\ndf=df.replace('Bakersfield',\"Cal State Bakersfield\")\ndf=df.replace(\"Fresno St\",\"Fresno State\")\ndf=df.replace(\"Boise St\",'Boise State')\ndf=df.replace(\"CA Baptist\",\"California Baptist\")\ndf=df.replace(\"Coastal\",\"Coastal Carolina\")\ndf=df.replace(\"Coppin St\",\"Coppin State\")\ndf=df.replace(\"Chicago St\",\"Chicago State\")\ndf=df.replace(\"C Arkansas\",\"Central Arkansas\")\ndf=df.replace(\"Delaware St\",\"Delaware State\")\ndf=df.replace(\"E Texas A&M\",\"Texas A&M-Commerce\")\ndf=df.replace(\"Fullerton\",\"Cal State Fullerton\")\ndf=df.replace(\"FGCU\",\"Florida Gulf Coast\")\ndf=df.replace(\"Kennesaw St\",\"Kennesaw State\")\ndf=df.replace(\"Miss Valley St\",\"Mississippi Valley State\")\ndf=df.replace(\"Morehead St\",\"Morehead State\")\ndf=df.replace(\"Miami\",\"Miami (FL)\")\ndf=df.replace(\"Miami OH\",\"Miami (OH)\")\ndf=df.replace(\"Mount St Marys\",\"Mount St. Mary's\")\ndf=df.replace(\"Morgan St\",\"Morgan State\")\ndf=df.replace(\"Ole Miss\",\"Mississippi\")\ndf=df.replace(\"Tarleton St\",\"Tarleton State\")\ndf=df.replace(\"N'Western St\",\"Northwestern State\")\ndf=df.replace(\"Tennessee St\",\"Tennessee State\")\ndf=df.replace(\"Colorado St\",\"Colorado State\")\ndf=df.replace(\"Cambridge MA\",\"Boston MA\")\ndf=df.replace(\"Riverdale NY\",\"Manhattan NY\")\nfor row in df.itertuples():\n    if 'RAC Arena' in str(row):\n        df.at[row.Index,'city']='Catonsville MD'\nfor row in df.itertuples():\n    if 'Ocean Bank Convocation Center' in str(row):\n        df.at[row.Index,'city']='University Park FL'\nfor row in df.itertuples():\n    if 'Barry University Health & Sports Center' in str(row):\n        df.at[row.Index,'city']='University Park FL'\ndf=df.replace(\"Manhattan NY\",\"New York NY\")\nteamz={}\nfor row in df.itertuples():\n    if 'False' in str(row.neutral):\n        if row.t1 not in teamz:\n            teamz[row.t1]=[]\n        if row.city not in str(teamz[row.t1]):\n            teamz[row.t1].append([row.city,row.stadium])\nfor t in teamz:\n    if t[0]=='Y':\n        print(t,teamz[t])\ny=pd.read_csv(\"https://cfbzzz.alwaysdata.net/ncaaf/nicknamez.txt\")\nteams={}\nfor row in y.itertuples():\n    er=str(row.City)\n    er=er.replace(\",\",\"\")\n    teams[row.School]=er\nteams['Birm-Southern']='Birmingham, AL'\nteams['Morris Brown']='Atlanta GA'\nteams['Temple']='Philadelphia PA'\nteams['Savannah State']='Savannah GA'\nteams['Centenary (LA)']=\"Shreveport LA\"\nteams['Seton Hall']=\"South Orange NJ\"\nteams['Western Kentucky']='Bowling Green KY'\nteams['Maryland-Baltimore County']='Catonsville MD'\nteams['Villanova']='Villanova PA'\ny=y.replace(\"Washington D.C.\",\"Washington DC\")\ny=y.replace(\"Vestal NY\",\"Binghamton NY\")\ny=y.replace(\"State College PA\",\"University Park PA\")\ny=y.replace(\"Allston MA\",\"Cambridge MA\")\ny=y.replace(\"St. Charles MO\",\"Saint Charles MO\")\ny=y.replace(\"Brooklyn NY\",\"New York NY\")\ny=y.replace(\"Queens NY\",\"New York NY\")\ny=y.replace(\"Lewiston NY\",\"Niagara Falls NY\")\nteams['NC State']='Raleigh NC'\nteams['UC Santa Barbara']='Santa Barbara CA'\nteams['UC San Diego']='San Diego CA'\nteams['Northern Illinois']='Dekalb IL'\nteams['Mississippi State']='Starkville MS'\nteams['Wright State']='Fairborn OH'\nteams['Wagner']='New York NY'\nteams['Manhattan']='New York NY'\nteams['Georgetown']=\"Washington DC\"\nteams['American']='Washington DC'\nteams['Howard']='Washington DC'\nteams['George Washington']='Washington DC'\nteams['Harvard']='Cambridge MA'\nteams['Binghamton']='Binghamton NY'\nteams['Long Island University']='New York NY'\nteams['Mississippi']='Oxford MS'\nteams[\"St. John's (NY)\"]='New York NY'\nteams['St. Francis (NY)']='New York NY'\nteams['St. Bonaventure']='Saint Bonaventure NY'\nteams['Lindenwood']='Saint Charles MO'\nteams['Penn State']='University Park PA'\nteams['Villanova']='Villanova PA'\nteams['Savannah State']='Savannah GA'\nteams['Centenary (LA)']='Shreveport LA'\nteams['Seton Hall']='South Orange NJ'\nteams['Western Kentucky']='Bowling Green KY'\nteams['Maryland-Baltimore County']='Catonsville MD'\nteams['Niagara']='Niagara Falls NY'\nteams['St. Bonaventure']='Saint Bonaventure NY'\ndf=df.astype({\"city\":\"string\"})\nfor row in df.itertuples():\n    if 'Nutter Center' in str(row.stadium):\n        df.at[row.Index,'city']='Fairborn OH'\nfor row in df.itertuples():\n    df.at[row.Index,'t1']=str(row.t1).rstrip()\n    df.at[row.Index,'t2']=str(row.t2).rstrip()\nsi=[]\nfor row in df.itertuples():\n    if 'False' in str(row.neutral):\n        if float(row.season) not in si:\n            print(float(row.season))\n            si.append(float(row.season))\n        t1c=''\n        t2c=''\n        if row.t1 in teams:\n            t1c=teams[row.t1]\n        if row.t2 in teams:\n            t2c=teams[row.t2]\n        if t1c==t2c:\n            df.at[row.Index,'neutral']=True\n            df.at[row.Index,'venue']='vs'\n        if t1c!=t2c:\n            if t1c==row.city:\n                df.at[row.Index,'neutral']=False\n                df.at[row.Index,'venue']='vs'\n            if t2c==row.city:\n                df.at[row.Index,'neutral']=False\n                df.at[row.Index,'venue']='@'     \nfor row in df.itertuples():\n    if row.t1=='South Carolina Upstate' and row.t2=='Wofford' and row.venue=='vs':\n        df.at[row.Index,'venue']='@'\n        df.at[row.Index,'neutral']='False'\n    if row.t1=='South Carolina Upstate' and row.t2=='Wofford' and row.venue=='@':\n        df.at[row.Index,'neutral']='False'\n    if row.t2=='South Carolina Upstate' and row.t1=='Wofford' and row.venue=='vs':\n        df.at[row.Index,'neutral']='False'\n    if row.t2=='South Carolina Upstate' and row.t1=='Wofford' and row.venue=='@':\n        df.at[row.Index,'neutral']='False'\n        df.at[row.Index,'neutral']='vs'\nfor row in df.itertuples():\n    if 'Koessler Center' in str(row):\n        if row.t1=='Canisius' and row.t2=='Buffalo':\n            df.at[row.Index,'neutral']=True\n        if row.t2=='Canisius' and row.t1=='Buffalo':\n            df.at[row.Index,'neutral']=True\nfor row in df.itertuples():\n    if 'False' in str(row.neutral):\n        if row.season<1982:\n            if row.venue=='vs' and row.t1=='Buffalo' and row.t2=='Canisius':\n                df.at[row.Index,'neutral']=True\n            if row.venue=='@' and row.t1=='Buffalo' and row.t2=='Canisius':\n                df.at[row.Index,'neutral']=True\n            if row.venue=='vs' and row.t2=='Buffalo' and row.t1=='Canisius':\n                df.at[row.Index,'neutral']=True\n            if row.venue=='@' and row.t2=='Buffalo' and row.t1=='Canisius':\n                df.at[row.Index,'neutral']=True\n        elif row.season<2014:\n            if row.venue=='@' and row.t1=='Buffalo' and row.t2=='Canisius':\n                df.at[row.Index,'neutral']=True\n            if row.venue=='vs' and row.t1=='Canisius' and row.t2=='Buffalo':\n                df.at[row.Index,'neutral']=True\n                \nfor row in df.itertuples():\n    arr.append([row.date,row.t1,row.t2,row.t1p,row.t2p,row.venue,row.season,row.neutral,False])\narr.append([20170314.0,'New Orleans',\"Mount St. Mary's\",66,67,'vs',2016.0,True,False])\narr.append([20170314.0,'UNC Greensboro','Syracuse',77,90,'@',2016.0,False,False])\narr.append([20170314.0,'Valparaiso','Illinois',57,82,'@',2016.0,False,False])\narr.append([20170314.0,'Oakland','Clemson',74,69,'@',2016.0,False,False])\narr.append([20170314.0,'Indiana','Georgia Tech',63,75,'@',2016.0,False,False])\narr.append([20170314.0,'Wake Forest','Kansas State',88,95,'vs',2016.0,True,False])\narr.append([20170314.0,'Richmond','Alabama',71,64,'@',2016.0,False,False])\narr.append([20170314.0,'Boise State','Utah',73,68,'@',2016.0,False,False])\narr.append([20170314.0,'Cal State Bakersfield','California',73,66,'@',2016.0,False,False])\narr.append([20170314.0,'Mississippi','Monmouth',91,83,'@',2016.0,False,False])\narr.append([20180112.0,'Delaware State','Hampton',56,78,'@',2017.0,False,False])\narr.append([20170314.0,'College of Charleston','Colorado State',74,81,'@',2016.0,False,False])\ndff=pd.DataFrame(arr,columns=['date','t1','t2','t1p','t2p','venue','season','neutral','hj'])\ndff=dff.astype({\"date\":float})\ndff=dff.sort_values(by='date')\ndff=dff.astype({\"venue\":\"string\"})\ndff['venue']=dff['venue'].replace(\"at\",\"@\")\ndff['venue']=dff['venue'].replace(\"A\",\"@\")\ndff['venue']=dff['venue'].replace(\"N\",\"vs\")\ndff['venue']=dff['venue'].replace(\"H\",\"vs\")\ndf22=dff.replace(\"Albany\",\"Albany (NY)\")\ndf22=df22.replace(\"LSU\",\"Louisiana State\")\ndf22=df22.replace(\"Citadel\",\"The Citadel\")\ndf22=df22.replace(\"NotreDame\",\"Notre Dame\")\ndf22=df22.replace(\"BYU\",\"Brigham Young\")\ndf22=df22.replace(\"NC Central\",\"North Carolina Central\")\nconfs[2025]['Texas A&M-Commerce']='Southland'\nconfs[2024]['Texas A&M-Commerce']='Southland'\nconfs[2023]['Texas A&M-Commerce']='Southland'\nconfs[2022]['Texas A&M-Commerce']='Southland'\nconfs[2024]['IU Indy']='Horizon'\nfor key in list(confs):\n    if 'IU Indy' in confs[key]:\n        confs[key]['IUPUI']=confs[key]['IU Indy']\ndf22=df22.replace(\"Citadel\",\"The Citadel\")\ndf22=df22.replace(\"NotreDame\",\"Notre Dame\")\ndf22=df22.replace(\"BYU\",\"Brigham Young\")\ndf22=df22.replace(\"IUPUI\",\"IU Indy\")\ndf22=df22.replace(\"Cal Baptist\",\"California Baptist\")\ndf22=df22.replace(\"East Texas A&M\",\"Texas A&M-Commerce\")\ndf22=df22.replace(\"Centenary\",\"Centenary (LA)\")\ndf22=df22.replace(\"Detroit\",\"Detroit Mercy\")\nconfs[2008]['North Dakota']='Ind'\nconfs[2011]['Omaha']='Ind'\nconfs[2008]['Seattle']='Ind'\nconfs[2001]['Purdue Fort Wayne']='Ind'\nconfs[2008]['North Dakota']='Ind'\nconfs[2001]['Morris Brown']='Ind'\nk=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/finalbart.csv\")\n!pip install playwright\n!playwright install\n!playwright install-deps\narrw=[]\nfrom playwright.async_api import async_playwright\nimport asyncio\n\n\nasync def fetch(link):\n    async with async_playwright() as p:\n        browser=await p.chromium.launch(headless=True)\n        page=await browser.new_page()\n        await page.goto(link,wait_until=\"load\")\n        last=None\n        for _ in range(10):\n            await page.wait_for_load_state(\"networkidle\")\n            new=page.url\n            if new==last:\n                break\n            last=new\n        try:\n            await page.wait_for_selector(\"table\")\n        except Exception as e:\n            print(e)\n        html=await page.content()\n        await browser.close()\n        soup=BeautifulSoup(html)\n        return soup\nfrom playwright.async_api import async_playwright\nfrom bs4 import BeautifulSoup\nimport asyncio\n\n\n\nasync def fetchz(link, context):\n    page = await context.new_page()\n    await page.route(\"**/*\", lambda route: route.abort() if route.request.resource_type in [\"image\", \"stylesheet\", \"font\"] else route.continue_())\n    await page.goto(link, wait_until=\"domcontentloaded\",timeout=0)\n    last = None\n    for _ in range(10):\n        await page.wait_for_load_state(\"networkidle\")\n        new = page.url\n        if new == last:\n            break\n        last = new\n    try:\n        await page.wait_for_selector(\"table\",state=\"attached\")\n    except Exception as e:\n        print(e)\n    element = await page.query_selector(\"table\")\n    html = await element.inner_html()\n    soup = BeautifulSoup(html, \"html.parser\")\n    await page.close()\n    return soup\n\nasync def main(link):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=True,args=[\"--disable-gpu\", \"--no-sandbox\"])\n        context = await browser.new_context()\n        result = await fetchz(link,context)\n        await browser.close()\n        return result\ndates={}\nimport nest_asyncio\nnest_asyncio.apply()\nh=df22[df22.season==2025]\nfrom datetime import date\ntoday=date.today()\ntoday=str(today)\ntoday=today.replace(\"-\",\"\")\ntoday=float(today)\nfor row in h.itertuples():\n    if row.date not in dates:\n        if float(row.date)<today:\n            dates[row.date]=row.season\n        \nfor d in dates:\n    print(d)\n    d=str(d)\n    d=d.replace(\".0\",\"\")\n    url=\"https://barttorvik.com/schedule.php?date=\"+d+\"&conlimit=\"\n    loop = asyncio.get_event_loop()\n    table = loop.run_until_complete(main(url))\n    for tr in table.find_all(\"tr\"):\n        if \"Result\" not in str(tr) and 'absolute error' not in str(tr):\n            teams=tr.find_all(\"td\")[1]\n            pred=tr.find_all(\"td\")[2]\n            pred=pred.find(\"a\").text\n            score=tr.find_all(\"td\")[4]\n            score=score.find(\"a\").text\n            t1=teams.find_all(\"a\")[0].text\n            t2=teams.find_all(\"a\")[1].text\n            pred=pred.split(\",\")\n            pred=pred[0]\n            predw=\"?\"\n            line=\"?\"\n            if \"-\" in str(pred):\n                pred=pred.split(\"-\")\n                line=pred[1]\n                predw=pred[0]\n            if 'vs' in str(teams):\n                n=True\n            elif 'at' in str(teams):\n                n=False\n                \n            arrw.append([d,t2,t1,predw,line,score,n,dates[float(str(d)+\".0\")]])\ngames={}\nfor row in k.itertuples():\n    arrw.append([row.date,row.home,row.away,row.predw,row.line,row.final,row.neutral,row.season])\nk=pd.DataFrame(arrw,columns=['date','home','away','predw','line','final','neutral','season'])\nk=k.astype({\"final\":\"string\"})\nk=k[k.final!='']\nfor row in k.itertuples():\n    score=str(row.final)\n    score=score.split(\",\")\n    score=score[1]\n    score=score.replace(\" \",\"\")\n    s1=score.split(\"-\")[0]\n    s2=score.split(\"-\")[1]\n    name=str(row.date)+\".0\"+row.home+row.away+str(s1)+\" \"+str(s2)\n    name=name.replace(\"BYU\",\"Brigham Young\")\n    line=str(row.line)\n    if '?' in str(line):\n        line=-2000\n    prewin=str(row.predw)\n    prewin=prewin.rstrip()\n    games[name]={\"winner\":prewin,\"line\":float(line)}\nprint(\"dropping rows\")\nsy=[]\ndf22['isnon']=False\ndf22=df22.replace(\"IU Indy\",\"IUPUI\")\nfor row in df22.itertuples():\n    if row.t1 not in confs[row.season] or row.t2 not in confs[row.season]:\n        if row.season not in sy:\n            sy.append(row.season)\n            print(row.season)\n        df22.at[row.Index,'isnon']=True\ner=df22\ndf22=df22[df22.isnon==False]\nfor row in df22.itertuples():\n    if float(row.t1p)==0 and float(row.t2p)==0:\n        df22=df22.drop(row.Index)\n    if float(row.t1p)==2 and float(row.t2p)==0:\n        df22=df22.drop(row.Index)\n    if float(row.t1p)==0 and float(row.t2p)==2:\n        df22=df22.drop(row.Index)\n    if float(row.t1p)==1 and float(row.t2p)==0:\n        df22=df22.drop(row.Index)\n    if float(row.t1p)==0 and float(row.t2p)==1:\n        df22=df22.drop(row.Index)\nfor row in df22.itertuples():\n    if float(row.date)==20150216 and row.t1=='Bethune-Cookman' and row.t2=='North Carolina A&T':\n        df22.at[row.Index,'t1p']=78\n    if float(row.date)==20150216 and row.t2=='Bethune-Cookman' and row.t1=='North Carolina A&T':\n        df22.at[row.Index,'t2p']=78\nfor row in df22.itertuples():\n    if float(row.season)==2016 and row.t1=='Prairie View' and row.t2=='Jackson State':\n        df22.at[row.Index,'t2p']=56\n    if float(row.season)==2016 and row.t2=='Prairie View' and row.t1=='Jackson State':\n        df22.at[row.Index,'t1p']=56\nfor row in df22.itertuples():\n    if float(row.season)==2016 and row.t1=='Maryland-Eastern Shore' and row.t2=='North Carolina A&T' and row.t1p==74 and row.t2p==67:\n        df22.at[row.Index,'t1p']=75\n        df22.at[row.Index,'t2p']=65\n    if float(row.season)==2016 and row.t2=='Maryland-Eastern Shore' and row.t1=='North Carolina A&T' and row.t2p==74 and row.t1p==67:\n        df22.at[row.Index,'t2p']=75\n        df22.at[row.Index,'t1p']=65\nfor row in df22.itertuples():\n    if float(row.season)==2016 and row.t1=='North Carolina Central' and row.t2=='Maryland-Eastern Shore' and row.t1p==79 and row.t2p==49:\n        df22.at[row.Index,'t1p']=77\n    if float(row.season)==2016 and row.t2=='North Carolina Central' and row.t1=='Maryland-Eastern Shore' and row.t2p==79 and row.t1p==49:\n        df22.at[row.Index,'t2p']=77\nfor row in df22.itertuples():\n    if float(row.season)==2014 and row.t1=='Army' and row.t2=='Colgate' and row.t1p==65:\n        df22.at[row.Index,'t2p']=63\n    if float(row.season)==2014 and row.t2=='Army' and row.t1=='Colgate' and row.t2p==65:\n        df22.at[row.Index,'t1p']=63\nfor row in df22.itertuples():\n    if row.season==2018 and row.t1=='Saint Francis (PA)' and row.t2=='Morgan State' and row.t2p==60:\n        df22.at[row.Index,'t2p']=62\n    if row.season==2018 and row.t2=='Saint Francis (PA)' and row.t1=='Morgan State' and row.t1p==60:\n        df22.at[row.Index,'t1p']=62\nfor row in df22.itertuples():\n    if row.t1=='Old Dominion' and row.season==2018 and row.t2=='Southern Mississippi' and row.t1p==78 and row.t2p==60:\n        df22.at[row.Index,'t1p']=76\n        df22.at[row.Index,'t2p']=62\n    if row.t2=='Old Dominion' and row.season==2018 and row.t1=='Southern Mississippi' and row.t2p==78 and row.t1p==60:\n        df22.at[row.Index,'t2p']=76\n        df22.at[row.Index,'t1p']=62\nfor row in df22.itertuples():\n    if row.season==2019 and row.t1=='Gardner-Webb' and row.t2=='Hampton' and row.t1p==39 and row.t2p==31:\n        df22.at[row.Index,'t1p']=81\n        df22.at[row.Index,'t2p']=67\n    if row.season==2019 and row.t2=='Gardner-Webb' and row.t1=='Hampton' and row.t2p==39 and row.t1p==31:\n        df22.at[row.Index,'t2p']=81\n        df22.at[row.Index,'t1p']=67\nfor row in df22.itertuples():\n    if float(row.date)==20170314 and 'UNC Greensboro' in str(row) and 'Syracuse' in str(row):\n        df22=df22.drop(row.Index)\nfor row in df22.itertuples():\n    if float(row.date)==20180224 and 'Morgan State' in str(row)\tand 'Hampton' in str(row):\n        df22=df22.drop(row.Index)\nfor row in df22.itertuples():\n    if float(row.date)==20200120 and 'Hampton' in str(row) and 'Gardner-Webb' in str(row):\n        df22.at[row.Index,'date']=20200224\nfor row in df22.itertuples():\n    if float(row.date)==20180112 and row.t1=='Delaware State' and row.t2=='Hampton'\tand row.t1p==56\tand row.t2p==78:\n        df22=df22.drop(row.Index)\nkl=df22[df22.season>2013]\ngsz=[]\ngszz=[]\nprint(\"count new:\"+str(len(kl)))\nprint(\"doing confy\")\ndf22=df22[df22.hj==False]\ndf22=df22.astype({\"t1p\":float,'t2p':float})\ndf22=df22.astype({\"t1p\":float,'t2p':float})\nfor game in df22.itertuples():\n    if game.t1 in confs[game.season] and game.t2 in confs[game.season]:\n        if confs[float(game.season)][game.t1]!=confs[float(game.season)][game.t2]:\n            sconf=confs[float(game.season)][game.t1]\n            if sconf not in confy:\n                confy[sconf]=[]\n            confy[sconf].append(game.t1p-game.t2p)\n            oconf=confs[float(game.season)][game.t2]\n            if oconf not in confy:\n                confy[oconf]=[]\n            confy[oconf].append(game.t2p-game.t1p)\ncombo=[]\ncombo.append(['Samford',\"UAB\"])\ncombo.append([\"Manhattan\",\"Fordham\"])\ncombo.append(['Loyola (IL)','DePaul'])\ncombo.append(['DePaul','Illinois-Chicago'])\ncombo.append(['Grambling','Centenary (LA)'])\ncombo.append(['Chicago State','Illinois-Chicago'])\ncombo.append(['Loyola (IL)','Chicago State'])\ncombo.append([\"Fordham\",\"Columbia\"])\ncombo.append([\"Columbia\",\"Manhattan\"])\ncombo.append([\"East Carolina\",\"Furman\"])\ncombo.append([\"San Diego State\",\"San Diego\"])\ncombo.append([\"Butler\",\"IUPUI\"])\ncombo.append([\"Louisiana State\",\"Southern\"])\ncombo.append([\"UCLA\",\"Southern California\"])\ncombo.append([\"Southern California\",\"Loyola Marymount\"])\ncombo.append([\"UCLA\",\"Loyola Marymount\"])\ncombo.append([\"St. John's (NY)\",\"Manhattan\"])\ncombo.append(['Lipscomb','Belmont'])\ncombo.append(['Lipscomb','Tennessee State'])\ncombo.append(['Belmont','Vanderbilt'])\ncombo.append(['Delaware','NJIT'])\ncombo.append(['Vanderbilt','Lipscomb'])\ncombo.append([\"Fordham\",\"St. John's (NY)\"])\ncombo.append([\"Columbia\",\"St. John's (NY)\"])\ncombo.append([\"St. Francis (NY)\",\"St. John's (NY)\"])\ncombo.append([\"St. Francis (NY)\",\"Columbia\"])\ncombo.append(['Southern Indiana','Evansville'])\ncombo.append([\"Manhattan\",\"St. John's (NY)\"])\ncombo.append([\"Duke\",\"North Carolina Central\"])\ncombo.append(['Charleston Southern','College of Charleston'])\ncombo.append([\"Fordham\",\"St. Francis (NY)\"])\ncombo.append(['Le Moyne','Syracuse'])\ncombo.append(['North Carolina A&T','UNC Greensboro'])\ncombo.append(['Charlotte','Queens (NC)'])\ncombo.append(['Wake Forest','Winston-Salem'])\ncombo.append(['Florida State','Florida A&M'])\ncombo.append(['Washington (MO)','Saint Louis'])\ncombo.append(['Baltimore','Loyola (MD)'])\ncombo.append(['Baltimore','Coppin State'])\ncombo.append(['Baltimore','Morgan State'])\ncombo.append(['New Orleans','Loyola (LA)'])\ncombo.append(['Loyola (LA)','Tulane'])\ncombo.append(['Tulane','New Orleans'])\ncombo.append(['Northeastern Illinois','Chicago State'])\ncombo.append(['Northeastern Illinois','DePaul'])\ncombo.append(['Northeastern Illinois','Illinois-Chicago'])\ncombo.append(['Georgia Tech','Morris Brown'])\ncombo.append(['Georgia State','Morris Brown'])\ncombo.append(['Catholic','American'])\ncombo.append(['Catholic','George Washington'])\ncombo.append(['Catholic','Georgetown'])\ncombo.append(['Catholic','Howard'])\ncombo.append([\"St. John's (NY)\",'Wagner'])\ncombo.append(['Fordham','Wagner'])\ncombo.append(['Columbia','Wagner'])\ncombo.append(['Sacred Heart','Fairfield'])\ncombo.append(['Cal State Los Angeles','Southern California'])\ncombo.append(['San Diego State','UC San Diego'])\ncombo.append(['San Diego','UC San Diego'])\ncombo.append(['Cal State Los Angeles','Loyola Marymount'])\ncombo.append(['Cal State Los Angeles','UCLA'])\ncombo.append(['U.S. International','San Diego'])\ncombo.append(['St. Francis (NY)','Wagner'])\ncombo.append(['U.S. International','San Diego State'])\ncombo.append(['Southern Indiana','Evansville'])\ncombo.append(['Wagner','Columbia'])\ncombo.append([\"St. Francis (NY)\",\"Manhattan\"])\ncombo.append([\"Howard\",\"Georgetown\"])\ncombo.append([\"Howard\",\"George Washington\"])\ncombo.append([\"Howard\",\"American\"])\ncombo.append([\"Georgetown\",\"George Washington\"])\ncombo.append([\"American\",\"Georgetown\"])\ncombo.append([\"Howard\",\"Georgetown\"])\ncombo.append([\"Jacksonville\",\"North Florida\"])\ncombo.append([\"Georgia Tech\",\"Georgia State\"])\ncombo.append([\"Houston\",\"Texas Southern\"])\ncombo.append([\"Houston\",\"Rice\"])\ncombo.append([\"Houston\",\"Houston Christian\"])\ncombo.append([\"Rice\",\"Houston Christian\"])\ncombo.append([\"Rice\",\"Texas Southern\"])\ncombo.append([\"Houston Christian\",\"Texas Southern\"])\ncombo.append([\"DePaul\",\"Chicago State\"])\ncombo.append([\"Louisville\",\"Bellarmine\"])\ncombo.append([\"Harvard\",\"Boston University\"])\ncombo.append([\"Harvard\",\"Northeastern\"])\ncombo.append(['College of Charleston','The Citadel'])\ncombo.append([\"Boston University\",\"Northeastern\"])\ncombo.append([\"Morgan State\",\"Loyola (MD)\"])\ncombo.append([\"Coppin State\",\"Morgan State\"])\ncombo.append([\"Coppin State\",\"Loyola (MD)\"])\ncombo.append([\"Creighton\",\"Omaha\"])\ncombo.append([\"Tulsa\",\"Oral Roberts\"])\ncombo.append([\"Portland\",\"Portland State\"])\ncombo.append([\"Saint Joseph's\",\"Temple\"])\ncombo.append([\"Temple\",\"Pennsylvania\"])\ncombo.append([\"Saint Joseph's\",\"Pennsylvania\"])\ncombo.append([\"Temple\",\"La Salle\"])\ncombo.append([\"Saint Joseph's\",\"La Salle\"])\ncombo.append([\"La Salle\",\"Pennsylvania\"])\ncombo.append([\"La Salle\",\"Drexel\"])\ncombo.append([\"Drexel\",\"Pennsylvania\"])\ncombo.append([\"Saint Joseph's\",\"Drexel\"])\ncombo.append([\"Drexel\",\"Temple\"])\ncombo.append([\"Brown\",\"Providence\"])\ncombo.append([\"South Carolina Upstate\",\"Wofford\"])\ncombo.append([\"Vanderbilt\",\"Tennessee State\"])\ncombo.append([\"Vanderbilt\",\"Belmont\"])\ncombo.append([\"Belmont\",\"Tennessee State\"])\ncombo.append([\"Trinity (TX)\",\"UTSA\"])\ncombo.append(['Furman','East Carolina'])\ncombo.append([\"UTSA\",\"Incarnate Word\"])\ncombo.append([\"Abilene Christian\",\"Hardin-Simmons\"])\ncombo.append([\"Washington & Lee\",\"Virginia Military Institute\"])\ncombo.append([\"Richmond\",\"Virginia Commonwealth\"])\ncombo.append([\"Old Dominion\",\"Norfolk State\"])\ncombo.append([\"Washington\",\"Seattle\"])\ncombo.append([\"Milwaukee\",\"Marquette\"])\ncombo.append([\"Manhattan\",\"New York University\"])\ncombo.append([\"St. Francis (NY)\",\"New York University\"])\ncombo.append([\"St. John's (NY)\",\"New York University\"])\ncombo.append([\"Fordham\",\"New York University\"])\ncombo.append([\"Columbia\",\"New York University\"])\ncombo.append([\"New York University\",\"City College of New York\"])\ncombo.append([\"Manhattan\",\"City College of New York\"])\ncombo.append([\"Fordham\",\"City College of New York\"])\ncombo.append([\"Columbia\",\"City College of New York\"])\ncombo.append([\"St. John's (NY)\",\"City College of New York\"])\ncombo.append(['UC Riverside','California Baptist'])\ncombo.append([\"Pittsburgh\",\"Duquesne\"])\ncombo.append([\"Long Island University\",\"Manhattan\"])\ncombo.append([\"Long Island University\",\"St. John's (NY)\"])\ncombo.append([\"Long Island University\",\"St. Francis (NY)\"])\ncombo.append([\"Long Island University\",\"Columbia\"])\ncombo.append([\"Long Island University\",\"Fordham\"])\ncombo.append([\"Long Island University\",\"Wagner\"])\ncombo.append([\"Long Island University\",\"Brooklyn\"])\ncombo.append([\"Wagner\",\"Brooklyn\"])\ncombo.append([\"St. Francis (NY)\",\"Brooklyn\"])\ncombo.append([\"St. John's (NY)\",\"Brooklyn\"])\ncombo.append([\"New York University\",\"Brooklyn\"])\ncombo.append([\"City College of New York\",\"Brooklyn\"])\ncombo.append([\"Manhattan\",\"Brooklyn\"])\ncombo.append([\"New York University\",\"Long Island University\"])\ncombo.append([\"City College of New York\",\"Long Island University\"])\ncombo.append([\"Columbia\",\"Brooklyn\"])\ncombo.append([\"Fordham\",\"Brooklyn\"])\ncombo.append(['Xavier','Cincinnati'])\nfor row in df22.itertuples():\n    if row.season<2003:\n        if row.t1=='Miami (FL)' and row.venue=='vs':\n            df22.at[row.Index,'neutral']=True\n        if row.t2=='Miami (FL)' and row.venue=='@':\n            df22.at[row.Index,'neutral']=True\n        \nfor row in df22.itertuples():\n    if row.season>1981:\n        if row.t1=='Harvard' and row.venue=='vs':\n            df22.at[row.Index,'neutral']=True\n        if row.t2=='Harvard' and row.venue=='@':\n            df22.at[row.Index,'neutral']=True\n        if row.t1=='Harvard' and row.t2=='Northeastern' and row.venue=='@':\n            df22.at[row.Index,'neutral']=False\n        if row.t1=='Harvard' and row.t2=='Northeastern' and row.venue=='vs':\n            df22.at[row.Index,'neutral']=False\n            df22.at[row.Index,'venue']='@'\n        if row.t2=='Harvard' and row.t1=='Northeastern' and row.venue=='@':\n            df22.at[row.Index,'neutral']=False\n            df22.at[row.Index,'venue']='vs'\n        if row.t2=='Harvard' and row.t1=='Northeastern' and row.venue=='vs':\n            df22.at[row.Index,'neutral']=False\n\n        if row.t1=='Harvard' and row.t2=='Boston University' and row.venue=='@':\n            df22.at[row.Index,'neutral']=False\n        if row.t1=='Harvard' and row.t2=='Boston University' and row.venue=='vs':\n            df22.at[row.Index,'neutral']=False\n            df22.at[row.Index,'venue']='@'\n        if row.t2=='Harvard' and row.t1=='Boston University' and row.venue=='@':\n            df22.at[row.Index,'neutral']=False\n            df22.at[row.Index,'venue']='vs'\n        if row.t2=='Harvard' and row.t1=='Boston University' and row.venue=='vs':\n            df22.at[row.Index,'neutral']=False\ny=pd.read_csv(\"https://cfbzzz.alwaysdata.net/ncaaf/nicknamez.txt\")\ny=y.replace(\"Charleston\",\"College of Charleston\")\nteams={}\nfor row in y.itertuples():\n    teams[row.School]=row.City\nteams['Birm-Southern']='Birmingham AL'\nteams['Morris Brown']='Atlanta GA'\nteams['Savannah State']='Savannah GA'\nteams['Centenary (LA)']=\"Shreveport LA\"\nteams['Seton Hall']=\"South Orange NJ\"\nteams['Western Kentucky']='Bowling Green KY'\nteams['Maryland-Baltimore County']='Catonsville MD'\nteams['Villanova']='Villanova PA'\nfor comb in combo:\n    print(comb)\n    t1=comb[0]\n    t2=comb[1]\n    for row in df22.itertuples():\n        if row.t1==t1 and row.t2==t2:\n            df22.at[row.Index,'neutral']=True\n        if row.t1==t2 and row.t2==t1:\n            df22.at[row.Index,'neutral']=True\nfor game in df22.itertuples():\n    if game.t1 in confs[game.season] and game.t2 in confs[game.season] and 'True' not in str(game.neutral):\n        if game.neutral==True or game.neutral=='True':\n            m=1\n        else:\n            sc=confs[game.season][game.t1]\n            oc=confs[game.season][game.t2]\n            if sc not in hfas:\n                hfas[sc]=[]\n            if oc not in hfas:\n                hfas[oc]=[]\n            if game.venue!='@':\n                hfas[sc].append(game.t1p-game.t2p)\n            else:\n                hfas[oc].append(game.t2p-game.t1p)\nmh=[]\nfor key in hfas:\n    mh.append(round(np.mean(hfas[key])))\nmh=round(np.mean(mh))*kval\nfor key in hfas:\n    hfas[key]=round(np.mean(hfas[key]))\n    hfas[key]=hfas[key]*kval\nfor t in confy:\n    confy[t]=round(np.mean(confy[t]))*kval\nnewd1=[]\nfor row in df22.itertuples():\n    if row.season>1949:\n        if row.t1 in confs[row.season-1] and row.t2 not in confs[row.season-1]:\n            newd1.append(row.t2p-row.t1p)\n        if row.t2 in confs[row.season-1] and row.t1 not in confs[row.season-1]:\n            newd1.append(row.t1p-row.t2p)\nnewd1=round(np.mean(newd1))\nnewd1=newd1*kval\neloLeague.addPlayer(\"Case Western Reserve\",rating=1500)\ndf22=df22[df22.t1!='West Virginia Tech']\ndf22=df22[df22.t2!='West Virginia Tech']\ndf22=df22[df22.t1!='Lawrence Tech']\ndf22=df22[df22.t2!='Lawrence Tech']\nprint(\"dropping\")\nfor game in df22.itertuples():\n    if game.t1 not in confs[game.season] or game.t2 not in confs[game.season]:\n        df22=df22.drop(game.Index)\nfor game in df22.itertuples():\n    if game.t1p==0 and game.t2p==0:\n        df22=df22.drop(game.Index)\nprint(\"done dropping\")\nfor t in set(df22.t1.tolist()+df22.t2.tolist()):\n    eloLeague.addPlayer(t,rating=1500)\nfor game in df22.itertuples():\n    season=game.season\n    if season>currSeason: \n        print(season,'yes')\n        confz={}\n        pr=df22[df22.season==season]\n        hw=set(pr.t1.tolist()+pr.t2.tolist())\n        for t in hw:\n            if t not in eloLeague.ratingDict.keys():\n                eloLeague.addPlayer(t,rating=1500)\n            if t not in confs[game.season-1]:\n                eloLeague.ratingDict[t]=eloLeague.ratingDict[t]+newd1\n        for team in confs[game.season]:\n            if team in hw:\n                if confs[game.season][team] not in confz:\n                    confz[confs[game.season][team]]=[]\n                confz[confs[game.season][team]].append(eloLeague.ratingDict[team])\n        lsdf=df22[df22.season<game.season]\n        ls=set(lsdf.t1.tolist()+lsdf.t2.tolist())\n        for key in eloLeague.ratingDict.keys():\n            team=key\n            if key in confs[game.season] and key in ls:\n                mean=np.mean(confz[confs[game.season][team]])\n                eloLeague.ratingDict[team]=(eloLeague.ratingDict[team]*(1-rev))+(mean*rev)     \n        currSeason+=1\n    hr=eloLeague.ratingDict[game.t1]\n    ar=eloLeague.ratingDict[game.t2]\n    row=game\n    name=str(row.date)+row.t1+row.t2+str(row.t1p)+\" \"+str(row.t2p)\n    namez=str(row.date)+row.t2+row.t1+str(row.t2p)+\" \"+str(row.t1p)\n    namezz=str(row.date)+row.t1+row.t2+str(row.t2p)+\" \"+str(row.t1p)\n    namezzz=str(row.date)+row.t2+row.t1+str(row.t1p)+\" \"+str(row.t2p)\n    preds=-2000\n    if name in games:\n        predl=games[name]['line']\n        predw=games[name]['winner']\n        if predw==game.t1:\n            preds=float(predl)\n        else:\n            preds=-float(predl)\n    elif namez in games:\n        predl=games[namez]['line']\n        predw=games[namez]['winner']\n        if predw==game.t1:\n            preds=float(predl)\n        else:\n            preds=-float(predl)\n    elif namezz in games:\n        predl=games[namezz]['line']\n        predw=games[namezz]['winner']\n        if predw==game.t1:\n            preds=float(predl)\n        else:\n            preds=-float(predl)\n    elif namezzz in games:\n        predl=games[namezzz]['line']\n        predw=games[namezzz]['winner']\n        if predw==game.t1:\n            preds=float(predl)\n        else:\n            preds=-float(predl)\n        \n    hr+=confy[confs[game.season][game.t1]]\n    ar+=confy[confs[game.season][game.t2]]\n    if 'False' in str(game.neutral):\n        if 'vs' in str(game.venue):\n            hr+=hfas[confs[game.season][game.t1]]\n        if '@' in str(game.venue):\n            ar+=hfas[confs[game.season][game.t2]]\n    if preds!=-2000:\n        diff=(hr-ar)/kval\n        diff=(diff+preds)/2\n    else:\n        diff=(hr-ar)/kval\n    if(game.t1p>game.t2p):\n        df22.at[game.Index,'predt1s']=diff\n        eloLeague.gameOver(game.t1,game.t2,game.t1p,game.t2p,diff*kval)\n    if(game.t1p<game.t2p):\n        df22.at[game.Index,'predt1s']=diff\n        eloLeague.gameOver(game.t2,game.t1,game.t2p,game.t1p,-diff*kval)\n        \nprint(\"--- %s seconds ---\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2025-11-16T18:42:54.750824Z","iopub.execute_input":"2025-11-16T18:42:54.751356Z","iopub.status.idle":"2025-11-16T18:52:37.666998Z","shell.execute_reply.started":"2025-11-16T18:42:54.751261Z","shell.execute_reply":"2025-11-16T18:52:37.665207Z"},"trusted":true},"outputs":[{"name":"stdout","text":"done files\ngo through games\n1999.0\nno!!!!\nno!!!!\nno!!!!\n1998.0\nno!!!!\nno!!!!\nno!!!!\n1997.0\nno!!!!\nno!!!!\nno!!!!\n1996.0\nno!!!!\nno!!!!\nno!!!!\n1995.0\nno!!!!\nno!!!!\nno!!!!\n1994.0\nno!!!!\nno!!!!\nno!!!!\n1993.0\nno!!!!\nno!!!!\nno!!!!\n1992.0\nno!!!!\nno!!!!\nno!!!!\n1991.0\nno!!!!\nno!!!!\nno!!!!\n1990.0\nno!!!!\nno!!!!\nno!!!!\n1989.0\nno!!!!\nno!!!!\nno!!!!\n1988.0\nno!!!!\nno!!!!\nno!!!!\n1987.0\nno!!!!\nno!!!!\nno!!!!\n1986.0\nno!!!!\nno!!!!\nno!!!!\n1985.0\nno!!!!\nno!!!!\nno!!!!\n1984.0\nno!!!!\nno!!!!\nno!!!!\n1983.0\nno!!!!\nno!!!!\nno!!!!\n1982.0\nno!!!!\nno!!!!\nno!!!!\n1981.0\nno!!!!\nno!!!!\nno!!!!\n1980.0\nno!!!!\nno!!!!\nno!!!!\n1979.0\nno!!!!\nno!!!!\nno!!!!\n1978.0\nno!!!!\nno!!!!\nno!!!!\n1977.0\nno!!!!\nno!!!!\nno!!!!\n1976.0\nno!!!!\nno!!!!\nno!!!!\n1975.0\nno!!!!\nno!!!!\nno!!!!\n1974.0\nno!!!!\nno!!!!\nno!!!!\nno!!!!\n1973.0\nno!!!!\nno!!!!\nno!!!!\nno!!!!\n1972.0\nno!!!!\nno!!!!\nno!!!!\n1971.0\nno!!!!\nno!!!!\nno!!!!\n1970.0\nno!!!!\nno!!!!\nno!!!!\n1969.0\nno!!!!\nno!!!!\nno!!!!\n1968.0\nno!!!!\nno!!!!\nno!!!!\n1967.0\nno!!!!\nno!!!!\nno!!!!\n1966.0\nno!!!!\nno!!!!\nno!!!!\n1965.0\nno!!!!\nno!!!!\nno!!!!\n1964.0\nno!!!!\nno!!!!\nno!!!!\n1963.0\nno!!!!\nno!!!!\nno!!!!\n1962.0\nno!!!!\nno!!!!\nno!!!!\n1961.0\nno!!!!\nno!!!!\nno!!!!\n1960.0\nno!!!!\nno!!!!\nno!!!!\n1959.0\nno!!!!\nno!!!!\nno!!!!\n1958.0\nno!!!!\nno!!!!\nno!!!!\n1957.0\nno!!!!\nno!!!!\nno!!!!\n1956.0\nno!!!!\nno!!!!\nno!!!!\n1955.0\nno!!!!\nno!!!!\nno!!!!\n1954.0\nno!!!!\nno!!!!\nno!!!!\n1953.0\nno!!!!\nno!!!!\nno!!!!\n1952.0\nno!!!!\nno!!!!\nno!!!!\n1951.0\nwhat!!!!!!\n['604', 'CCN', '47', 'NYU', '84', 'H']\n['421', 'WTS', '60', 'HDS', '54', 'A']\n['519', 'WTS', '81', 'HDS', '54', 'H']\n['416', 'ARM', '62', 'LEH', '51', 'H']\n['502', 'ARM', '58', 'CLG', '52', 'H']\n['601', 'ARM', '55', 'NAV', '60', 'H']\n['315', 'BUC', '87', 'LEH', '67', 'H']\n['404', 'BUC', '53', 'CLG', '57', 'H']\n['509', 'BUC', '85', 'RHO', '74', 'A']\n['513', 'BUC', '60', 'LEH', '64', 'A']\nwhat!!!!!!\nwhat!!!!!!\n1950.0\nno!!!!\nno!!!!\nno!!!!\n1949.0\nno!!!!\nno!!!!\nno!!!!\nABI\nAFU\nAKR\nALA\nAAM\nALS\nANY\nALC\nAME\nAPP\nARI\nASU\nARK\nARS\nARL\nARG\nAPB\nARM\nAUB\nAUG\nAUS\nBAL\nBLD\nBLO\nBLT\nBAP\nBAY\nBEL\nBET\nBOI\nBOC\nBOU\nBGU\nBRA\nBRK\nBRO\nBUC\nBUF\nBUT\nBYU\nCAL\nCSL\nCLA\nCAM\nCAN\nCWR\nCAT\nCEN\nCCS\nCSO\nNCC\nUTC\nCHI\nCHS\nCIN\nCIT\nCCN\nCLE\nCLS\nCMI\nCCA\nCHA\nCLG\nCOL\nCSU\nCLM\nCON\nCOP\nCOR\nCRE\nFUL\nCNO\nCAS\nDAR\nDAV\nDAY\nDEL\nDSU\nDEN\nDEP\nDET\nDRA\nDRE\nDUK\nDUQ\nECA\nEIL\nEKY\nELN\nEMI\nETS\nEVA\nEWA\nFRF\nFDU\nFLA\nFLO\nFAM\nFLI\nFSU\nFOR\nFRE\nFUR\nGSO\nGEM\nGTN\nGEO\nGES\nGET\nGTY\nGON\nGRA\nGEW\nHML\nHMP\nHDS\nHRT\nHAR\nHAW\nHGH\nHOF\nHOL\nHOU\nHOB\nHOW\nIDA\nIDS\nILC\nILL\nILS\nIND\nINS\nION\nIOW\nIOS\nIUP\nJSU\nJAC\nJVS\nJAM\nJOH\nKAN\nKSU\nKTS\nKEN\nKYW\nLAF\nLBV\nLLA\nLAM\nLMN\nLAS\nLWT\nLEH\nLIB\nLBS\nLIU\nLOT\nLOU\nLOC\nLOI\nLOM\nLON\nLSU\nMAI\nMAN\nMRS\nMRQ\nMSH\nMAR\nMAS\nMCN\nMBC\nMDE\nMEM\nMER\nMFL\nMOH\nMIC\nMSU\nMDT\nMIN\nMIS\nMSS\nMSO\nMKC\nSWM\nMOM\nMON\nMOS\nMOR\nMGS\nMVS\nMSM\nMUH\nMUR\nNAR\nNAV\nNCT\nNCS\nNEB\nUNR\nNEH\nNEM\nNMS\nNEO\nNYU\nNIA\nNIC\nNEI\nNIL\nNFK\nUNC\nNOE\nNEL\nNCL\nNIO\nNTS\nNOR\nNWL\nNOT\nOAK\nOHI\nOSU\nOKL\nOKC\nOKS\nOLD\nORA\nORE\nORS\nPAC\nPAN\nPEN\nPSU\nPEP\nPIT\nPOR\nPOS\nPRA\nPRI\nPRO\nPUR\nQUI\nRAD\nREG\nRHO\nRIC\nRCH\nRID\nROB\nRUT\nSAC\nSAL\nSMF\nSAM\nSDI\nSDS\nSFR\nSJS\nCSB\nCSC\nSCR\nSEA\nSCS\nSEL\nSEM\nSET\nSFA\nSIE\nSIL\nSMU\nSCA\nSWL\nSMS\nSOU\nSUS\nSFL\nSTA\nSTB\nSTE\nSFN\nSFP\nSTJ\nSJP\nSTL\nSTM\nSTO\nSTP\nSYR\nCRP\nTCU\nTEM\nTEN\nTNS\nTNT\nTEX\nTAM\nSWT\nTET\nTXW\nUTM\nTOL\nTOW\nTTX\nTRO\nTLN\nTUL\nTEA\nTSA\nTES\nALB\nCFL\nUCI\nUCL\nNCA\nNCG\nNCW\nUNL\nUSC\nUSI\nUTA\nUTS\nUTE\nUTI\nVIC\nVAL\nVAN\nUVM\nVIL\nVIR\nVIT\nVMI\nWAG\nWAK\nWAM\nWAS\nWSS\nW&L\nWAY\nWCA\nWEB\nWCS\nWTS\nWVI\nWIC\nWGR\nW&M\nWLM\nWIL\nWML\nWIN\nWIS\nWKE\nWMI\nWOF\nWRI\nWYO\nXAV\nYAL\nYOU\n20251103\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251103&groups=50&limit=360\n169\n20251104\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251104&groups=50&limit=360\n36\n20251105\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251105&groups=50&limit=360\n35\n20251106\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251106&groups=50&limit=360\n44\n20251107\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251107&groups=50&limit=360\n76\n20251108\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251108&groups=50&limit=360\n68\n20251109\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251109&groups=50&limit=360\n34\n20251110\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251110&groups=50&limit=360\n40\n20251111\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251111&groups=50&limit=360\n82\n20251112\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251112&groups=50&limit=360\n54\n20251113\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251113&groups=50&limit=360\n26\n20251114\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251114&groups=50&limit=360\n50\n20251115\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251115&groups=50&limit=360\n82\n20251116\nhttps://site.api.espn.com/apis/site/v2/sports/basketball/mens-college-basketball/scoreboard?dates=20251116&groups=50&limit=360\n34\nYoungstown State [['Youngstown OH', 'Beeghly Center']]\nYale [['New Haven CT', 'John J. Lee Amphitheater']]\n2025.0\n2014.0\n2015.0\n2016.0\n2017.0\n2018.0\n2019.0\n2020.0\n2021.0\n2022.0\n2023.0\n2024.0\n/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nCollecting playwright\n  Downloading playwright-1.35.0-py3-none-manylinux1_x86_64.whl (35.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from playwright) (4.1.1)\nCollecting pyee==9.0.4\n  Downloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\nCollecting greenlet==2.0.2\n  Downloading greenlet-2.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (566 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyee, greenlet, playwright\n  Attempting uninstall: greenlet\n    Found existing installation: greenlet 1.1.3\n    Uninstalling greenlet-1.1.3:\n      Successfully uninstalled greenlet-1.1.3\nSuccessfully installed greenlet-2.0.2 playwright-1.35.0 pyee-9.0.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nDownloading Chromium 115.0.5790.24 (playwright build v1067)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1067/chromium-linux.zip\u001b[22m\n\u001b[1G146.4 Mb [                    ] 0% 9.7s\u001b[0K\u001b[1G146.4 Mb [                    ] 0% 33.9s\u001b[0K\u001b[1G146.4 Mb [                    ] 0% 22.8s\u001b[0K\u001b[1G146.4 Mb [                    ] 0% 12.6s\u001b[0K\u001b[1G146.4 Mb [                    ] 0% 7.4s\u001b[0K\u001b[1G146.4 Mb [                    ] 1% 4.5s\u001b[0K\u001b[1G146.4 Mb [=                   ] 2% 3.4s\u001b[0K\u001b[1G146.4 Mb [=                   ] 4% 2.6s\u001b[0K\u001b[1G146.4 Mb [=                   ] 5% 2.4s\u001b[0K\u001b[1G146.4 Mb [=                   ] 6% 2.2s\u001b[0K\u001b[1G146.4 Mb [=                   ] 7% 2.1s\u001b[0K\u001b[1G146.4 Mb [==                  ] 8% 2.0s\u001b[0K\u001b[1G146.4 Mb [==                  ] 9% 1.9s\u001b[0K\u001b[1G146.4 Mb [==                  ] 10% 1.9s\u001b[0K\u001b[1G146.4 Mb [==                  ] 11% 1.7s\u001b[0K\u001b[1G146.4 Mb [===                 ] 12% 1.7s\u001b[0K\u001b[1G146.4 Mb [===                 ] 13% 1.6s\u001b[0K\u001b[1G146.4 Mb [===                 ] 14% 1.6s\u001b[0K\u001b[1G146.4 Mb [===                 ] 16% 1.5s\u001b[0K\u001b[1G146.4 Mb [===                 ] 17% 1.5s\u001b[0K\u001b[1G146.4 Mb [====                ] 17% 1.5s\u001b[0K\u001b[1G146.4 Mb [====                ] 19% 1.4s\u001b[0K\u001b[1G146.4 Mb [====                ] 20% 1.4s\u001b[0K\u001b[1G146.4 Mb [====                ] 21% 1.3s\u001b[0K\u001b[1G146.4 Mb [=====               ] 22% 1.3s\u001b[0K\u001b[1G146.4 Mb [=====               ] 24% 1.3s\u001b[0K\u001b[1G146.4 Mb [=====               ] 25% 1.2s\u001b[0K\u001b[1G146.4 Mb [=====               ] 26% 1.2s\u001b[0K\u001b[1G146.4 Mb [======              ] 27% 1.2s\u001b[0K\u001b[1G146.4 Mb [======              ] 28% 1.2s\u001b[0K\u001b[1G146.4 Mb [======              ] 29% 1.2s\u001b[0K\u001b[1G146.4 Mb [======              ] 30% 1.1s\u001b[0K\u001b[1G146.4 Mb [======              ] 31% 1.1s\u001b[0K\u001b[1G146.4 Mb [=======             ] 32% 1.1s\u001b[0K\u001b[1G146.4 Mb [=======             ] 33% 1.1s\u001b[0K\u001b[1G146.4 Mb [=======             ] 34% 1.1s\u001b[0K\u001b[1G146.4 Mb [=======             ] 36% 1.1s\u001b[0K\u001b[1G146.4 Mb [========            ] 37% 1.1s\u001b[0K\u001b[1G146.4 Mb [========            ] 38% 1.1s\u001b[0K\u001b[1G146.4 Mb [========            ] 39% 1.1s\u001b[0K\u001b[1G146.4 Mb [========            ] 40% 1.0s\u001b[0K\u001b[1G146.4 Mb [========            ] 42% 1.0s\u001b[0K\u001b[1G146.4 Mb [=========           ] 43% 1.0s\u001b[0K\u001b[1G146.4 Mb [=========           ] 44% 1.0s\u001b[0K\u001b[1G146.4 Mb [=========           ] 45% 1.0s\u001b[0K\u001b[1G146.4 Mb [=========           ] 46% 0.9s\u001b[0K\u001b[1G146.4 Mb [==========          ] 47% 0.9s\u001b[0K\u001b[1G146.4 Mb [==========          ] 49% 0.9s\u001b[0K\u001b[1G146.4 Mb [==========          ] 50% 0.9s\u001b[0K\u001b[1G146.4 Mb [==========          ] 51% 0.8s\u001b[0K\u001b[1G146.4 Mb [==========          ] 52% 0.8s\u001b[0K\u001b[1G146.4 Mb [===========         ] 53% 0.8s\u001b[0K\u001b[1G146.4 Mb [===========         ] 54% 0.8s\u001b[0K\u001b[1G146.4 Mb [===========         ] 55% 0.8s\u001b[0K\u001b[1G146.4 Mb [===========         ] 56% 0.7s\u001b[0K\u001b[1G146.4 Mb [============        ] 57% 0.7s\u001b[0K\u001b[1G146.4 Mb [============        ] 59% 0.7s\u001b[0K\u001b[1G146.4 Mb [============        ] 60% 0.7s\u001b[0K\u001b[1G146.4 Mb [============        ] 61% 0.7s\u001b[0K\u001b[1G146.4 Mb [============        ] 62% 0.6s\u001b[0K\u001b[1G146.4 Mb [=============       ] 63% 0.6s\u001b[0K\u001b[1G146.4 Mb [=============       ] 64% 0.6s\u001b[0K\u001b[1G146.4 Mb [=============       ] 65% 0.6s\u001b[0K\u001b[1G146.4 Mb [=============       ] 66% 0.6s\u001b[0K\u001b[1G146.4 Mb [==============      ] 68% 0.6s\u001b[0K\u001b[1G146.4 Mb [==============      ] 69% 0.5s\u001b[0K\u001b[1G146.4 Mb [==============      ] 71% 0.5s\u001b[0K\u001b[1G146.4 Mb [==============      ] 72% 0.5s\u001b[0K\u001b[1G146.4 Mb [===============     ] 73% 0.5s\u001b[0K\u001b[1G146.4 Mb [===============     ] 74% 0.5s\u001b[0K\u001b[1G146.4 Mb [===============     ] 75% 0.4s\u001b[0K\u001b[1G146.4 Mb [===============     ] 76% 0.4s\u001b[0K\u001b[1G146.4 Mb [===============     ] 77% 0.4s\u001b[0K\u001b[1G146.4 Mb [================    ] 77% 0.4s\u001b[0K\u001b[1G146.4 Mb [================    ] 79% 0.4s\u001b[0K\u001b[1G146.4 Mb [================    ] 80% 0.4s\u001b[0K\u001b[1G146.4 Mb [================    ] 82% 0.3s\u001b[0K\u001b[1G146.4 Mb [=================   ] 82% 0.3s\u001b[0K\u001b[1G146.4 Mb [=================   ] 83% 0.3s\u001b[0K\u001b[1G146.4 Mb [=================   ] 85% 0.3s\u001b[0K\u001b[1G146.4 Mb [=================   ] 86% 0.3s\u001b[0K\u001b[1G146.4 Mb [=================   ] 87% 0.2s\u001b[0K\u001b[1G146.4 Mb [==================  ] 87% 0.2s\u001b[0K\u001b[1G146.4 Mb [==================  ] 88% 0.2s\u001b[0K\u001b[1G146.4 Mb [==================  ] 90% 0.2s\u001b[0K\u001b[1G146.4 Mb [==================  ] 92% 0.1s\u001b[0K\u001b[1G146.4 Mb [=================== ] 93% 0.1s\u001b[0K\u001b[1G146.4 Mb [=================== ] 94% 0.1s\u001b[0K\u001b[1G146.4 Mb [=================== ] 95% 0.1s\u001b[0K\u001b[1G146.4 Mb [=================== ] 97% 0.1s\u001b[0K\u001b[1G146.4 Mb [====================] 98% 0.0s\u001b[0K\u001b[1G146.4 Mb [====================] 99% 0.0s\u001b[0K\u001b[1G146.4 Mb [====================] 100% 0.0s\u001b[0K\nChromium 115.0.5790.24 (playwright build v1067) downloaded to /root/.cache/ms-playwright/chromium-1067\nDownloading FFMPEG playwright build v1009\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1009/ffmpeg-linux.zip\u001b[22m\n\u001b[1G2.6 Mb [                    ] 0% 0.0s\u001b[0K\u001b[1G2.6 Mb [=                   ] 3% 0.5s\u001b[0K\u001b[1G2.6 Mb [==                  ] 9% 0.3s\u001b[0K\u001b[1G2.6 Mb [=====               ] 25% 0.1s\u001b[0K\u001b[1G2.6 Mb [=========           ] 47% 0.1s\u001b[0K\u001b[1G2.6 Mb [=================== ] 92% 0.0s\u001b[0K\u001b[1G2.6 Mb [====================] 100% 0.0s\u001b[0K\nFFMPEG playwright build v1009 downloaded to /root/.cache/ms-playwright/ffmpeg-1009\nDownloading Firefox 113.0 (playwright build v1408)\u001b[2m from https://playwright.azureedge.net/builds/firefox/1408/firefox-ubuntu-20.04.zip\u001b[22m\n\u001b[1G78.7 Mb [                    ] 0% 0.0s\u001b[0K\u001b[1G78.7 Mb [                    ] 0% 16.2s\u001b[0K\u001b[1G78.7 Mb [                    ] 0% 10.7s\u001b[0K\u001b[1G78.7 Mb [                    ] 0% 7.5s\u001b[0K\u001b[1G78.7 Mb [                    ] 1% 4.8s\u001b[0K\u001b[1G78.7 Mb [                    ] 2% 3.3s\u001b[0K\u001b[1G78.7 Mb [=                   ] 3% 2.7s\u001b[0K\u001b[1G78.7 Mb [=                   ] 4% 2.5s\u001b[0K\u001b[1G78.7 Mb [=                   ] 5% 2.2s\u001b[0K\u001b[1G78.7 Mb [=                   ] 6% 2.1s\u001b[0K\u001b[1G78.7 Mb [==                  ] 8% 1.8s\u001b[0K\u001b[1G78.7 Mb [==                  ] 9% 1.7s\u001b[0K\u001b[1G78.7 Mb [==                  ] 10% 1.7s\u001b[0K\u001b[1G78.7 Mb [==                  ] 11% 1.6s\u001b[0K\u001b[1G78.7 Mb [===                 ] 13% 1.5s\u001b[0K\u001b[1G78.7 Mb [===                 ] 14% 1.4s\u001b[0K\u001b[1G78.7 Mb [===                 ] 16% 1.3s\u001b[0K\u001b[1G78.7 Mb [===                 ] 16% 1.4s\u001b[0K\u001b[1G78.7 Mb [====                ] 18% 1.3s\u001b[0K\u001b[1G78.7 Mb [====                ] 20% 1.2s\u001b[0K\u001b[1G78.7 Mb [=====               ] 22% 1.1s\u001b[0K\u001b[1G78.7 Mb [=====               ] 24% 1.0s\u001b[0K\u001b[1G78.7 Mb [=====               ] 26% 1.0s\u001b[0K\u001b[1G78.7 Mb [======              ] 28% 0.9s\u001b[0K\u001b[1G78.7 Mb [======              ] 30% 0.9s\u001b[0K\u001b[1G78.7 Mb [======              ] 32% 0.9s\u001b[0K\u001b[1G78.7 Mb [=======             ] 32% 0.9s\u001b[0K\u001b[1G78.7 Mb [=======             ] 34% 0.8s\u001b[0K\u001b[1G78.7 Mb [=======             ] 37% 0.8s\u001b[0K\u001b[1G78.7 Mb [========            ] 39% 0.7s\u001b[0K\u001b[1G78.7 Mb [========            ] 42% 0.7s\u001b[0K\u001b[1G78.7 Mb [=========           ] 44% 0.6s\u001b[0K\u001b[1G78.7 Mb [=========           ] 47% 0.6s\u001b[0K\u001b[1G78.7 Mb [==========          ] 49% 0.5s\u001b[0K\u001b[1G78.7 Mb [==========          ] 51% 0.5s\u001b[0K\u001b[1G78.7 Mb [===========         ] 54% 0.5s\u001b[0K\u001b[1G78.7 Mb [===========         ] 57% 0.4s\u001b[0K\u001b[1G78.7 Mb [============        ] 59% 0.4s\u001b[0K\u001b[1G78.7 Mb [============        ] 61% 0.4s\u001b[0K\u001b[1G78.7 Mb [=============       ] 64% 0.4s\u001b[0K\u001b[1G78.7 Mb [=============       ] 66% 0.3s\u001b[0K\u001b[1G78.7 Mb [==============      ] 68% 0.3s\u001b[0K\u001b[1G78.7 Mb [==============      ] 70% 0.3s\u001b[0K\u001b[1G78.7 Mb [==============      ] 72% 0.3s\u001b[0K\u001b[1G78.7 Mb [===============     ] 74% 0.2s\u001b[0K\u001b[1G78.7 Mb [===============     ] 77% 0.2s\u001b[0K\u001b[1G78.7 Mb [================    ] 80% 0.2s\u001b[0K\u001b[1G78.7 Mb [================    ] 81% 0.2s\u001b[0K\u001b[1G78.7 Mb [================    ] 82% 0.2s\u001b[0K\u001b[1G78.7 Mb [=================   ] 82% 0.2s\u001b[0K\u001b[1G78.7 Mb [=================   ] 84% 0.2s\u001b[0K\u001b[1G78.7 Mb [=================   ] 86% 0.1s\u001b[0K\u001b[1G78.7 Mb [==================  ] 89% 0.1s\u001b[0K\u001b[1G78.7 Mb [==================  ] 91% 0.1s\u001b[0K\u001b[1G78.7 Mb [=================== ] 92% 0.1s\u001b[0K\u001b[1G78.7 Mb [=================== ] 95% 0.0s\u001b[0K\u001b[1G78.7 Mb [====================] 98% 0.0s\u001b[0K\u001b[1G78.7 Mb [====================] 99% 0.0s\u001b[0K\u001b[1G78.7 Mb [====================] 100% 0.0s\u001b[0K\nFirefox 113.0 (playwright build v1408) downloaded to /root/.cache/ms-playwright/firefox-1408\nDownloading Webkit 16.4 (playwright build v1860)\u001b[2m from https://playwright.azureedge.net/builds/webkit/1860/webkit-ubuntu-20.04.zip\u001b[22m\n\u001b[1G114.5 Mb [                    ] 0% 0.0s\u001b[0K\u001b[1G114.5 Mb [                    ] 0% 23.6s\u001b[0K\u001b[1G114.5 Mb [                    ] 0% 18.1s\u001b[0K\u001b[1G114.5 Mb [                    ] 0% 11.3s\u001b[0K\u001b[1G114.5 Mb [                    ] 0% 8.6s\u001b[0K\u001b[1G114.5 Mb [                    ] 1% 5.8s\u001b[0K\u001b[1G114.5 Mb [                    ] 2% 4.3s\u001b[0K\u001b[1G114.5 Mb [=                   ] 3% 3.3s\u001b[0K\u001b[1G114.5 Mb [=                   ] 5% 2.6s\u001b[0K\u001b[1G114.5 Mb [=                   ] 6% 2.3s\u001b[0K\u001b[1G114.5 Mb [==                  ] 7% 2.0s\u001b[0K\u001b[1G114.5 Mb [==                  ] 9% 1.8s\u001b[0K\u001b[1G114.5 Mb [==                  ] 10% 1.6s\u001b[0K\u001b[1G114.5 Mb [==                  ] 11% 1.6s\u001b[0K\u001b[1G114.5 Mb [===                 ] 13% 1.5s\u001b[0K\u001b[1G114.5 Mb [===                 ] 14% 1.5s\u001b[0K\u001b[1G114.5 Mb [===                 ] 15% 1.6s\u001b[0K\u001b[1G114.5 Mb [===                 ] 16% 1.6s\u001b[0K\u001b[1G114.5 Mb [====                ] 17% 1.5s\u001b[0K\u001b[1G114.5 Mb [====                ] 18% 1.4s\u001b[0K\u001b[1G114.5 Mb [====                ] 20% 1.3s\u001b[0K\u001b[1G114.5 Mb [====                ] 21% 1.3s\u001b[0K\u001b[1G114.5 Mb [====                ] 22% 1.3s\u001b[0K\u001b[1G114.5 Mb [=====               ] 22% 1.3s\u001b[0K\u001b[1G114.5 Mb [=====               ] 24% 1.3s\u001b[0K\u001b[1G114.5 Mb [=====               ] 26% 1.2s\u001b[0K\u001b[1G114.5 Mb [======              ] 28% 1.1s\u001b[0K\u001b[1G114.5 Mb [======              ] 29% 1.1s\u001b[0K\u001b[1G114.5 Mb [======              ] 31% 1.1s\u001b[0K\u001b[1G114.5 Mb [=======             ] 32% 1.0s\u001b[0K\u001b[1G114.5 Mb [=======             ] 34% 1.0s\u001b[0K\u001b[1G114.5 Mb [=======             ] 35% 1.0s\u001b[0K\u001b[1G114.5 Mb [=======             ] 37% 1.0s\u001b[0K\u001b[1G114.5 Mb [========            ] 38% 0.9s\u001b[0K\u001b[1G114.5 Mb [========            ] 39% 0.9s\u001b[0K\u001b[1G114.5 Mb [========            ] 40% 0.9s\u001b[0K\u001b[1G114.5 Mb [========            ] 41% 0.9s\u001b[0K\u001b[1G114.5 Mb [========            ] 42% 0.9s\u001b[0K\u001b[1G114.5 Mb [=========           ] 42% 0.9s\u001b[0K\u001b[1G114.5 Mb [=========           ] 43% 0.9s\u001b[0K\u001b[1G114.5 Mb [=========           ] 44% 0.9s\u001b[0K\u001b[1G114.5 Mb [=========           ] 45% 0.9s\u001b[0K\u001b[1G114.5 Mb [=========           ] 46% 0.8s\u001b[0K\u001b[1G114.5 Mb [==========          ] 47% 0.8s\u001b[0K\u001b[1G114.5 Mb [==========          ] 47% 0.9s\u001b[0K\u001b[1G114.5 Mb [==========          ] 48% 0.9s\u001b[0K\u001b[1G114.5 Mb [==========          ] 49% 0.9s\u001b[0K\u001b[1G114.5 Mb [==========          ] 50% 0.8s\u001b[0K\u001b[1G114.5 Mb [==========          ] 52% 0.8s\u001b[0K\u001b[1G114.5 Mb [===========         ] 54% 0.8s\u001b[0K\u001b[1G114.5 Mb [===========         ] 55% 0.7s\u001b[0K\u001b[1G114.5 Mb [===========         ] 56% 0.7s\u001b[0K\u001b[1G114.5 Mb [============        ] 58% 0.7s\u001b[0K\u001b[1G114.5 Mb [============        ] 60% 0.7s\u001b[0K\u001b[1G114.5 Mb [============        ] 62% 0.6s\u001b[0K\u001b[1G114.5 Mb [=============       ] 63% 0.6s\u001b[0K\u001b[1G114.5 Mb [=============       ] 65% 0.6s\u001b[0K\u001b[1G114.5 Mb [=============       ] 66% 0.6s\u001b[0K\u001b[1G114.5 Mb [=============       ] 66% 0.5s\u001b[0K\u001b[1G114.5 Mb [==============      ] 68% 0.5s\u001b[0K\u001b[1G114.5 Mb [==============      ] 70% 0.5s\u001b[0K\u001b[1G114.5 Mb [==============      ] 71% 0.5s\u001b[0K\u001b[1G114.5 Mb [==============      ] 72% 0.4s\u001b[0K\u001b[1G114.5 Mb [===============     ] 74% 0.4s\u001b[0K\u001b[1G114.5 Mb [===============     ] 75% 0.4s\u001b[0K\u001b[1G114.5 Mb [===============     ] 76% 0.4s\u001b[0K\u001b[1G114.5 Mb [================    ] 77% 0.4s\u001b[0K\u001b[1G114.5 Mb [================    ] 78% 0.3s\u001b[0K\u001b[1G114.5 Mb [================    ] 79% 0.3s\u001b[0K\u001b[1G114.5 Mb [================    ] 81% 0.3s\u001b[0K\u001b[1G114.5 Mb [=================   ] 83% 0.3s\u001b[0K\u001b[1G114.5 Mb [=================   ] 84% 0.2s\u001b[0K\u001b[1G114.5 Mb [=================   ] 86% 0.2s\u001b[0K\u001b[1G114.5 Mb [==================  ] 88% 0.2s\u001b[0K\u001b[1G114.5 Mb [==================  ] 90% 0.1s\u001b[0K\u001b[1G114.5 Mb [==================  ] 91% 0.1s\u001b[0K\u001b[1G114.5 Mb [=================== ] 92% 0.1s\u001b[0K\u001b[1G114.5 Mb [=================== ] 93% 0.1s\u001b[0K\u001b[1G114.5 Mb [=================== ] 95% 0.1s\u001b[0K\u001b[1G114.5 Mb [====================] 97% 0.0s\u001b[0K\u001b[1G114.5 Mb [====================] 98% 0.0s\u001b[0K\u001b[1G114.5 Mb [====================] 99% 0.0s\u001b[0K\u001b[1G114.5 Mb [====================] 100% 0.0s\u001b[0K\nWebkit 16.4 (playwright build v1860) downloaded to /root/.cache/ms-playwright/webkit-1860\n/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nInstalling dependencies...\nHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]        \nGet:3 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]      \nGet:4 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]      \nGet:5 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [1227 B]    \nGet:6 https://packages.cloud.google.com/apt cloud-sdk InRelease [1620 B]       \nGet:7 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1599 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [4998 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4920 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [36.8 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\nGet:13 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1308 kB]\nErr:5 http://packages.cloud.google.com/apt gcsfuse-focal InRelease\n  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\nErr:6 https://packages.cloud.google.com/apt cloud-sdk InRelease\n  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\nGet:14 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [33.1 kB]\nGet:15 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [4801 kB]\nGet:16 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [4432 kB]\nFetched 22.6 MB in 4s (6345 kB/s)                          \nReading package lists... Done\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://packages.cloud.google.com/apt gcsfuse-focal InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: https://packages.cloud.google.com/apt cloud-sdk InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\nW: Failed to fetch http://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\nW: Failed to fetch https://packages.cloud.google.com/apt/dists/cloud-sdk/InRelease  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY C0BA5CE6DC6315A3\nW: Some index files failed to download. They have been ignored, or old ones used instead.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nNote, selecting 'libfontconfig1' instead of 'libfontconfig'\nlibatk1.0-0 is already the newest version (2.35.1-1ubuntu2).\nlibatk1.0-0 set to manually installed.\nlibatspi2.0-0 is already the newest version (2.36.0-2).\nlibatspi2.0-0 set to manually installed.\nlibcairo-gobject2 is already the newest version (1.16.0-4ubuntu1).\nlibcairo-gobject2 set to manually installed.\nlibcairo2 is already the newest version (1.16.0-4ubuntu1).\nlibcairo2 set to manually installed.\nlibepoxy0 is already the newest version (1.5.4-1).\nlibepoxy0 set to manually installed.\nlibevent-2.1-7 is already the newest version (2.1.11-stable-1).\nlibevent-2.1-7 set to manually installed.\nlibfontconfig1 is already the newest version (2.13.1-2ubuntu3).\nlibopus0 is already the newest version (1.3.1-0ubuntu1).\nlibopus0 set to manually installed.\nlibpango-1.0-0 is already the newest version (1.44.7-2ubuntu4).\nlibpango-1.0-0 set to manually installed.\nlibpangocairo-1.0-0 is already the newest version (1.44.7-2ubuntu4).\nlibpangocairo-1.0-0 set to manually installed.\nlibpangoft2-1.0-0 is already the newest version (1.44.7-2ubuntu4).\nlibpangoft2-1.0-0 set to manually installed.\nlibpng16-16 is already the newest version (1.6.37-2).\nlibpng16-16 set to manually installed.\nlibxcb-shm0 is already the newest version (1.14-2).\nlibxcb-shm0 set to manually installed.\nlibxcb1 is already the newest version (1.14-2).\nlibxcb1 set to manually installed.\nlibxcomposite1 is already the newest version (1:0.4.5-1).\nlibxcomposite1 set to manually installed.\nlibxcursor1 is already the newest version (1:1.2.0-2).\nlibxcursor1 set to manually installed.\nlibxdamage1 is already the newest version (1:1.1.5-2).\nlibxdamage1 set to manually installed.\nlibxext6 is already the newest version (2:1.3.4-0ubuntu1).\nlibxfixes3 is already the newest version (1:5.0.3-2).\nlibxfixes3 set to manually installed.\nlibxi6 is already the newest version (2:1.7.10-0ubuntu1).\nlibxi6 set to manually installed.\nlibxkbcommon0 is already the newest version (0.10.0-1).\nlibxkbcommon0 set to manually installed.\nlibxrandr2 is already the newest version (2:1.5.2-0ubuntu1).\nlibxrandr2 set to manually installed.\nlibxrender1 is already the newest version (1:0.9.10-1).\nlibxshmfence1 is already the newest version (1.3-1).\nlibxshmfence1 set to manually installed.\nlibxt6 is already the newest version (1:1.1.5-1).\nlibxt6 set to manually installed.\nlibflite1 is already the newest version (2.1-release-3).\nlibflite1 set to manually installed.\nlibx264-155 is already the newest version (2:0.155.2917+git0a84d98-2).\nlibx264-155 set to manually installed.\nlibasound2 is already the newest version (1.2.2-2.1ubuntu2.5).\nlibasound2 set to manually installed.\nlibatk-bridge2.0-0 is already the newest version (2.34.2-0ubuntu2~20.04.1).\nlibatk-bridge2.0-0 set to manually installed.\nlibdrm2 is already the newest version (2.4.107-8ubuntu1~20.04.2).\nlibdrm2 set to manually installed.\nlibgl1 is already the newest version (1.3.2-1~ubuntu0.20.04.2).\nlibgl1 set to manually installed.\nlibicu66 is already the newest version (66.1-2ubuntu2.1).\nlibicu66 set to manually installed.\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\nThe following additional packages will be installed:\n  dbus fonts-ubuntu gcc-10-base libaspell15 libcc1-0 libegl-mesa0\n  libfreetype-dev libfreetype6-dev libgcc-s1 libgdk-pixbuf2.0-common\n  libgfortran5 libglib2.0-bin libgomp1 libgtk-3-common libitm1\n  libjpeg-turbo8-dev liblsan0 libquadmath0 libsecret-common libstdc++6\n  libtsan0 libubsan1 xserver-common\nSuggested packages:\n  aspell cups-common libenchant-2-voikko libenchant-voikko freetype2-doc gvfs\nRecommended packages:\n  fonts-ipafont-mincho fonts-tlwg-loma aspell-en | aspell-dictionary\n  | aspell6a-dictionary enchant-2 enchant libgdk-pixbuf2.0-bin xdg-user-dirs\n  libgtk-3-bin gnome-shell | notification-daemon\nThe following NEW packages will be installed:\n  fonts-ipafont-gothic fonts-liberation fonts-noto-color-emoji\n  fonts-tlwg-loma-otf fonts-ubuntu fonts-wqy-zenhei libaspell15\n  libdbus-glib-1-2 libegl-mesa0 libegl1 libenchant-2-2 libenchant1c2a\n  libevdev2 libgbm1 libgles2 libgudev-1.0-0 libhyphen0 libnotify4 libopengl0\n  libsecret-1-0 libsecret-common libwayland-server0 libwebpdemux2 libwoff1\n  libxslt1.1 libxtst6 ttf-ubuntu-font-family ttf-unifont xfonts-cyrillic\n  xfonts-scalable\nThe following packages will be upgraded:\n  dbus gcc-10-base libatomic1 libcc1-0 libcups2 libdbus-1-3 libfreetype-dev\n  libfreetype6 libfreetype6-dev libgcc-s1 libgdk-pixbuf2.0-0\n  libgdk-pixbuf2.0-common libgfortran5 libglib2.0-0 libglib2.0-bin libgomp1\n  libgtk-3-0 libgtk-3-common libharfbuzz-icu0 libharfbuzz0b libitm1\n  libjpeg-turbo8 libjpeg-turbo8-dev liblsan0 libnspr4 libnss3 libopenjp2-7\n  libquadmath0 libsoup2.4-1 libstdc++6 libtsan0 libubsan1 libvpx6\n  libwayland-client0 libwayland-egl1 libwebp6 libx11-6 libx11-xcb1 libxml2\n  xserver-common xvfb\n41 upgraded, 30 newly installed, 0 to remove and 190 not upgraded.\nNeed to get 45.1 MB of archives.\nAfter this operation, 72.2 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 fonts-ipafont-gothic all 00303-18ubuntu1 [3526 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 fonts-wqy-zenhei all 0.9.45-7ubuntu1 [7468 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libatomic1 amd64 10.5.0-1ubuntu1~20.04 [9284 B]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libubsan1 amd64 10.5.0-1ubuntu1~20.04 [785 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libtsan0 amd64 10.5.0-1ubuntu1~20.04 [2016 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gcc-10-base amd64 10.5.0-1ubuntu1~20.04 [20.8 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libstdc++6 amd64 10.5.0-1ubuntu1~20.04 [501 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libquadmath0 amd64 10.5.0-1ubuntu1~20.04 [146 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 liblsan0 amd64 10.5.0-1ubuntu1~20.04 [835 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libitm1 amd64 10.5.0-1ubuntu1~20.04 [26.2 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgomp1 amd64 10.5.0-1ubuntu1~20.04 [102 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgfortran5 amd64 10.5.0-1ubuntu1~20.04 [737 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcc1-0 amd64 10.5.0-1ubuntu1~20.04 [48.8 kB]\nGet:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgcc-s1 amd64 10.5.0-1ubuntu1~20.04 [41.8 kB]\nGet:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 dbus amd64 1.12.16-2ubuntu2.3 [151 kB]\nGet:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdbus-1-3 amd64 1.12.16-2ubuntu2.3 [179 kB]\nGet:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-bin amd64 2.64.6-1~ubuntu20.04.9 [72.9 kB]\nGet:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-0 amd64 2.64.6-1~ubuntu20.04.9 [1290 kB]\nGet:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libxml2 amd64 2.9.10+dfsg-5ubuntu0.20.04.10 [640 kB]\nGet:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-6 amd64 2:1.6.9-2ubuntu1.6 [577 kB]\nGet:21 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-liberation all 1:1.07.4-11 [822 kB]\nGet:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 fonts-noto-color-emoji all 0~20200916-1~ubuntu20.04.1 [9940 kB]\nGet:23 http://archive.ubuntu.com/ubuntu focal/universe amd64 fonts-tlwg-loma-otf all 1:0.7.1-3 [98.8 kB]\nGet:24 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-ubuntu all 0.83-4ubuntu1 [1458 kB]\nGet:25 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libaspell15 amd64 0.60.8-1ubuntu0.1 [328 kB]\nGet:26 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcups2 amd64 2.3.1-9ubuntu1.9 [234 kB]\nGet:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libdbus-glib-1-2 amd64 0.110-5fakssync1 [59.1 kB]\nGet:28 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-server0 amd64 1.18.0-1ubuntu0.1 [31.3 kB]\nGet:29 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgbm1 amd64 21.2.6-0ubuntu0.1~20.04.2 [29.2 kB]\nGet:30 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-client0 amd64 1.18.0-1ubuntu0.1 [23.9 kB]\nGet:31 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-xcb1 amd64 2:1.6.9-2ubuntu1.6 [9448 B]\nGet:32 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libegl-mesa0 amd64 21.2.6-0ubuntu0.1~20.04.2 [96.3 kB]\nGet:33 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libenchant-2-2 amd64 2.2.8-1ubuntu0.20.04.1 [45.6 kB]\nGet:34 http://archive.ubuntu.com/ubuntu focal/universe amd64 libenchant1c2a amd64 1.6.0-11.3build1 [64.7 kB]\nGet:35 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libfreetype-dev amd64 2.10.1-2ubuntu0.4 [493 kB]\nGet:36 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libfreetype6-dev amd64 2.10.1-2ubuntu0.4 [9808 B]\nGet:37 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libfreetype6 amd64 2.10.1-2ubuntu0.4 [341 kB]\nGet:38 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgdk-pixbuf2.0-0 amd64 2.40.0+dfsg-3ubuntu0.5 [169 kB]\nGet:39 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgdk-pixbuf2.0-common all 2.40.0+dfsg-3ubuntu0.5 [4628 B]\nGet:40 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libharfbuzz0b amd64 2.6.4-1ubuntu4.3 [391 kB]\nGet:41 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-egl1 amd64 1.18.0-1ubuntu0.1 [5596 B]\nGet:42 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgtk-3-common all 3.24.20-0ubuntu1.2 [234 kB]\nGet:43 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgtk-3-0 amd64 3.24.20-0ubuntu1.2 [2620 kB]\nGet:44 http://archive.ubuntu.com/ubuntu focal/main amd64 libgudev-1.0-0 amd64 1:233-1 [14.0 kB]\nGet:45 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libharfbuzz-icu0 amd64 2.6.4-1ubuntu4.3 [5592 B]\nGet:46 http://archive.ubuntu.com/ubuntu focal/main amd64 libhyphen0 amd64 2.8.8-7 [27.0 kB]\nGet:47 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libjpeg-turbo8-dev amd64 2.0.3-0ubuntu1.20.04.3 [238 kB]\nGet:48 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libjpeg-turbo8 amd64 2.0.3-0ubuntu1.20.04.3 [118 kB]\nGet:49 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnotify4 amd64 0.7.9-1ubuntu3.20.04.2 [19.5 kB]\nGet:50 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnspr4 amd64 2:4.35-0ubuntu0.20.04.1 [108 kB]\nGet:51 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnss3 amd64 2:3.98-0ubuntu0.20.04.2 [1391 kB]\nGet:52 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsecret-common all 0.20.4-0ubuntu1 [3940 B]\nGet:53 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsecret-1-0 amd64 0.20.4-0ubuntu1 [110 kB]\nGet:54 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsoup2.4-1 amd64 2.70.0-1ubuntu0.5 [263 kB]\nGet:55 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libvpx6 amd64 1.8.2-1ubuntu0.4 [819 kB]\nGet:56 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwebp6 amd64 0.6.1-2ubuntu0.20.04.3 [185 kB]\nGet:57 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwebpdemux2 amd64 0.6.1-2ubuntu0.20.04.3 [9560 B]\nGet:58 http://archive.ubuntu.com/ubuntu focal/main amd64 libwoff1 amd64 1.0.2-1build2 [42.0 kB]\nGet:59 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libxslt1.1 amd64 1.1.34-4ubuntu0.20.04.3 [151 kB]\nGet:60 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\nGet:61 http://archive.ubuntu.com/ubuntu focal/universe amd64 ttf-ubuntu-font-family all 1:0.83-4ubuntu1 [10.2 kB]\nGet:62 http://archive.ubuntu.com/ubuntu focal/main amd64 ttf-unifont all 1:12.0.01-2 [3137 kB]\nGet:63 http://archive.ubuntu.com/ubuntu focal/universe amd64 xfonts-cyrillic all 1:1.0.4 [387 kB]\nGet:64 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-scalable all 1:1.0.3-1.1 [304 kB]\nGet:65 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.20 [28.1 kB]\nGet:66 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.20 [781 kB]\nGet:67 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libegl1 amd64 1.3.2-1~ubuntu0.20.04.2 [31.9 kB]\nGet:68 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libevdev2 amd64 1.9.0+dfsg-1ubuntu0.2 [31.6 kB]\nGet:69 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgles2 amd64 1.3.2-1~ubuntu0.20.04.2 [15.6 kB]\nGet:70 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libopengl0 amd64 1.3.2-1~ubuntu0.20.04.2 [29.2 kB]\nGet:71 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libopenjp2-7 amd64 2.3.1-1ubuntu4.20.04.4 [141 kB]\nFetched 45.1 MB in 3s (17.2 MB/s)        \nExtracting templates from packages: 100%\nSelecting previously unselected package fonts-ipafont-gothic.\n(Reading database ... 107293 files and directories currently installed.)\nPreparing to unpack .../0-fonts-ipafont-gothic_00303-18ubuntu1_all.deb ...\nUnpacking fonts-ipafont-gothic (00303-18ubuntu1) ...\nSelecting previously unselected package fonts-wqy-zenhei.\nPreparing to unpack .../1-fonts-wqy-zenhei_0.9.45-7ubuntu1_all.deb ...\nUnpacking fonts-wqy-zenhei (0.9.45-7ubuntu1) ...\nPreparing to unpack .../2-libatomic1_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libatomic1:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../3-libubsan1_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libubsan1:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../4-libtsan0_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libtsan0:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../5-gcc-10-base_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking gcc-10-base:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nSetting up gcc-10-base:amd64 (10.5.0-1ubuntu1~20.04) ...\n(Reading database ... 107314 files and directories currently installed.)\nPreparing to unpack .../libstdc++6_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libstdc++6:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nSetting up libstdc++6:amd64 (10.5.0-1ubuntu1~20.04) ...\n(Reading database ... 107314 files and directories currently installed.)\nPreparing to unpack .../0-libquadmath0_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libquadmath0:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../1-liblsan0_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking liblsan0:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../2-libitm1_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libitm1:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../3-libgomp1_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libgomp1:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../4-libgfortran5_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libgfortran5:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../5-libcc1-0_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libcc1-0:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nPreparing to unpack .../6-libgcc-s1_10.5.0-1ubuntu1~20.04_amd64.deb ...\nUnpacking libgcc-s1:amd64 (10.5.0-1ubuntu1~20.04) over (10.3.0-1ubuntu1~20.04) ...\nSetting up libgcc-s1:amd64 (10.5.0-1ubuntu1~20.04) ...\n(Reading database ... 107314 files and directories currently installed.)\nPreparing to unpack .../00-dbus_1.12.16-2ubuntu2.3_amd64.deb ...\nUnpacking dbus (1.12.16-2ubuntu2.3) over (1.12.16-2ubuntu2.2) ...\nPreparing to unpack .../01-libdbus-1-3_1.12.16-2ubuntu2.3_amd64.deb ...\nUnpacking libdbus-1-3:amd64 (1.12.16-2ubuntu2.3) over (1.12.16-2ubuntu2.2) ...\nPreparing to unpack .../02-libglib2.0-bin_2.64.6-1~ubuntu20.04.9_amd64.deb ...\nUnpacking libglib2.0-bin (2.64.6-1~ubuntu20.04.9) over (2.64.6-1~ubuntu20.04.4) ...\nPreparing to unpack .../03-libglib2.0-0_2.64.6-1~ubuntu20.04.9_amd64.deb ...\nUnpacking libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.9) over (2.64.6-1~ubuntu20.04.4) ...\nPreparing to unpack .../04-libxml2_2.9.10+dfsg-5ubuntu0.20.04.10_amd64.deb ...\nUnpacking libxml2:amd64 (2.9.10+dfsg-5ubuntu0.20.04.10) over (2.9.10+dfsg-5ubuntu0.20.04.4) ...\nPreparing to unpack .../05-libx11-6_2%3a1.6.9-2ubuntu1.6_amd64.deb ...\nUnpacking libx11-6:amd64 (2:1.6.9-2ubuntu1.6) over (2:1.6.9-2ubuntu1.2) ...\nSelecting previously unselected package fonts-liberation.\nPreparing to unpack .../06-fonts-liberation_1%3a1.07.4-11_all.deb ...\nUnpacking fonts-liberation (1:1.07.4-11) ...\nSelecting previously unselected package fonts-noto-color-emoji.\nPreparing to unpack .../07-fonts-noto-color-emoji_0~20200916-1~ubuntu20.04.1_all.deb ...\nUnpacking fonts-noto-color-emoji (0~20200916-1~ubuntu20.04.1) ...\nSelecting previously unselected package fonts-tlwg-loma-otf.\nPreparing to unpack .../08-fonts-tlwg-loma-otf_1%3a0.7.1-3_all.deb ...\nUnpacking fonts-tlwg-loma-otf (1:0.7.1-3) ...\nSelecting previously unselected package fonts-ubuntu.\nPreparing to unpack .../09-fonts-ubuntu_0.83-4ubuntu1_all.deb ...\nUnpacking fonts-ubuntu (0.83-4ubuntu1) ...\nSelecting previously unselected package libaspell15:amd64.\nPreparing to unpack .../10-libaspell15_0.60.8-1ubuntu0.1_amd64.deb ...\nUnpacking libaspell15:amd64 (0.60.8-1ubuntu0.1) ...\nPreparing to unpack .../11-libcups2_2.3.1-9ubuntu1.9_amd64.deb ...\nUnpacking libcups2:amd64 (2.3.1-9ubuntu1.9) over (2.3.1-9ubuntu1.2) ...\nSelecting previously unselected package libdbus-glib-1-2:amd64.\nPreparing to unpack .../12-libdbus-glib-1-2_0.110-5fakssync1_amd64.deb ...\nUnpacking libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSelecting previously unselected package libwayland-server0:amd64.\nPreparing to unpack .../13-libwayland-server0_1.18.0-1ubuntu0.1_amd64.deb ...\nUnpacking libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSelecting previously unselected package libgbm1:amd64.\nPreparing to unpack .../14-libgbm1_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\nUnpacking libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nPreparing to unpack .../15-libwayland-client0_1.18.0-1ubuntu0.1_amd64.deb ...\nUnpacking libwayland-client0:amd64 (1.18.0-1ubuntu0.1) over (1.18.0-1) ...\nPreparing to unpack .../16-libx11-xcb1_2%3a1.6.9-2ubuntu1.6_amd64.deb ...\nUnpacking libx11-xcb1:amd64 (2:1.6.9-2ubuntu1.6) over (2:1.6.9-2ubuntu1.2) ...\nSelecting previously unselected package libegl-mesa0:amd64.\nPreparing to unpack .../17-libegl-mesa0_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\nUnpacking libegl-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSelecting previously unselected package libenchant-2-2:amd64.\nPreparing to unpack .../18-libenchant-2-2_2.2.8-1ubuntu0.20.04.1_amd64.deb ...\nUnpacking libenchant-2-2:amd64 (2.2.8-1ubuntu0.20.04.1) ...\nSelecting previously unselected package libenchant1c2a:amd64.\nPreparing to unpack .../19-libenchant1c2a_1.6.0-11.3build1_amd64.deb ...\nUnpacking libenchant1c2a:amd64 (1.6.0-11.3build1) ...\nPreparing to unpack .../20-libfreetype-dev_2.10.1-2ubuntu0.4_amd64.deb ...\nUnpacking libfreetype-dev:amd64 (2.10.1-2ubuntu0.4) over (2.10.1-2ubuntu0.2) ...\nPreparing to unpack .../21-libfreetype6-dev_2.10.1-2ubuntu0.4_amd64.deb ...\nUnpacking libfreetype6-dev:amd64 (2.10.1-2ubuntu0.4) over (2.10.1-2ubuntu0.2) ...\nPreparing to unpack .../22-libfreetype6_2.10.1-2ubuntu0.4_amd64.deb ...\nUnpacking libfreetype6:amd64 (2.10.1-2ubuntu0.4) over (2.10.1-2ubuntu0.2) ...\nPreparing to unpack .../23-libgdk-pixbuf2.0-0_2.40.0+dfsg-3ubuntu0.5_amd64.deb ...\nUnpacking libgdk-pixbuf2.0-0:amd64 (2.40.0+dfsg-3ubuntu0.5) over (2.40.0+dfsg-3ubuntu0.4) ...\nPreparing to unpack .../24-libgdk-pixbuf2.0-common_2.40.0+dfsg-3ubuntu0.5_all.deb ...\nUnpacking libgdk-pixbuf2.0-common (2.40.0+dfsg-3ubuntu0.5) over (2.40.0+dfsg-3ubuntu0.4) ...\nPreparing to unpack .../25-libharfbuzz0b_2.6.4-1ubuntu4.3_amd64.deb ...\nUnpacking libharfbuzz0b:amd64 (2.6.4-1ubuntu4.3) over (2.6.4-1ubuntu4.2) ...\nPreparing to unpack .../26-libwayland-egl1_1.18.0-1ubuntu0.1_amd64.deb ...\nUnpacking libwayland-egl1:amd64 (1.18.0-1ubuntu0.1) over (1.18.0-1) ...\nPreparing to unpack .../27-libgtk-3-common_3.24.20-0ubuntu1.2_all.deb ...\nUnpacking libgtk-3-common (3.24.20-0ubuntu1.2) over (3.24.20-0ubuntu1.1) ...\nPreparing to unpack .../28-libgtk-3-0_3.24.20-0ubuntu1.2_amd64.deb ...\nUnpacking libgtk-3-0:amd64 (3.24.20-0ubuntu1.2) over (3.24.20-0ubuntu1.1) ...\nSelecting previously unselected package libgudev-1.0-0:amd64.\nPreparing to unpack .../29-libgudev-1.0-0_1%3a233-1_amd64.deb ...\nUnpacking libgudev-1.0-0:amd64 (1:233-1) ...\nPreparing to unpack .../30-libharfbuzz-icu0_2.6.4-1ubuntu4.3_amd64.deb ...\nUnpacking libharfbuzz-icu0:amd64 (2.6.4-1ubuntu4.3) over (2.6.4-1ubuntu4.2) ...\nSelecting previously unselected package libhyphen0:amd64.\nPreparing to unpack .../31-libhyphen0_2.8.8-7_amd64.deb ...\nUnpacking libhyphen0:amd64 (2.8.8-7) ...\nPreparing to unpack .../32-libjpeg-turbo8-dev_2.0.3-0ubuntu1.20.04.3_amd64.deb ...\nUnpacking libjpeg-turbo8-dev:amd64 (2.0.3-0ubuntu1.20.04.3) over (2.0.3-0ubuntu1.20.04.1) ...\nPreparing to unpack .../33-libjpeg-turbo8_2.0.3-0ubuntu1.20.04.3_amd64.deb ...\nUnpacking libjpeg-turbo8:amd64 (2.0.3-0ubuntu1.20.04.3) over (2.0.3-0ubuntu1.20.04.1) ...\nSelecting previously unselected package libnotify4:amd64.\nPreparing to unpack .../34-libnotify4_0.7.9-1ubuntu3.20.04.2_amd64.deb ...\nUnpacking libnotify4:amd64 (0.7.9-1ubuntu3.20.04.2) ...\nPreparing to unpack .../35-libnspr4_2%3a4.35-0ubuntu0.20.04.1_amd64.deb ...\nUnpacking libnspr4:amd64 (2:4.35-0ubuntu0.20.04.1) over (2:4.25-1) ...\nPreparing to unpack .../36-libnss3_2%3a3.98-0ubuntu0.20.04.2_amd64.deb ...\nUnpacking libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) over (2:3.49.1-1ubuntu1.8) ...\nSelecting previously unselected package libsecret-common.\nPreparing to unpack .../37-libsecret-common_0.20.4-0ubuntu1_all.deb ...\nUnpacking libsecret-common (0.20.4-0ubuntu1) ...\nSelecting previously unselected package libsecret-1-0:amd64.\nPreparing to unpack .../38-libsecret-1-0_0.20.4-0ubuntu1_amd64.deb ...\nUnpacking libsecret-1-0:amd64 (0.20.4-0ubuntu1) ...\nPreparing to unpack .../39-libsoup2.4-1_2.70.0-1ubuntu0.5_amd64.deb ...\nUnpacking libsoup2.4-1:amd64 (2.70.0-1ubuntu0.5) over (2.70.0-1) ...\nPreparing to unpack .../40-libvpx6_1.8.2-1ubuntu0.4_amd64.deb ...\nUnpacking libvpx6:amd64 (1.8.2-1ubuntu0.4) over (1.8.2-1build1) ...\nPreparing to unpack .../41-libwebp6_0.6.1-2ubuntu0.20.04.3_amd64.deb ...\nUnpacking libwebp6:amd64 (0.6.1-2ubuntu0.20.04.3) over (0.6.1-2ubuntu0.20.04.1) ...\nSelecting previously unselected package libwebpdemux2:amd64.\nPreparing to unpack .../42-libwebpdemux2_0.6.1-2ubuntu0.20.04.3_amd64.deb ...\nUnpacking libwebpdemux2:amd64 (0.6.1-2ubuntu0.20.04.3) ...\nSelecting previously unselected package libwoff1:amd64.\nPreparing to unpack .../43-libwoff1_1.0.2-1build2_amd64.deb ...\nUnpacking libwoff1:amd64 (1.0.2-1build2) ...\nSelecting previously unselected package libxslt1.1:amd64.\nPreparing to unpack .../44-libxslt1.1_1.1.34-4ubuntu0.20.04.3_amd64.deb ...\nUnpacking libxslt1.1:amd64 (1.1.34-4ubuntu0.20.04.3) ...\nSelecting previously unselected package libxtst6:amd64.\nPreparing to unpack .../45-libxtst6_2%3a1.2.3-1_amd64.deb ...\nUnpacking libxtst6:amd64 (2:1.2.3-1) ...\nSelecting previously unselected package ttf-ubuntu-font-family.\nPreparing to unpack .../46-ttf-ubuntu-font-family_1%3a0.83-4ubuntu1_all.deb ...\nUnpacking ttf-ubuntu-font-family (1:0.83-4ubuntu1) ...\nSelecting previously unselected package ttf-unifont.\nPreparing to unpack .../47-ttf-unifont_1%3a12.0.01-2_all.deb ...\nUnpacking ttf-unifont (1:12.0.01-2) ...\nSelecting previously unselected package xfonts-cyrillic.\nPreparing to unpack .../48-xfonts-cyrillic_1%3a1.0.4_all.deb ...\nUnpacking xfonts-cyrillic (1:1.0.4) ...\nSelecting previously unselected package xfonts-scalable.\nPreparing to unpack .../49-xfonts-scalable_1%3a1.0.3-1.1_all.deb ...\nUnpacking xfonts-scalable (1:1.0.3-1.1) ...\nPreparing to unpack .../50-xserver-common_2%3a1.20.13-1ubuntu1~20.04.20_all.deb ...\nUnpacking xserver-common (2:1.20.13-1ubuntu1~20.04.20) over (2:1.20.13-1ubuntu1~20.04.6) ...\nPreparing to unpack .../51-xvfb_2%3a1.20.13-1ubuntu1~20.04.20_amd64.deb ...\nUnpacking xvfb (2:1.20.13-1ubuntu1~20.04.20) over (2:1.20.13-1ubuntu1~20.04.6) ...\nSelecting previously unselected package libegl1:amd64.\nPreparing to unpack .../52-libegl1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\nUnpacking libegl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\nSelecting previously unselected package libevdev2:amd64.\nPreparing to unpack .../53-libevdev2_1.9.0+dfsg-1ubuntu0.2_amd64.deb ...\nUnpacking libevdev2:amd64 (1.9.0+dfsg-1ubuntu0.2) ...\nSelecting previously unselected package libgles2:amd64.\nPreparing to unpack .../54-libgles2_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\nUnpacking libgles2:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\nSelecting previously unselected package libopengl0:amd64.\nPreparing to unpack .../55-libopengl0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\nUnpacking libopengl0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\nPreparing to unpack .../56-libopenjp2-7_2.3.1-1ubuntu4.20.04.4_amd64.deb ...\nUnpacking libopenjp2-7:amd64 (2.3.1-1ubuntu4.20.04.4) over (2.3.1-1ubuntu4.20.04.1) ...\nSetting up libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSetting up libx11-xcb1:amd64 (2:1.6.9-2ubuntu1.6) ...\nSetting up libwoff1:amd64 (1.0.2-1build2) ...\nSetting up libhyphen0:amd64 (2.8.8-7) ...\nSetting up libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSetting up fonts-noto-color-emoji (0~20200916-1~ubuntu20.04.1) ...\nSetting up libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.9) ...\nSetting up libaspell15:amd64 (0.60.8-1ubuntu0.1) ...\nSetting up ttf-unifont (1:12.0.01-2) ...\nSetting up fonts-ubuntu (0.83-4ubuntu1) ...\nSetting up libgdk-pixbuf2.0-common (2.40.0+dfsg-3ubuntu0.5) ...\nSetting up fonts-wqy-zenhei (0.9.45-7ubuntu1) ...\nSetting up libenchant1c2a:amd64 (1.6.0-11.3build1) ...\nSetting up libglib2.0-bin (2.64.6-1~ubuntu20.04.9) ...\nSetting up libgomp1:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up libopengl0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\nSetting up libgles2:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\nSetting up fonts-tlwg-loma-otf (1:0.7.1-3) ...\nSetting up libfreetype6:amd64 (2.10.1-2ubuntu0.4) ...\nSetting up libnspr4:amd64 (2:4.35-0ubuntu0.20.04.1) ...\nSetting up libdbus-1-3:amd64 (1.12.16-2ubuntu2.3) ...\nSetting up dbus (1.12.16-2ubuntu2.3) ...\ndbus-uuidgen: /opt/conda/lib/libdbus-1.so.3: version `LIBDBUS_PRIVATE_1.12.16' not found (required by dbus-uuidgen)\ndpkg: error processing package dbus (--configure):\n installed dbus package post-installation script subprocess returned error exit status 1\nSetting up libquadmath0:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up libatomic1:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up libwebp6:amd64 (0.6.1-2ubuntu0.20.04.3) ...\nSetting up libjpeg-turbo8:amd64 (2.0.3-0ubuntu1.20.04.3) ...\nSetting up libgfortran5:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up libcups2:amd64 (2.3.1-9ubuntu1.9) ...\nSetting up libubsan1:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up fonts-ipafont-gothic (00303-18ubuntu1) ...\nupdate-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\nSetting up libvpx6:amd64 (1.8.2-1ubuntu0.4) ...\nSetting up xfonts-cyrillic (1:1.0.4) ...\nSetting up fonts-liberation (1:1.07.4-11) ...\nSetting up libopenjp2-7:amd64 (2.3.1-1ubuntu4.20.04.4) ...\nSetting up libx11-6:amd64 (2:1.6.9-2ubuntu1.6) ...\nSetting up libharfbuzz0b:amd64 (2.6.4-1ubuntu4.3) ...\nSetting up libwayland-egl1:amd64 (1.18.0-1ubuntu0.1) ...\nSetting up xserver-common (2:1.20.13-1ubuntu1~20.04.20) ...\nSetting up ttf-ubuntu-font-family (1:0.83-4ubuntu1) ...\nSetting up libevdev2:amd64 (1.9.0+dfsg-1ubuntu0.2) ...\nSetting up libxml2:amd64 (2.9.10+dfsg-5ubuntu0.20.04.10) ...\nSetting up libcc1-0:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up libgudev-1.0-0:amd64 (1:233-1) ...\nSetting up libsecret-common (0.20.4-0ubuntu1) ...\nSetting up liblsan0:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up xfonts-scalable (1:1.0.3-1.1) ...\nSetting up libgtk-3-common (3.24.20-0ubuntu1.2) ...\nSetting up libitm1:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up libtsan0:amd64 (10.5.0-1ubuntu1~20.04) ...\nSetting up libwayland-client0:amd64 (1.18.0-1ubuntu0.1) ...\nSetting up libjpeg-turbo8-dev:amd64 (2.0.3-0ubuntu1.20.04.3) ...\nSetting up libharfbuzz-icu0:amd64 (2.6.4-1ubuntu4.3) ...\nSetting up libsoup2.4-1:amd64 (2.70.0-1ubuntu0.5) ...\nSetting up libenchant-2-2:amd64 (2.2.8-1ubuntu0.20.04.1) ...\nSetting up libxtst6:amd64 (2:1.2.3-1) ...\nSetting up libwebpdemux2:amd64 (0.6.1-2ubuntu0.20.04.3) ...\nSetting up xvfb (2:1.20.13-1ubuntu1~20.04.20) ...\nSetting up libnss3:amd64 (2:3.98-0ubuntu0.20.04.2) ...\nSetting up libfreetype-dev:amd64 (2.10.1-2ubuntu0.4) ...\nSetting up libsecret-1-0:amd64 (0.20.4-0ubuntu1) ...\nSetting up libegl-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSetting up libdbus-glib-1-2:amd64 (0.110-5fakssync1) ...\nSetting up libgdk-pixbuf2.0-0:amd64 (2.40.0+dfsg-3ubuntu0.5) ...\nSetting up libxslt1.1:amd64 (1.1.34-4ubuntu0.20.04.3) ...\nSetting up libegl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\nSetting up libgtk-3-0:amd64 (3.24.20-0ubuntu1.2) ...\nSetting up libfreetype6-dev:amd64 (2.10.1-2ubuntu0.4) ...\nSetting up libnotify4:amd64 (0.7.9-1ubuntu3.20.04.2) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.17) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for fontconfig (2.13.1-2ubuntu3) ...\nErrors were encountered while processing:\n dbus\nE: Sub-process /usr/bin/dpkg returned an error code (1)\nFailed to install browser dependencies\nError: Installation process exited with code: 100\n20251103.0\n20251104.0\n20251105.0\n20251106.0\n20251107.0\n20251108.0\n20251109.0\n20251110.0\n20251111.0\n20251112.0\n20251113.0\n20251114.0\n20251115.0\ndropping rows\n1949.0\n1950.0\n1952.0\n1953.0\n1954.0\n1956.0\n1957.0\n1958.0\n1966.0\n1967.0\n1968.0\n1969.0\n1970.0\n1971.0\n1972.0\n1973.0\n1974.0\n1975.0\n1976.0\n1977.0\n1978.0\n1979.0\n1980.0\n1981.0\n1982.0\n1983.0\n1984.0\n1985.0\n1986.0\n1987.0\n1988.0\n1989.0\n1990.0\n1991.0\n1992.0\n1993.0\n1994.0\n1995.0\n1996.0\n1997.0\n1998.0\n1999.0\n2000.0\n2001.0\n2002.0\n2003.0\n2004.0\n2005.0\n2006.0\n2007.0\n2008.0\n2009.0\n2010.0\n2011.0\n2012.0\n2013.0\n2014.0\n2015.0\n2016.0\n2017.0\n2018.0\n2019.0\n2020.0\n2021.0\n2022.0\n2023.0\n2024.0\n2025.0\ncount new:119229\ndoing confy\n['Samford', 'UAB']\n['Manhattan', 'Fordham']\n['Loyola (IL)', 'DePaul']\n['DePaul', 'Illinois-Chicago']\n['Grambling', 'Centenary (LA)']\n['Chicago State', 'Illinois-Chicago']\n['Loyola (IL)', 'Chicago State']\n['Fordham', 'Columbia']\n['Columbia', 'Manhattan']\n['East Carolina', 'Furman']\n['San Diego State', 'San Diego']\n['Butler', 'IUPUI']\n['Louisiana State', 'Southern']\n['UCLA', 'Southern California']\n['Southern California', 'Loyola Marymount']\n['UCLA', 'Loyola Marymount']\n[\"St. John's (NY)\", 'Manhattan']\n['Lipscomb', 'Belmont']\n['Lipscomb', 'Tennessee State']\n['Belmont', 'Vanderbilt']\n['Delaware', 'NJIT']\n['Vanderbilt', 'Lipscomb']\n['Fordham', \"St. John's (NY)\"]\n['Columbia', \"St. John's (NY)\"]\n['St. Francis (NY)', \"St. John's (NY)\"]\n['St. Francis (NY)', 'Columbia']\n['Southern Indiana', 'Evansville']\n['Manhattan', \"St. John's (NY)\"]\n['Duke', 'North Carolina Central']\n['Charleston Southern', 'College of Charleston']\n['Fordham', 'St. Francis (NY)']\n['Le Moyne', 'Syracuse']\n['North Carolina A&T', 'UNC Greensboro']\n['Charlotte', 'Queens (NC)']\n['Wake Forest', 'Winston-Salem']\n['Florida State', 'Florida A&M']\n['Washington (MO)', 'Saint Louis']\n['Baltimore', 'Loyola (MD)']\n['Baltimore', 'Coppin State']\n['Baltimore', 'Morgan State']\n['New Orleans', 'Loyola (LA)']\n['Loyola (LA)', 'Tulane']\n['Tulane', 'New Orleans']\n['Northeastern Illinois', 'Chicago State']\n['Northeastern Illinois', 'DePaul']\n['Northeastern Illinois', 'Illinois-Chicago']\n['Georgia Tech', 'Morris Brown']\n['Georgia State', 'Morris Brown']\n['Catholic', 'American']\n['Catholic', 'George Washington']\n['Catholic', 'Georgetown']\n['Catholic', 'Howard']\n[\"St. John's (NY)\", 'Wagner']\n['Fordham', 'Wagner']\n['Columbia', 'Wagner']\n['Sacred Heart', 'Fairfield']\n['Cal State Los Angeles', 'Southern California']\n['San Diego State', 'UC San Diego']\n['San Diego', 'UC San Diego']\n['Cal State Los Angeles', 'Loyola Marymount']\n['Cal State Los Angeles', 'UCLA']\n['U.S. International', 'San Diego']\n['St. Francis (NY)', 'Wagner']\n['U.S. International', 'San Diego State']\n['Southern Indiana', 'Evansville']\n['Wagner', 'Columbia']\n['St. Francis (NY)', 'Manhattan']\n['Howard', 'Georgetown']\n['Howard', 'George Washington']\n['Howard', 'American']\n['Georgetown', 'George Washington']\n['American', 'Georgetown']\n['Howard', 'Georgetown']\n['Jacksonville', 'North Florida']\n['Georgia Tech', 'Georgia State']\n['Houston', 'Texas Southern']\n['Houston', 'Rice']\n['Houston', 'Houston Christian']\n['Rice', 'Houston Christian']\n['Rice', 'Texas Southern']\n['Houston Christian', 'Texas Southern']\n['DePaul', 'Chicago State']\n['Louisville', 'Bellarmine']\n['Harvard', 'Boston University']\n['Harvard', 'Northeastern']\n['College of Charleston', 'The Citadel']\n['Boston University', 'Northeastern']\n['Morgan State', 'Loyola (MD)']\n['Coppin State', 'Morgan State']\n['Coppin State', 'Loyola (MD)']\n['Creighton', 'Omaha']\n['Tulsa', 'Oral Roberts']\n['Portland', 'Portland State']\n[\"Saint Joseph's\", 'Temple']\n['Temple', 'Pennsylvania']\n[\"Saint Joseph's\", 'Pennsylvania']\n['Temple', 'La Salle']\n[\"Saint Joseph's\", 'La Salle']\n['La Salle', 'Pennsylvania']\n['La Salle', 'Drexel']\n['Drexel', 'Pennsylvania']\n[\"Saint Joseph's\", 'Drexel']\n['Drexel', 'Temple']\n['Brown', 'Providence']\n['South Carolina Upstate', 'Wofford']\n['Vanderbilt', 'Tennessee State']\n['Vanderbilt', 'Belmont']\n['Belmont', 'Tennessee State']\n['Trinity (TX)', 'UTSA']\n['Furman', 'East Carolina']\n['UTSA', 'Incarnate Word']\n['Abilene Christian', 'Hardin-Simmons']\n['Washington & Lee', 'Virginia Military Institute']\n['Richmond', 'Virginia Commonwealth']\n['Old Dominion', 'Norfolk State']\n['Washington', 'Seattle']\n['Milwaukee', 'Marquette']\n['Manhattan', 'New York University']\n['St. Francis (NY)', 'New York University']\n[\"St. John's (NY)\", 'New York University']\n['Fordham', 'New York University']\n['Columbia', 'New York University']\n['New York University', 'City College of New York']\n['Manhattan', 'City College of New York']\n['Fordham', 'City College of New York']\n['Columbia', 'City College of New York']\n[\"St. John's (NY)\", 'City College of New York']\n['UC Riverside', 'California Baptist']\n['Pittsburgh', 'Duquesne']\n['Long Island University', 'Manhattan']\n['Long Island University', \"St. John's (NY)\"]\n['Long Island University', 'St. Francis (NY)']\n['Long Island University', 'Columbia']\n['Long Island University', 'Fordham']\n['Long Island University', 'Wagner']\n['Long Island University', 'Brooklyn']\n['Wagner', 'Brooklyn']\n['St. Francis (NY)', 'Brooklyn']\n[\"St. John's (NY)\", 'Brooklyn']\n['New York University', 'Brooklyn']\n['City College of New York', 'Brooklyn']\n['Manhattan', 'Brooklyn']\n['New York University', 'Long Island University']\n['City College of New York', 'Long Island University']\n['Columbia', 'Brooklyn']\n['Fordham', 'Brooklyn']\n['Xavier', 'Cincinnati']\ndropping\ndone dropping\n1950.0 yes\n1951.0 yes\n1952.0 yes\n1953.0 yes\n1954.0 yes\n1955.0 yes\n1956.0 yes\n1957.0 yes\n1958.0 yes\n1959.0 yes\n1960.0 yes\n1961.0 yes\n1962.0 yes\n1963.0 yes\n1964.0 yes\n1965.0 yes\n1966.0 yes\n1967.0 yes\n1968.0 yes\n1969.0 yes\n1970.0 yes\n1971.0 yes\n1972.0 yes\n1973.0 yes\n1974.0 yes\n1975.0 yes\n1976.0 yes\n1977.0 yes\n1978.0 yes\n1979.0 yes\n1980.0 yes\n1981.0 yes\n1982.0 yes\n1983.0 yes\n1984.0 yes\n1985.0 yes\n1986.0 yes\n1987.0 yes\n1988.0 yes\n1989.0 yes\n1990.0 yes\n1991.0 yes\n1992.0 yes\n1993.0 yes\n1994.0 yes\n1995.0 yes\n1996.0 yes\n1997.0 yes\n1998.0 yes\n1999.0 yes\n2000.0 yes\n2001.0 yes\n2002.0 yes\n2003.0 yes\n2004.0 yes\n2005.0 yes\n2006.0 yes\n2007.0 yes\n2008.0 yes\n2009.0 yes\n2010.0 yes\n2011.0 yes\n2012.0 yes\n2013.0 yes\n2014.0 yes\n2015.0 yes\n2016.0 yes\n2017.0 yes\n2018.0 yes\n2019.0 yes\n2020.0 yes\n2021.0 yes\n2022.0 yes\n2023.0 yes\n2024.0 yes\n2025.0 yes\n--- 581.6673619747162 seconds ---\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df22[df22.t1==\"Texas A&M-Corpus Christi\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:26:09.562305Z","iopub.execute_input":"2025-11-16T19:26:09.562820Z","iopub.status.idle":"2025-11-16T19:26:09.622041Z","shell.execute_reply.started":"2025-11-16T19:26:09.562784Z","shell.execute_reply":"2025-11-16T19:26:09.620290Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"              date                        t1                       t2   t1p  \\\n241680  19720108.0  Texas A&M-Corpus Christi           Tennessee Tech  85.0   \n241681  19720210.0  Texas A&M-Corpus Christi  Texas-Rio Grande Valley  81.0   \n242415  19720215.0  Texas A&M-Corpus Christi                  Houston  70.0   \n241679  19720227.0  Texas A&M-Corpus Christi              North Texas  77.0   \n241682  19720303.0  Texas A&M-Corpus Christi  Texas-Rio Grande Valley  86.0   \n...            ...                       ...                      ...   ...   \n486877  20250215.0  Texas A&M-Corpus Christi           Incarnate Word  69.0   \n486980  20250217.0  Texas A&M-Corpus Christi        Houston Christian  68.0   \n487588  20250301.0  Texas A&M-Corpus Christi   Southeastern Louisiana  68.0   \n487663  20250303.0  Texas A&M-Corpus Christi              New Orleans  95.0   \n487950  20250309.0  Texas A&M-Corpus Christi        Houston Christian  62.0   \n\n         t2p venue  season neutral     hj  isnon    predt1s  \n241680  84.0    vs  1972.0   False  False  False   1.317097  \n241681  72.0    vs  1972.0   False  False  False   4.017891  \n242415  82.0     @  1972.0   False  False  False -16.904136  \n241679  83.0     @  1972.0   False  False  False -10.904519  \n241682  80.0     @  1972.0   False  False  False  -4.011200  \n...      ...   ...     ...     ...    ...    ...        ...  \n486877  55.0    vs  2024.0   False  False  False   8.198067  \n486980  62.0    vs  2024.0   False  False  False   8.550112  \n487588  54.0    vs  2024.0   False  False  False   3.599397  \n487663  62.0    vs  2024.0   False  False  False  14.835694  \n487950  48.0    vs  2024.0    True  False  False   5.533053  \n\n[339 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>t1</th>\n      <th>t2</th>\n      <th>t1p</th>\n      <th>t2p</th>\n      <th>venue</th>\n      <th>season</th>\n      <th>neutral</th>\n      <th>hj</th>\n      <th>isnon</th>\n      <th>predt1s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>241680</th>\n      <td>19720108.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Tennessee Tech</td>\n      <td>85.0</td>\n      <td>84.0</td>\n      <td>vs</td>\n      <td>1972.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1.317097</td>\n    </tr>\n    <tr>\n      <th>241681</th>\n      <td>19720210.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Texas-Rio Grande Valley</td>\n      <td>81.0</td>\n      <td>72.0</td>\n      <td>vs</td>\n      <td>1972.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>4.017891</td>\n    </tr>\n    <tr>\n      <th>242415</th>\n      <td>19720215.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Houston</td>\n      <td>70.0</td>\n      <td>82.0</td>\n      <td>@</td>\n      <td>1972.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>-16.904136</td>\n    </tr>\n    <tr>\n      <th>241679</th>\n      <td>19720227.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>North Texas</td>\n      <td>77.0</td>\n      <td>83.0</td>\n      <td>@</td>\n      <td>1972.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>-10.904519</td>\n    </tr>\n    <tr>\n      <th>241682</th>\n      <td>19720303.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Texas-Rio Grande Valley</td>\n      <td>86.0</td>\n      <td>80.0</td>\n      <td>@</td>\n      <td>1972.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>-4.011200</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>486877</th>\n      <td>20250215.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Incarnate Word</td>\n      <td>69.0</td>\n      <td>55.0</td>\n      <td>vs</td>\n      <td>2024.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>8.198067</td>\n    </tr>\n    <tr>\n      <th>486980</th>\n      <td>20250217.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Houston Christian</td>\n      <td>68.0</td>\n      <td>62.0</td>\n      <td>vs</td>\n      <td>2024.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>8.550112</td>\n    </tr>\n    <tr>\n      <th>487588</th>\n      <td>20250301.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Southeastern Louisiana</td>\n      <td>68.0</td>\n      <td>54.0</td>\n      <td>vs</td>\n      <td>2024.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>3.599397</td>\n    </tr>\n    <tr>\n      <th>487663</th>\n      <td>20250303.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>New Orleans</td>\n      <td>95.0</td>\n      <td>62.0</td>\n      <td>vs</td>\n      <td>2024.0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>14.835694</td>\n    </tr>\n    <tr>\n      <th>487950</th>\n      <td>20250309.0</td>\n      <td>Texas A&amp;M-Corpus Christi</td>\n      <td>Houston Christian</td>\n      <td>62.0</td>\n      <td>48.0</td>\n      <td>vs</td>\n      <td>2024.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>5.533053</td>\n    </tr>\n  </tbody>\n</table>\n<p>339 rows × 11 columns</p>\n</div>"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"k=k.replace(\"Michigan St.\",\"Michigan State\")\nk['home']=k['home'].str.replace(\" St.\",\" State\")\nk['away']=k['away'].str.replace(\" St.\",\" State\")\nk=k.replace(\"IU Indy\",\"IUPUI\")\nk=k.replace(\"Fresno St\",\"Fresno State\")\nk=k.replace(\"Alcorn St.\",\"Alcorn State\")\nk=k.replace(\"UNLV\",\"Nevada-Lad Vegas\")\nk=k.replace(\"Arkansas St.\",\"Arkansas State\")\nk=k.replace(\"Mississippi St.\",\"Mississippi State\")\nk=k.replace(\"Queens\",\"Queens (NC)\")\nk=k.replace(\"BYU\",\"Brigham Young\")\nk=k.replace(\"Charleston\",\"College of Charleston\")\nk=k.replace(\"Arizona St.\",\"Arizona State\")\nk=k.replace(\"Arkansas Pine Bluff\",\"Arkansas-Pine Bluff\")\nk=k.replace(\"Albany\",\"Albany (NY)\")\nk=k.replace(\"Dixie State\",\"Utah Tech\")\nk=k.replace(\"Central Connecticut\",\"Central Connecticut State\")\nk=k.replace(\"Cal Baptist\",\"California Baptist\")\nk=k.replace(\"Bethune Cookman\",\"Bethune-Cookman\")\nk['home']=k['home'].str.replace(\" Statetete\",\" State\")\nk['away']=k['away'].str.replace(\" Statetete\",\" State\")\nk['home']=k['home'].str.replace(\" Statete\",\" State\")\nk=k.replace(\"East Texas A&M\",\"Texas A&M-Commerce\")\nk['away']=k['away'].str.replace(\" Statete\",\" State\")\nk=k.replace(\"Nevada-Lad Vegas\",\"Nevada-Las Vegas\")\nk=k.replace(\"Fairleigh Dickinson\",\"FDU\")\nk=k.replace(\"FIU\",\"Florida International\")\nk=k.replace(\"Illinois Chicago\",\"Illinois-Chicago\")\nk=k.replace(\"Grambling State\",\"Grambling\")\nk=k.replace(\"LSU\",\"Louisiana State\")\nk=k.replace(\"LIU\",\"Long Island University\")\nk=k.replace(\"N.C. State\",\"NC State\")\nk=k.replace(\"Maryland Eastern Shore\",\"Maryland-Eastern Shore\")\nk=k.replace(\"Miami OH\",\"Miami (OH)\")\nk=k.replace(\"Miami FL\",\"Miami (FL)\")\nk=k.replace(\"Louisiana Monroe\",\"Louisiana-Monroe\")\nk=k.replace(\"Lindenwood (MO)\",\"Lindenwood\")\nk=k.replace(\"Loyola MD\",\"Loyola (MD)\")\nk=k.replace(\"Texas A&M Corpus Chris\",\"Texas A&M-Corpus Christi\")\nk=k.replace(\"SMU\",\"Southern Methodist\")\nk=k.replace(\"Penn\",\"Pennsylvania\")\nk=k.replace(\"Prairie View A&M\",\"Prairie View\")\nk=k.replace(\"Mount State Mary's\",\"Mount St. Mary's\")\nk=k.replace(\"Nebraska Omaha\",\"Omaha\")\nk=k.replace(\"St. John's\",\"St. John's (NY)\")\nk=k.replace(\"Saint Mary's\",\"Saint Mary's (CA)\")\nk=k.replace(\"Southern Miss\",\"Southern Mississippi\")\nk=k.replace(\"Texas A&M Commerce\",\"Texas A&M-Commerce\")\nk=k.replace(\"SIU Edwardsville\",\"Southern Illinois-Edwardsville\")\nk=k.replace(\"Sam Houston State\",\"Sam Houston\")\nk=k.replace(\"Loyola Chicago\",\"Loyola (IL)\")\nk=k.replace(\"Tennessee Martin\",\"Tennessee-Martin\")\nk=k.replace(\"UT Rio Grande Valley\",\"Texas-Rio Grande Valley\")\nk=k.replace(\"UMBC\",\"Maryland-Baltimore County\")\nk=k.replace(\"UIndy\",\"IUPUI\")\nk=k.replace(\"USC\",\"Southern California\")\nk=k.replace(\"UMass Lowell\",\"Massachusetts-Lowell\")\nk=k.replace(\"UMKC\",\"Kansas City\")\nk=k.replace(\"USC Upstate\",\"South Carolina Upstate\")\nk=k.replace(\"UMBC\",\"Maryland-Baltimore County\")\ntz=set(k.home.tolist()+k.away.tolist())\nop=[]\ntzz=set(df22.t1.tolist()+df22.t2.tolist())\nfor t in tz:\n    if t not in tzz:\n        op.append(t)\nfor u in op:\n    if u[0]=='U':\n        print(u)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:28:22.565254Z","iopub.execute_input":"2025-11-16T19:28:22.565811Z","iopub.status.idle":"2025-11-16T19:28:23.968023Z","shell.execute_reply.started":"2025-11-16T19:28:22.565766Z","shell.execute_reply":"2025-11-16T19:28:23.966738Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n  This is separate from the ipykernel package so we can avoid doing imports until\n","output_type":"stream"},{"name":"stdout","text":"University of the South\nUMass Boston\nUniversity of Chicago\nUnion TN\nUrbana\nUC Merced\nUniv. of the Virgin Islands\nUniversity of Great Falls\nUHSP\nUC Santa Cruz\nUniversity of the Ozarks\nUNC Wesleyan\nUnion (NY)\nUVa-Wise\nUnion Commonwealth\nUT Tyler\nUniversity of Mary\nUnion\nUW-River Falls\nUNT Dallas\nU New England\nUC Clermont\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"from datetime import date\nprint(date.today())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:22:25.702385Z","iopub.execute_input":"2025-11-15T20:22:25.703542Z","iopub.status.idle":"2025-11-15T20:22:25.738320Z","shell.execute_reply.started":"2025-11-15T20:22:25.703412Z","shell.execute_reply":"2025-11-15T20:22:25.737059Z"}},"outputs":[{"name":"stdout","text":"2025-11-15\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"row","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T01:13:02.298456Z","iopub.execute_input":"2025-11-14T01:13:02.298829Z","iopub.status.idle":"2025-11-14T01:13:02.305421Z","shell.execute_reply.started":"2025-11-14T01:13:02.298781Z","shell.execute_reply":"2025-11-14T01:13:02.304168Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nk=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/finalbart.csv\")\nk.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T23:32:24.801924Z","iopub.execute_input":"2025-11-05T23:32:24.802320Z","iopub.status.idle":"2025-11-05T23:32:25.961296Z","shell.execute_reply.started":"2025-11-05T23:32:24.802289Z","shell.execute_reply":"2025-11-05T23:32:25.959895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confs[2025]['Princeton']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T00:10:10.858498Z","iopub.execute_input":"2025-11-07T00:10:10.858880Z","iopub.status.idle":"2025-11-07T00:10:10.867726Z","shell.execute_reply.started":"2025-11-07T00:10:10.858851Z","shell.execute_reply":"2025-11-07T00:10:10.866243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"k=df22[df22.season==2025]\nio=0\nfor row in k.itertuples():\n    if confs[2025][row.t1]=='SWAC' or confs[2025][row.t2]=='SWAC':\n        hj=str(row.t1)+str(\"    \")+str(row.t2)+\"      \"+str(row.predt1s)\n        print(hj)\n        io+=1\nprint(io)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T01:54:37.724520Z","iopub.execute_input":"2025-11-14T01:54:37.724849Z","iopub.status.idle":"2025-11-14T01:54:37.737659Z","shell.execute_reply.started":"2025-11-14T01:54:37.724823Z","shell.execute_reply":"2025-11-14T01:54:37.736368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"jk=df22[df22.season==2025]\ns='Arkansas-Pine Bluff'\njk[(jk.t1==s)|(jk.t2==s)]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-14T03:19:35.788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install media-downloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T03:23:12.105014Z","iopub.execute_input":"2025-11-14T03:23:12.105431Z","iopub.status.idle":"2025-11-14T03:23:24.915586Z","shell.execute_reply.started":"2025-11-14T03:23:12.105398Z","shell.execute_reply":"2025-11-14T03:23:24.914076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import library\nfrom media_downloader import MediaDownloader\n\n# Set URL of video/audio here\nurl = \"https://rumble.com/v6xfw7u-tribute-video-honoring-the-great-dr.-edwin-j.-feulner.html\"\n\n# Instantiate vide_downloader_instance\nvideo_downloader_instance = MediaDownloader()\n\n# Set the location to save the video\nvideo_downloader_instance.set_save_path(\"a.mp4\")\n\n# Add URL to download\nvideo_downloader_instance.append_link(url)\n\n# Download all videos appended\nvideo_downloader_instance.download_all()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T03:23:36.736454Z","iopub.execute_input":"2025-11-14T03:23:36.736868Z","iopub.status.idle":"2025-11-14T03:23:38.624706Z","shell.execute_reply.started":"2025-11-14T03:23:36.736836Z","shell.execute_reply":"2025-11-14T03:23:38.622905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"1","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-14T03:20:58.841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s='Alabama A&M'\nfg=hfas[confs[2025][s]]\nhr=eloLeague.ratingDict[s]+confy[confs[2025][s]]+fg\nar=eloLeague.ratingDict['Lindenwood']+confy['OVC']\ns=(hr-ar)/20\nspread=s+3.4\nspread=spread/2\nspread","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T18:53:31.275543Z","iopub.execute_input":"2025-11-16T18:53:31.276135Z","iopub.status.idle":"2025-11-16T18:53:31.290443Z","shell.execute_reply.started":"2025-11-16T18:53:31.276097Z","shell.execute_reply":"2025-11-16T18:53:31.289061Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"0.18078777373088428"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"s='Howard'\nrt=df22[df22.season==2025]\nrt[(rt.t1==s)|(rt.t2==s)]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-07T02:07:54.850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ci=0\nwrong=['2014.0ColgateArmy6365','2014.0ArmyColgate6563']\nwrong.append(['2014.0Mississippi Valley StateAlcorn State7462'])\nwrong.append(['2014.0Alcorn StateMississippi Valley State6274'])\nwrong.append(['2015.0Texas SouthernAlabama A&M7168'])\nwrong.append(['2015.0Alabama A&MTexas Southern6871'])\nwrong.append(['2015.0Texas SouthernAlabama A&M7166'])\nwrong.append(['2015.0Alabama A&MTexas Southern6671'])\nwrong.append(['2015.0Idaho StateIdaho7080'])\nwrong.append(['2015.0IdahoIdaho State8070'])\nwrong.append(['2015.0Idaho StateIdaho6882'])\nwrong.append(['2018.0OaklandIUPUI7463'])\nwrong.append(['2017.0Northern ColoradoUC Davis5972'])\nwrong.append(['2017.0UC DavisNorthern Colorado7259'])\nwrong.append(['2015.0IdahoIdaho State8268'])\nwrong.append(['2017.0WashingtonLoyola Marymount8078'])\nwrong.append(['2017.0Loyola MarymountWashington7880'])\nwrong.append(['2018.0IUPUIOakland6374'])\nwrong.append(['2019.0Texas A&M-Corpus ChristiSam Houston7460'])\nwrong.append(['2019.0Sam HoustonTexas A&M-Corpus Christi6074'])\nfor key in gszz:\n    if key not in gsz and key not in wrong:\n        print(key,ci)\n        ci+=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T01:21:50.339859Z","iopub.execute_input":"2025-11-03T01:21:50.340256Z","iopub.status.idle":"2025-11-03T01:21:54.892267Z","shell.execute_reply.started":"2025-11-03T01:21:50.340224Z","shell.execute_reply":"2025-11-03T01:21:54.890608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gj={}\ngjj={}\nyu=df22[df22.hj==False]\nyu=yu.drop_duplicates()\nyu=yu[yu.season>2013]\nprint(len(yu))\nj=df22[df22.hj==True]\nj=j.drop_duplicates()\nprint(len(j))\nfor i in range(2014,2025):\n    gj[float(i)]={}\n    gjj[float(i)]={}\nfor row in j.itertuples():\n    if row.t1 not in gj[float(row.season)]:\n        gj[float(row.season)][row.t1]=0\n    gj[float(row.season)][row.t1]+=1\n    if row.t2 not in gj[float(row.season)]:\n        gj[float(row.season)][row.t2]=0\n    gj[float(row.season)][row.t2]+=1\nfor row in yu.itertuples():\n    if row.t1 not in gjj[float(row.season)]:\n        gjj[float(row.season)][row.t1]=0\n    gjj[float(row.season)][row.t1]+=1\n    if row.t2 not in gjj[float(row.season)]:\n        gjj[float(row.season)][row.t2]=0\n    gjj[float(row.season)][row.t2]+=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T03:37:16.984552Z","iopub.execute_input":"2025-11-03T03:37:16.984910Z","iopub.status.idle":"2025-11-03T03:37:17.890439Z","shell.execute_reply.started":"2025-11-03T03:37:16.984884Z","shell.execute_reply":"2025-11-03T03:37:17.889258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for key in gj:\n    for t in gj[key]:\n        if gj[key][t]!=gjj[key][t]:\n            print(key,t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T03:37:32.285852Z","iopub.execute_input":"2025-11-03T03:37:32.286260Z","iopub.status.idle":"2025-11-03T03:37:32.294412Z","shell.execute_reply.started":"2025-11-03T03:37:32.286227Z","shell.execute_reply":"2025-11-03T03:37:32.293207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nyu=df22[df22.hj==False]\nyu=yu.drop_duplicates()\nyu=yu[yu.season>2013]\nprint(len(yu))\nj=df22[df22.hj==True]\nj=j.drop_duplicates()\nprint(len(j))\nu=j[j.season==2017]\nt='Hampton'\nu=u[(u.t1==t)|(u.t2==t)]\nuu=yu[yu.season==2017]\nuu=uu[(uu.t1==t)|(uu.t2==t)]\nprint(len(u),len(uu))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T03:37:54.350882Z","iopub.execute_input":"2025-11-03T03:37:54.351304Z","iopub.status.idle":"2025-11-03T03:37:54.769674Z","shell.execute_reply.started":"2025-11-03T03:37:54.351270Z","shell.execute_reply":"2025-11-03T03:37:54.767955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for k in gj:\n    if k not in gjj:\n        print(k)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T01:23:39.782614Z","iopub.execute_input":"2025-11-03T01:23:39.783023Z","iopub.status.idle":"2025-11-03T01:23:56.386795Z","shell.execute_reply.started":"2025-11-03T01:23:39.782990Z","shell.execute_reply":"2025-11-03T01:23:56.383966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ne=pd.read_html(\"https://basketball.fandom.com/wiki/List_of_NCAA_Division_I_Schools\")\nteams=[]\ni=1\nwhile(i<len(e)):\n    j=pd.DataFrame(e[i])\n    j.columns=['School','n','c','Arena','City']\n    for row in j.itertuples():\n            \n        teams.append([row.School,row.City])\n    i+=1\ny=pd.DataFrame(teams,columns=['School','City'])\ny.to_csv(\"nicknames.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T13:22:57.973002Z","iopub.execute_input":"2025-11-02T13:22:57.973424Z","iopub.status.idle":"2025-11-02T13:22:58.568965Z","shell.execute_reply.started":"2025-11-02T13:22:57.973390Z","shell.execute_reply":"2025-11-02T13:22:58.567599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:57:22.006402Z","iopub.execute_input":"2025-10-27T14:57:22.006829Z","iopub.status.idle":"2025-10-27T14:58:45.829418Z","shell.execute_reply.started":"2025-10-27T14:57:22.006792Z","shell.execute_reply":"2025-10-27T14:58:45.827849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T01:43:50.034276Z","iopub.execute_input":"2025-10-27T01:43:50.035256Z","iopub.status.idle":"2025-10-27T01:43:50.068154Z","shell.execute_reply.started":"2025-10-27T01:43:50.035224Z","shell.execute_reply":"2025-10-27T01:43:50.066724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T15:00:59.840820Z","iopub.execute_input":"2025-10-27T15:00:59.841361Z","iopub.status.idle":"2025-10-27T15:00:59.904104Z","shell.execute_reply.started":"2025-10-27T15:00:59.841317Z","shell.execute_reply":"2025-10-27T15:00:59.903097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/standings.csv\")\nstandings=pd.read_csv(\"https://cfbzzz.alwaysdata.net/ncaab/d1vsnond1/teams/d1standings.txt\")\ndf[df.season>1949]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T22:05:53.685037Z","iopub.execute_input":"2025-11-03T22:05:53.685293Z","iopub.status.idle":"2025-11-03T22:05:56.965495Z","shell.execute_reply.started":"2025-11-03T22:05:53.685266Z","shell.execute_reply":"2025-11-03T22:05:56.963744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dates={}\nimport nest_asyncio\nnest_asyncio.apply()\nh=df22[df22.season>2023]\nfor row in h.itertuples():\n    if row.date not in dates:\n        dates[row.date]=row.season\nfor d in dates:\n    print(d)\n    d=str(d)\n    d=d.replace(\".0\",\"\")\n    url=\"https://barttorvik.com/schedule.php?date=\"+d+\"&conlimit=\"\n    loop = asyncio.get_event_loop()\n    table = loop.run_until_complete(main(url))\n    for tr in table.find_all(\"tr\"):\n        if \"Result\" not in str(tr) and 'absolute error' not in str(tr):\n            teams=tr.find_all(\"td\")[1]\n            pred=tr.find_all(\"td\")[2]\n            pred=pred.find(\"a\").text\n            score=tr.find_all(\"td\")[4]\n            score=score.find(\"a\").text\n            t1=teams.find_all(\"a\")[0].text\n            t2=teams.find_all(\"a\")[1].text\n            pred=pred.split(\",\")\n            pred=pred[0]\n            predw=\"?\"\n            line=\"?\"\n            if \"-\" in str(pred):\n                pred=pred.split(\"-\")\n                line=pred[1]\n                predw=pred[0]\n            if 'vs' in str(teams):\n                n=True\n            elif 'at' in str(teams):\n                n=False\n                \n            arr.append([d,t2,t1,predw,line,score,n,dates[float(str(d)+\".0\")]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T15:01:07.496202Z","iopub.execute_input":"2025-10-27T15:01:07.497791Z","iopub.status.idle":"2025-10-27T15:08:45.635116Z","shell.execute_reply.started":"2025-10-27T15:01:07.497742Z","shell.execute_reply":"2025-10-27T15:08:45.633872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['date','home','away','predw','line','final','neutral','season'])\ndf.to_csv(\"barttvk2.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T15:10:51.874939Z","iopub.execute_input":"2025-10-27T15:10:51.875466Z","iopub.status.idle":"2025-10-27T15:10:51.944934Z","shell.execute_reply.started":"2025-10-27T15:10:51.875420Z","shell.execute_reply":"2025-10-27T15:10:51.943447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=df.astype({\"final\":\"string\"})\ndf=df.replace(\"Ohio St.\",\"Ohio State\")\ndf['final']=df['final'].str.replace(\" St.\",\" State\")\ndf['home']=df['home'].str.replace(\" St.\",\" State\")\ndf['away']=df['away'].str.replace(\" St.\",\" State\")\ndf['predw']=df['predw'].str.replace(\" St.\",\" State\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T15:13:21.436071Z","iopub.execute_input":"2025-10-27T15:13:21.437288Z","iopub.status.idle":"2025-10-27T15:13:21.501583Z","shell.execute_reply.started":"2025-10-27T15:13:21.437209Z","shell.execute_reply":"2025-10-27T15:13:21.500090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"names={}\nfor row in df.itertuples():\n    score=str(row.final)\n    scores=score.split(\",\")[1]\n    scores=scores.replace(\" \",\"\")\n    winner=score.split(\",\")[0]\n    s1=scores.split(\"-\")[0]\n    s2=scores.split(\"-\")[1]\n    if row.home==winner:\n        name=row.home+row.away+s1+s2\n    elif row.away==winner:\n        name=row.away+row.home+s1+s2\n    if name not in names:\n        names[name]=0\n    if\n    names[name]+=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T01:39:19.232767Z","iopub.execute_input":"2025-10-27T01:39:19.233125Z","iopub.status.idle":"2025-10-27T01:39:19.511191Z","shell.execute_reply.started":"2025-10-27T01:39:19.233097Z","shell.execute_reply":"2025-10-27T01:39:19.508814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"names['LIUWagner6047']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T01:40:44.009940Z","iopub.execute_input":"2025-10-27T01:40:44.010298Z","iopub.status.idle":"2025-10-27T01:40:44.018161Z","shell.execute_reply.started":"2025-10-27T01:40:44.010274Z","shell.execute_reply":"2025-10-27T01:40:44.016687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"j=0\nfor key in names:\n    if float(names[key])>1:\n        k=key\n        j+=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T01:40:36.383221Z","iopub.execute_input":"2025-10-27T01:40:36.383631Z","iopub.status.idle":"2025-10-27T01:40:36.417984Z","shell.execute_reply.started":"2025-10-27T01:40:36.383601Z","shell.execute_reply":"2025-10-27T01:40:36.416250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"k","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T01:40:38.049394Z","iopub.execute_input":"2025-10-27T01:40:38.049856Z","iopub.status.idle":"2025-10-27T01:40:38.059249Z","shell.execute_reply.started":"2025-10-27T01:40:38.049830Z","shell.execute_reply":"2025-10-27T01:40:38.056358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!playwright install-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T21:15:42.672129Z","iopub.execute_input":"2025-10-26T21:15:42.672526Z","iopub.status.idle":"2025-10-26T21:16:21.960141Z","shell.execute_reply.started":"2025-10-26T21:15:42.672490Z","shell.execute_reply":"2025-10-26T21:16:21.958894Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T23:33:15.096549Z","iopub.execute_input":"2025-10-26T23:33:15.096893Z","iopub.status.idle":"2025-10-26T23:33:15.108021Z","shell.execute_reply.started":"2025-10-26T23:33:15.096866Z","shell.execute_reply":"2025-10-26T23:33:15.106641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"t=eloLeague.ratingDict['Indiana']+hfas[confs[2025]['Indiana']]+confy[confs[2025]['Indiana']]\ntt=eloLeague.ratingDict['Grambling']+confy[confs[2025]['Grambling']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T01:58:59.945759Z","iopub.execute_input":"2025-10-26T01:58:59.946863Z","iopub.status.idle":"2025-10-26T01:58:59.953116Z","shell.execute_reply.started":"2025-10-26T01:58:59.946786Z","shell.execute_reply":"2025-10-26T01:58:59.951697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"w=[]\nfor y in confs:\n    for t in confs[y]:\n        if confs[y][t]=='nan':\n            w.append(t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T01:57:20.012090Z","iopub.execute_input":"2025-10-26T01:57:20.012519Z","iopub.status.idle":"2025-10-26T01:57:20.022391Z","shell.execute_reply.started":"2025-10-26T01:57:20.012483Z","shell.execute_reply":"2025-10-26T01:57:20.020948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.read_csv(\"https://cfbzzz.alwaysdata.net/newcbb/standings.csv\")\ndf[df.isna()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T01:57:52.501731Z","iopub.execute_input":"2025-10-26T01:57:52.502203Z","iopub.status.idle":"2025-10-26T01:57:53.887035Z","shell.execute_reply.started":"2025-10-26T01:57:52.502169Z","shell.execute_reply":"2025-10-26T01:57:53.886069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup, Comment\n\nlinks={}\nimport time\nys={}\nfor i in range(1949,2026):\n    ys[i]=[]\nfor i in range(2026,2027):\n    print(i)\n    links[i]=[]\n    html=requests.get(\"https://www.sports-reference.com/cbb/seasons/men/\"+str(i)+\"-standings.html\")\n    print(html.status_code)\n    html=html.text\n    html=html.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n    soup=BeautifulSoup(html,'lxml')\n    \n    \n    y=i-1\n    for table in soup.find_all(\"table\"):\n        for tr in table.find_all(\"tr\"):\n            if \"Notes\" not in str(tr) and 'Overall' not in str(tr):\n                \n                \n                schl=tr.find_all(\"td\")[0].text\n                conf=tr.find_all(\"td\")[1].text\n                srs=tr.find_all(\"td\")[13].text\n            \n                \n                arr.append([schl,conf,y,srs])\n    time.sleep(5)\n    print(len(arr))","metadata":{"execution":{"iopub.status.busy":"2025-10-26T00:41:22.213975Z","iopub.execute_input":"2025-10-26T00:41:22.214403Z","iopub.status.idle":"2025-10-26T00:41:28.022019Z","shell.execute_reply.started":"2025-10-26T00:41:22.214373Z","shell.execute_reply":"2025-10-26T00:41:28.020628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.DataFrame(arr,columns=['team','conf','season','num'])\ndf.to_csv(\"standings.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T00:41:37.882121Z","iopub.execute_input":"2025-10-26T00:41:37.882502Z","iopub.status.idle":"2025-10-26T00:41:37.954587Z","shell.execute_reply.started":"2025-10-26T00:41:37.882472Z","shell.execute_reply":"2025-10-26T00:41:37.953311Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ","metadata":{}}]}